"""
Logistics Planner 
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import glob
from datetime import datetime
import io

# ==========================================
# CONFIG
# ==========================================
MODEL_PATH = 'models/decision_tree_model.pkl'

# ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
LIMITS = {
    '4W': {'max_w': 2500, 'max_c': 5.0},
    '6W': {'max_w': 5800, 'max_c': 22.0},
    'JB': {'max_w': 3500, 'max_c': 8.0}
}

# ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÑ‡∏î‡πâ‡πÄ‡∏Å‡∏¥‡∏ô 5%
BUFFER = 1.05

# ==========================================
# HELPER FUNCTIONS
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def can_fit_truck(total_weight, total_cube, truck_type):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡πÉ‡∏™‡πà‡∏£‡∏ñ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    limits = LIMITS[truck_type]
    max_w = limits['max_w'] * BUFFER
    max_c = limits['max_c'] * BUFFER
    return total_weight <= max_w and total_cube <= max_c

def suggest_truck(total_weight, total_cube):
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
    for truck in ['4W', 'JB', '6W']:
        if can_fit_truck(total_weight, total_cube, truck):
            return truck
    return '6W+'  # ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏•‡∏±‡∏á 6W

def is_similar_name(name1, name2):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤1, ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤2)"""
    def clean_name(name):
        if pd.isna(name) or name is None:
            return ""
        s = str(name).strip().upper()
        # ‡∏•‡∏ö prefix ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
        prefixes = ['PTC-MRT-', 'PTC-', 'PUN-', 'FC', 'MAXMART', 'MaxMart']
        for prefix in prefixes:
            s = s.replace(prefix.upper(), '')
        # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
        cleaned = ''.join([c for c in s if c.isalpha()])
        return cleaned
    
    clean1 = clean_name(name1)
    clean2 = clean_name(name2)
    
    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£
    if len(clean1) < 3 or len(clean2) < 3:
        return False
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    shorter = min(clean1, clean2, key=len)
    longer = max(clean1, clean2, key=len)
    
    # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏±‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡∏ß ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô 80%+ = ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
    if shorter in longer:
        return True
    
    # ‡∏ô‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
    matches = sum(1 for a, b in zip(clean1, clean2) if a == b)
    similarity = matches / max(len(clean1), len(clean2))
    
    return similarity >= 0.8  # ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô 80% ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ

def load_model():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
    if not os.path.exists(MODEL_PATH):
        return None
    
    try:
        with open(MODEL_PATH, 'rb') as f:
            model_data = pickle.load(f)
        return model_data
    except Exception as e:
        st.error(f"‚ùå Error loading model: {e}")
        return None

def create_pair_features(code1, code2, branch_info):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤"""
    import math
    
    info1 = branch_info[code1]
    info2 = branch_info[code2]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß
    weight_diff = abs(info1['avg_weight'] - info2['avg_weight'])
    cube_diff = abs(info1['avg_cube'] - info2['avg_cube'])
    weight_sum = info1['avg_weight'] + info2['avg_weight']
    cube_sum = info1['avg_cube'] + info2['avg_cube']
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    same_province = 1 if info1['province'] == info2['province'] else 0
    
    # Code prefix ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    prefix1 = code1[:2] if len(code1) >= 2 else code1
    prefix2 = code2[:2] if len(code2) >= 2 else code2
    same_prefix = 1 if prefix1 == prefix2 else 0
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î
    distance_km = 0.0
    if info1['latitude'] != 0 and info2['latitude'] != 0:
        lat1, lon1 = math.radians(info1['latitude']), math.radians(info1['longitude'])
        lat2, lon2 = math.radians(info2['latitude']), math.radians(info2['longitude'])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
        c = 2 * math.asin(math.sqrt(a))
        distance_km = 6371 * c
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
    freq_product = info1['total_trips'] * info2['total_trips']
    freq_diff = abs(info1['total_trips'] - info2['total_trips'])
    
    # Ratio
    weight_ratio = (info1['avg_weight'] / info2['avg_weight']) if info2['avg_weight'] > 0 else 0
    cube_ratio = (info1['avg_cube'] / info2['avg_cube']) if info2['avg_cube'] > 0 else 0
    
    # ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ
    over_4w = 1 if (weight_sum > 2500 or cube_sum > 5.0) else 0
    over_jb = 1 if (weight_sum > 3500 or cube_sum > 8.0) else 0
    over_6w = 1 if (weight_sum > 5800 or cube_sum > 22.0) else 0
    
    return {
        'weight_sum': weight_sum,
        'cube_sum': cube_sum,
        'weight_diff': weight_diff,
        'cube_diff': cube_diff,
        'same_province': same_province,
        'same_prefix': same_prefix,
        'distance_km': distance_km,
        'avg_weight_1': info1['avg_weight'],
        'avg_weight_2': info2['avg_weight'],
        'avg_cube_1': info1['avg_cube'],
        'avg_cube_2': info2['avg_cube'],
        'freq_product': freq_product,
        'freq_diff': freq_diff,
        'weight_ratio': weight_ratio,
        'cube_ratio': cube_ratio,
        'over_4w': over_4w,
        'over_jb': over_jb,
        'over_6w': over_6w
    }

def load_excel(file_content, sheet_name=None):
    """‡πÇ‡∏´‡∏•‡∏î Excel"""
    try:
        xls = pd.ExcelFile(io.BytesIO(file_content))
        
        target_sheet = None
        if sheet_name and sheet_name in xls.sheet_names:
            target_sheet = sheet_name
        else:
            for s in xls.sheet_names:
                if 'punthai' in s.lower() or '2.' in s.lower():
                    target_sheet = s
                    break
        
        if not target_sheet:
            target_sheet = xls.sheet_names[0]
        
        # ‡∏´‡∏≤ header row
        df_temp = pd.read_excel(xls, sheet_name=target_sheet, header=None)
        header_row = 0
        
        for i in range(min(10, len(df_temp))):
            row_values = df_temp.iloc[i].astype(str).str.upper()
            match_count = sum([
                'BRANCH' in ' '.join(row_values),
                'TRIP' in ' '.join(row_values),
                '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in ' '.join(df_temp.iloc[i].astype(str))
            ])
            if match_count >= 2:
                header_row = i
                break
        
        df = pd.read_excel(xls, sheet_name=target_sheet, header=header_row)
        df = df.loc[:, ~df.columns.duplicated()]
        
        return df
    except Exception as e:
        st.error(f"‚ùå Error: {e}")
        return None

def process_dataframe(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    if df is None:
        return None
    
    rename_map = {}
    for col in df.columns:
        col_clean = str(col).strip()
        col_upper = col_clean.upper().replace(' ', '').replace('_', '')
        
        if col_clean == 'BranchCode' or '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏£‡∏´‡∏±‡∏™ WMS':
            rename_map[col] = 'Code'
        elif col_clean == 'Branch' or '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏™‡∏≤‡∏Ç‡∏≤':
            rename_map[col] = 'Name'
        elif col_clean == 'TOTALWGT' or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col_clean:
            rename_map[col] = 'Weight'
        elif col_clean == 'TOTALCUBE' or '‡∏Ñ‡∏¥‡∏ß' in col_clean:
            rename_map[col] = 'Cube'
        elif 'latitude' in col_clean.lower() or col_clean == '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î':
            rename_map[col] = 'Latitude'
        elif 'longitude' in col_clean.lower() or col_clean == '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î':
            rename_map[col] = 'Longitude'
        elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean:
            rename_map[col] = 'Province'
    
    df = df.rename(columns=rename_map)
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥
    df = df.loc[:, ~df.columns.duplicated()]
    
    if 'Code' in df.columns:
        df['Code'] = df['Code'].apply(normalize)
    
    for col in ['Weight', 'Cube']:
        if col not in df.columns:
            df[col] = 0.0
        else:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)
    
    return df.reset_index(drop=True)

def predict_trips(test_df, model_data):
    """
    ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏î‡πâ‡∏ß‡∏¢ AI ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏é‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
    1. ‚úÖ ‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ (trip_pairs) - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100% + ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
    2. ‚úÖ ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤1, ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤2)
    3. ‚úÖ AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å Decision Tree Model
    4. ‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡∏´‡∏£‡∏∑‡∏≠ Auto-suggest
    """
    model = model_data['model']
    trip_pairs = model_data['trip_pairs']
    branch_info = model_data['branch_info']
    trip_vehicles = model_data.get('trip_vehicles', {})  # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà
    for code in test_df['Code'].unique():
        if code not in branch_info:
            code_data = test_df[test_df['Code'] == code]
            branch_info[code] = {
                'avg_weight': code_data['Weight'].mean(),
                'avg_cube': code_data['Cube'].mean(),
                'total_trips': 1,
                'province': code_data['Province'].iloc[0] if 'Province' in code_data.columns else 'UNKNOWN',
                'latitude': 0.0,
                'longitude': 0.0
            }
    
    all_codes = test_df['Code'].unique().tolist()
    assigned_trips = {}
    trip_counter = 1
    trip_recommended_vehicles = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_codes = len(all_codes)
    processed = 0
    
    while all_codes:
        seed_code = all_codes.pop(0)
        current_trip = [seed_code]
        assigned_trips[seed_code] = trip_counter
        
        processed += 1
        progress_bar.progress(processed / total_codes)
        status_text.text(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ {trip_counter}... ({processed}/{total_codes} ‡∏™‡∏≤‡∏Ç‡∏≤)")
        
        remaining = all_codes[:]
        recommended_vehicle = None  # ‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ
        
        for code in remaining:
            pair = tuple(sorted([seed_code, code]))
            
            # ‡∏Å‡∏é 1: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡∏à‡∏±‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô + ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏° (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
            if pair in trip_pairs:
                should_pair = True
                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
                if pair in trip_vehicles and recommended_vehicle is None:
                    vehicle_info = trip_vehicles[pair]
                    recommended_vehicle = vehicle_info.get('vehicle', '6W')
            else:
                # ‡∏Å‡∏é 2: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤1, ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤2)
                seed_name = test_df[test_df['Code'] == seed_code]['Name'].iloc[0] if 'Name' in test_df.columns else ''
                code_name = test_df[test_df['Code'] == code]['Name'].iloc[0] if 'Name' in test_df.columns else ''
                
                if is_similar_name(seed_name, code_name):
                    should_pair = True
                else:
                    # ‡∏Å‡∏é 3: ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                    features = create_pair_features(seed_code, code, branch_info)
                    X = pd.DataFrame([features])
                    should_pair = model.predict(X)[0] == 1
            
            if should_pair:
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ
                trip_weight = test_df[test_df['Code'].isin(current_trip + [code])]['Weight'].sum()
                trip_cube = test_df[test_df['Code'].isin(current_trip + [code])]['Cube'].sum()
                
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏£‡∏ñ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡πÉ‡∏ä‡πâ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡∏ô‡∏±‡πâ‡∏ô
                if recommended_vehicle and recommended_vehicle in LIMITS:
                    max_w = LIMITS[recommended_vehicle]['max_w'] * BUFFER
                    max_c = LIMITS[recommended_vehicle]['max_c'] * BUFFER
                else:
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ 6W ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
                    max_w = LIMITS['6W']['max_w'] * BUFFER
                    max_c = LIMITS['6W']['max_c'] * BUFFER
                
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if trip_weight <= max_w and trip_cube <= max_c:
                    current_trip.append(code)
                    assigned_trips[code] = trip_counter
                    all_codes.remove(code)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ
        if recommended_vehicle:
            trip_recommended_vehicles[trip_counter] = recommended_vehicle
        
        trip_counter += 1
    
    progress_bar.empty()
    status_text.empty()
    
    test_df['Trip'] = test_df['Code'].map(assigned_trips)
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ
    summary_data = []
    for trip_num in sorted(test_df['Trip'].unique()):
        trip_data = test_df[test_df['Trip'] == trip_num]
        total_w = trip_data['Weight'].sum()
        total_c = trip_data['Cube'].sum()
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá auto-suggest
        if trip_num in trip_recommended_vehicles:
            suggested = trip_recommended_vehicles[trip_num]
            source = "üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥"
        else:
            suggested = suggest_truck(total_w, total_c)
            source = "ü§ñ AI"
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ
        if suggested in LIMITS:
            w_util = (total_w / LIMITS[suggested]['max_w']) * 100
            c_util = (total_c / LIMITS[suggested]['max_c']) * 100
        else:
            w_util = c_util = 0
        
        summary_data.append({
            'Trip': trip_num,
            'Branches': len(trip_data),
            'Weight': total_w,
            'Cube': total_c,
            'Truck': f"{suggested} {source}",
            'Weight_Use%': w_util,
            'Cube_Use%': c_util
        })
    
    summary_df = pd.DataFrame(summary_data)
    
    return test_df, summary_df

# ==========================================
# STREAMLIT UI
# ==========================================
def main():
    st.set_page_config(
        page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡πà‡∏á‡∏Ç‡∏≠‡∏á",
        page_icon="üöö",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # Header
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("üöö ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞")
        st.caption("Smart Logistics Planner")
    with col2:
        st.image("https://raw.githubusercontent.com/twitter/twemoji/master/assets/svg/1f69a.svg", width=100)
    
    st.markdown("---")
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_data = load_model()
    
    if not model_data:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.info("üí° ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: `python test_model.py`")
        st.stop()
    
    # ‡πÅ‡∏ó‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å
    tab1, tab2 = st.tabs(["üì¶ ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡πà‡∏á‡∏Ç‡∏≠‡∏á", "üìö ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"])
    
    # ==========================================
    # ‡πÅ‡∏ó‡πá‡∏ö 1: ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
    # ==========================================
    with tab1:
        st.markdown("### üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            uploaded_file = st.file_uploader(
                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel (.xlsx)", 
                type=['xlsx'],
                help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå"
            )
        with col2:
            st.info("""
            **‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå:**
            - ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤
            - ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
            - ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å (kg)
            - ‡∏Ñ‡∏¥‡∏ß (m¬≥)
            """)
    
    if uploaded_file:
        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
            df = load_excel(uploaded_file.read())
            df = process_dataframe(df)
            
            if df is not None and 'Code' in df.columns:
                st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df)} ‡πÅ‡∏ñ‡∏ß")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                with st.expander("üîç ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö"):
                    st.dataframe(df.head(10))
                
                # ‡∏õ‡∏∏‡πà‡∏°‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
                if st.button("üöÄ ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥", type="primary", use_container_width=True):
                    with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ (‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)..."):
                        result_df, summary = predict_trips(df, model_data)
                        
                        st.success(f"‚úÖ ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô! ‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ {len(summary)} ‡∏ó‡∏£‡∏¥‡∏õ")
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", len(result_df))
                        with col2:
                            st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏£‡∏¥‡∏õ", result_df['Trip'].nunique())
                        with col3:
                            avg_branches = len(result_df) / result_df['Trip'].nunique()
                            st.metric("‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤/‡∏ó‡∏£‡∏¥‡∏õ", f"{avg_branches:.1f}")
                        
                        st.markdown("---")
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ
                        st.markdown("### üìä ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ")
                        st.dataframe(
                            summary.style.format({
                                'Weight': '{:.2f}',
                                'Cube': '{:.2f}',
                                'Weight_Use%': '{:.1f}%',
                                'Cube_Use%': '{:.1f}%'
                            }).background_gradient(
                                subset=['Weight_Use%', 'Cube_Use%'],
                                cmap='RdYlGn',
                                vmin=0,
                                vmax=100
                            ),
                            use_container_width=True
                        )
                        
                        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ï‡πá‡∏°
                        st.markdown("### üìã ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î")
                        st.dataframe(result_df, use_container_width=True)
                        
                        # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
                        output = io.BytesIO()
                        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                            result_df.to_excel(writer, sheet_name='Trips', index=False)
                            summary.to_excel(writer, sheet_name='Summary', index=False)
                        
                        st.download_button(
                            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Excel)",
                            data=output.getvalue(),
                            file_name=f"trips_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

if __name__ == "__main__":
    main()
