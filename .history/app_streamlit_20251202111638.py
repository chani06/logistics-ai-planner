import streamlit as st
import pandas as pd
import numpy as np
import io
import os
import networkx as nx
from sklearn.cluster import DBSCAN
import math
import warnings

warnings.filterwarnings('ignore')

# ==========================================
# 1. CONFIG
# ==========================================
LIMITS = {'4W': {'max_w': 2500, 'max_c': 5.0}, 'JB': {'max_w': 3500, 'max_c': 8.0}, '6W': {'max_w': 5800, 'max_c': 22.0}}
BUFFER = 1.05
MAX_KM_CLUSTER = 30.0
TARGET_DROPS = 10
MAX_DROPS_FLEX = 12
NEARBY_RADIUS = 5.0
MAX_ZONE_DISTANCE = 100.0
STRICT_ZONE_MODE = True
EXCLUDE = ['PTDC', 'Distribution Center', 'DCà¸§à¸±à¸‡à¸™à¹‰à¸­à¸¢', 'DC011']

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def normalize(val):
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    dLat = math.radians(lat2 - lat1)
    dLon = math.radians(lon2 - lon1)
    a = math.sin(dLat/2) * math.sin(dLat/2) + \
        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * \
        math.sin(dLon/2) * math.sin(dLon/2)
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    return R * c

def is_similar_name(name1, name2):
    def clean(n):
        return ''.join([c for c in str(n) if c.isalpha()])
    return clean(name1) == clean(name2) and len(clean(name1)) > 3

def get_province_zone(province):
    if not province or pd.isna(province):
        return 'UNKNOWN'
    
    prov = str(province).strip()
    
    central = ['à¸à¸£à¸¸à¸‡à¹€à¸—à¸ž', 'à¸™à¸™à¸—à¸šà¸¸à¸£à¸µ', 'à¸›à¸—à¸¸à¸¡à¸˜à¸²à¸™à¸µ', 'à¸ªà¸¡à¸¸à¸—à¸£à¸›à¸£à¸²à¸à¸²à¸£', 'à¸ªà¸¡à¸¸à¸—à¸£à¸ªà¸²à¸„à¸£', 'à¸™à¸„à¸£à¸›à¸à¸¡', 
               'à¸ªà¸¡à¸¸à¸—à¸£à¸ªà¸‡à¸„à¸£à¸²à¸¡', 'à¸£à¸²à¸Šà¸šà¸¸à¸£à¸µ', 'à¸à¸²à¸à¸ˆà¸™à¸šà¸¸à¸£à¸µ', 'à¸ªà¸¸à¸žà¸£à¸£à¸“à¸šà¸¸à¸£à¸µ', 'à¸Šà¸±à¸¢à¸™à¸²à¸—', 'à¸ªà¸´à¸‡à¸«à¹Œà¸šà¸¸à¸£à¸µ', 
               'à¸­à¹ˆà¸²à¸‡à¸—à¸­à¸‡', 'à¸¥à¸žà¸šà¸¸à¸£à¸µ', 'à¸ªà¸£à¸°à¸šà¸¸à¸£à¸µ', 'à¸­à¸¢à¸¸à¸˜à¸¢à¸²', 'à¸žà¸£à¸°à¸™à¸„à¸£à¸¨à¸£à¸µà¸­à¸¢à¸¸à¸˜à¸¢à¸²']
    
    northeast = ['à¸™à¸„à¸£à¸£à¸²à¸Šà¸ªà¸µà¸¡à¸²', 'à¹‚à¸„à¸£à¸²à¸Š', 'à¸šà¸¸à¸£à¸µà¸£à¸±à¸¡à¸¢à¹Œ', 'à¸ªà¸¸à¸£à¸´à¸™à¸—à¸£à¹Œ', 'à¸¨à¸µà¸‚à¸£à¸ à¸¹à¸¡à¸´', 'à¸‚à¸­à¸™à¹à¸à¹ˆà¸™', 
                 'à¸­à¸¸à¸”à¸£à¸˜à¸²à¸™à¸µ', 'à¹€à¸¥à¸¢', 'à¸«à¸™à¸­à¸‡à¸„à¸²à¸¢', 'à¸¡à¸«à¸²à¸ªà¸²à¸£à¸„à¸²à¸¡', 'à¸£à¹‰à¸­à¸¢à¹€à¸­à¹‡à¸”', 'à¸à¸²à¸¬à¸ªà¸´à¸™à¸˜à¸¸à¹Œ', 
                 'à¸ªà¸à¸¥à¸™à¸„à¸£', 'à¸™à¸„à¸£à¸žà¸™à¸¡', 'à¸¡à¸¸à¸à¸”à¸²à¸«à¸²à¸£', 'à¸¢à¹‚à¸ªà¸˜à¸£', 'à¸­à¸³à¸™à¸²à¸ˆà¹€à¸ˆà¸£à¸´à¸', 'à¸­à¸¸à¸šà¸¥à¸£à¸²à¸Šà¸˜à¸²à¸™à¸µ', 
                 'à¸Šà¸±à¸¢à¸ à¸¹à¸¡à¸´', 'à¸šà¸¶à¸‡à¸à¸²à¸¬']
    
    north = ['à¹€à¸Šà¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ', 'à¹€à¸Šà¸µà¸¢à¸‡à¸£à¸²à¸¢', 'à¸¥à¸³à¸žà¸¹à¸™', 'à¸¥à¸³à¸›à¸²à¸‡', 'à¸žà¸°à¹€à¸¢à¸²', 'à¹à¸žà¸£à¹ˆ', 'à¸™à¹ˆà¸²à¸™', 
             'à¸­à¸¸à¸•à¸£à¸”à¸´à¸•à¸–à¹Œ', 'à¸•à¸²à¸', 'à¸ªà¸¸à¹‚à¸‚à¸—à¸±à¸¢', 'à¸žà¸´à¸©à¸“à¸¸à¹‚à¸¥à¸', 'à¸žà¸´à¸ˆà¸´à¸•à¸£', 'à¹€à¸žà¸Šà¸£à¸šà¸¹à¸£à¸“à¹Œ', 'à¸à¸³à¹à¸žà¸‡à¹€à¸žà¸Šà¸£']
    
    south = ['à¸Šà¸¸à¸¡à¸žà¸£', 'à¸ªà¸¸à¸£à¸²à¸©à¸Žà¸£à¹Œà¸˜à¸²à¸™à¸µ', 'à¸£à¸°à¸™à¸­à¸‡', 'à¸žà¸±à¸‡à¸‡à¸²', 'à¸ à¸¹à¹€à¸à¹‡à¸•', 'à¸à¸£à¸°à¸šà¸µà¹ˆ', 'à¸™à¸„à¸£à¸¨à¸£à¸µà¸˜à¸£à¸£à¸¡à¸£à¸²à¸Š', 
             'à¸•à¸£à¸±à¸‡', 'à¸žà¸±à¸—à¸¥à¸¸à¸‡', 'à¸ªà¸‡à¸‚à¸¥à¸²', 'à¸ªà¸•à¸¹à¸¥', 'à¸›à¸±à¸•à¸•à¸²à¸™à¸µ', 'à¸¢à¸°à¸¥à¸²', 'à¸™à¸£à¸²à¸˜à¸´à¸§à¸²à¸ª']
    
    east = ['à¸‰à¸°à¹€à¸Šà¸´à¸‡à¹€à¸—à¸£à¸²', 'à¸Šà¸¥à¸šà¸¸à¸£à¸µ', 'à¸£à¸°à¸¢à¸­à¸‡', 'à¸ˆà¸±à¸™à¸—à¸šà¸¸à¸£à¸µ', 'à¸•à¸£à¸²à¸”', 'à¸›à¸£à¸²à¸ˆà¸µà¸™à¸šà¸¸à¸£à¸µ', 'à¸ªà¸£à¸°à¹à¸à¹‰à¸§']
    
    west = ['à¸à¸²à¸à¸ˆà¸™à¸šà¸¸à¸£à¸µ', 'à¸•à¸²à¸', 'à¸›à¸£à¸°à¸ˆà¸§à¸šà¸„à¸µà¸£à¸µà¸‚à¸±à¸™à¸˜à¹Œ', 'à¹€à¸žà¸Šà¸£à¸šà¸¸à¸£à¸µ']
    
    for p in central:
        if p in prov: return 'CENTRAL'
    for p in northeast:
        if p in prov: return 'NORTHEAST'
    for p in north:
        if p in prov: return 'NORTH'
    for p in south:
        if p in prov: return 'SOUTH'
    for p in east:
        if p in prov: return 'EAST'
    for p in west:
        if p in prov: return 'WEST'
    
    return 'UNKNOWN'

def is_same_zone(code1, code2, zone_map, geo):
    if not STRICT_ZONE_MODE:
        return True
    
    if code1 in geo and code2 in geo:
        lat1, lon1 = geo[code1]
        lat2, lon2 = geo[code2]
        if lat1 != 0 and lat2 != 0:
            dist = haversine(lat1, lon1, lat2, lon2)
            if dist > MAX_ZONE_DISTANCE:
                return False
    
    zone1 = zone_map.get(code1, 'UNKNOWN')
    zone2 = zone_map.get(code2, 'UNKNOWN')
    
    if zone1 != 'UNKNOWN' and zone2 != 'UNKNOWN':
        if zone1 != zone2:
            return False
    
    return True

# ==========================================
# 3. LOADERS & PROCESSORS
# ==========================================
def load_excel(content):
    try:
        xls = pd.ExcelFile(io.BytesIO(content))
        target_sheet = None
        priority = ['2.', 'punthai', 'order', 'history']
        for p in priority:
            for s in xls.sheet_names:
                if p in s.lower(): target_sheet = s; break
            if target_sheet: break
        if not target_sheet: target_sheet = xls.sheet_names[0]
        
        df_tmp = pd.read_excel(xls, sheet_name=target_sheet, nrows=20, header=None)
        h_row = -1
        for i, r in df_tmp.iterrows():
            row_str = r.astype(str).str.upper().tolist()
            if sum(1 for k in ['CODE','BRANCH','à¸ªà¸²à¸‚à¸²','WGT'] if any(k in s for s in row_str)) >= 2:
                h_row = i; break
        if h_row == -1: h_row = 1
        return pd.read_excel(xls, sheet_name=target_sheet, header=h_row)
    except: return None

def process_dataframe(df):
    if df is None: return None
    df.columns = df.columns.astype(str).str.strip()
    df = df.loc[:, ~df.columns.duplicated()]
    rename_map = {}
    for c in df.columns:
        cu = c.upper().replace(' ','').replace('_','')
        if 'BRANCHCODE' in cu or 'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²' in cu: rename_map[c] = 'Code'
        elif 'BRANCH' in cu or 'à¸Šà¸·à¹ˆà¸­à¸ªà¸²à¸‚à¸²' in cu or 'à¸ªà¸²à¸‚à¸²'==c: rename_map[c] = 'Name'
        elif 'WGT' in cu or 'à¸™à¹‰à¸³à¸«à¸™à¸±à¸' in cu: rename_map[c] = 'Wgt'
        elif 'CUBE' in cu or 'à¸„à¸´à¸§' in cu: rename_map[c] = 'Cube'
        elif 'LAT' in cu: rename_map[c] = 'Lat'
        elif 'LON' in cu: rename_map[c] = 'Lon'
        elif 'TRIP' in cu or 'BOOKING' in cu: rename_map[c] = 'Trip'
        elif 'VEHICLE' in cu or 'TRIPNO' in cu: rename_map[c] = 'Vehicle'
        elif 'à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”' in cu: rename_map[c] = 'Province'
    
    df.rename(columns=rename_map, inplace=True)
    if 'Code' not in df.columns:
        if 'Name' in df.columns: df['Code'] = df['Name']
        else: return None
        
    df['Code'] = df['Code'].apply(normalize)
    for c in ['Wgt','Cube','Lat','Lon']:
        if c not in df.columns: df[c] = 0.0
        else: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0.0)
        
    mask_ex = df['Code'].isin(EXCLUDE)
    if 'Name' in df.columns: mask_ex |= df['Name'].apply(lambda x: any(k in str(x) for k in EXCLUDE))
    return df[~mask_ex].copy()

def process_geo(df):
    if df is None: return {}
    df = process_dataframe(df)
    geo = {}
    if df is not None:
        for _, r in df.iterrows():
            if r['Lat']!=0: geo[r['Code']] = (r['Lat'], r['Lon'])
    return geo

# ==========================================
# 4. AI CORE
# ==========================================
def train_ai(df_list):
    G = nx.Graph()
    req = {}
    zones = {}
    regions = {}
    
    for df in df_list:
        if df is None or 'Trip' not in df.columns: continue
        
        # à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸² Trip à¹€à¸›à¹‡à¸™ DataFrame
        if isinstance(df['Trip'], pd.DataFrame):
            df = df.copy()
            df['Trip'] = df['Trip'].iloc[:,0]
        
        # à¹à¸›à¸¥à¸‡ Trip à¹€à¸›à¹‡à¸™ string à¹à¸¥à¸°à¸¥à¸š NaN
        df = df.copy()
        df['Trip'] = df['Trip'].astype(str)
        df = df[df['Trip'].notna() & (df['Trip'] != 'nan') & (df['Trip'] != '')]
        
        if len(df) == 0:
            continue
        
        for idx, r in df.iterrows():
            if 'Province' in df.columns and pd.notna(r['Province']):
                prov = str(r['Province']).strip()
                zones[r['Code']] = prov
                regions[r['Code']] = get_province_zone(prov)
            
        for t, g in df.groupby('Trip'):
            codes = g['Code'].unique()
            veh = str(g['Vehicle'].iloc[0]).upper() if 'Vehicle' in g.columns else ''
            rank = 3 if '6' in veh else (2 if 'J' in veh else 1)
            for c in codes: req[c] = max(req.get(c,1), rank)
            
            if len(codes)>1:
                for i in range(len(codes)):
                    for j in range(i+1, len(codes)): G.add_edge(codes[i], codes[j])
            elif len(codes)==1: G.add_node(codes[0])
    
    return G, req, regions

def select_truck(w, c, min_rank):
    s = min_rank
    if s >= 3: return '6 à¸¥à¹‰à¸­ à¸•à¸¹à¹‰à¸—à¸¶à¸š'
    if s <= 1 and c <= LIMITS['4W']['max_c']*BUFFER and w <= LIMITS['4W']['max_w']: return '4 à¸¥à¹‰à¸­ à¸•à¸¹à¹‰à¸—à¸¶à¸š'
    if s <= 2 and c <= LIMITS['JB']['max_c']*BUFFER and w <= LIMITS['JB']['max_w']: return '4 à¸¥à¹‰à¸­ à¸ˆà¸±à¸¡à¹‚à¸šà¹‰ à¸•à¸¹à¹‰à¸—à¸¶à¸š'
    return '6 à¸¥à¹‰à¸­ à¸•à¸¹à¹‰à¸—à¸¶à¸š'

def run_prediction(df_test, G, geo, constraints, region_map):
    df_test['Lat'] = df_test.apply(lambda r: geo.get(r['Code'],(0,0))[0] if r['Lat']==0 else r['Lat'], axis=1)
    df_test['Lon'] = df_test.apply(lambda r: geo.get(r['Code'],(0,0))[1] if r['Lon']==0 else r['Lon'], axis=1)
    df_test['Region'] = df_test['Code'].map(lambda x: region_map.get(x, 'UNKNOWN'))
    
    hist_map = {n:i for i,c in enumerate(nx.connected_components(G)) for n in c}
    df_test['Cluster'] = df_test['Code'].map(lambda x: f"H-{hist_map[x]}" if x in hist_map else "UNK")
    
    if STRICT_ZONE_MODE:
        new_clusters = []
        for idx, row in df_test.iterrows():
            if row['Cluster'] != 'UNK' and row['Region'] != 'UNKNOWN':
                new_clusters.append(f"{row['Cluster']}-{row['Region']}")
            else:
                new_clusters.append(row['Cluster'])
        df_test['Cluster'] = new_clusters
    
    mask_unk = df_test['Cluster']=="UNK"
    if mask_unk.any():
        mask_geo = (df_test['Lat']!=0) & mask_unk
        if mask_geo.any():
            coords = np.radians(df_test.loc[mask_geo, ['Lat','Lon']].values)
            db = DBSCAN(eps=MAX_KM_CLUSTER/6371.0, min_samples=1).fit(coords)
            df_test.loc[mask_geo, 'Cluster'] = [f"G-{x}" if x!=-1 else "NOISE" for x in db.labels_]
    
    mask_fin = df_test['Cluster'].isin(["UNK","NOISE"])
    if mask_fin.any():
        df_test.loc[mask_fin, 'Cluster'] = df_test.loc[mask_fin, 'Code'].map(
            lambda x: f"Z-{region_map.get(x, 'NEW')}" if x in region_map else f"NEW-{x}"
        )
    
    final_rows = []
    trip_cnt = 1
    
    for cid, group in df_test.groupby('Cluster'):
        pool = []
        for code, sub in group.groupby('Code'):
            pool.append({
                'Code': code, 'Name': sub.iloc[0]['Name'],
                'Wgt': sub['Wgt'].sum(), 'Cube': sub['Cube'].sum(),
                'Lat': sub.iloc[0]['Lat'], 'Lon': sub.iloc[0]['Lon']
            })
            
        while pool:
            pool.sort(key=lambda x: x['Cube'], reverse=True)
            current_truck = []
            seed = pool.pop(0)
            current_truck.append(seed)
            
            curr_w = seed['Wgt']
            curr_c = seed['Cube']
            last_lat = seed['Lat']
            last_lon = seed['Lon']
            last_name = seed['Name']
            drops = 1
            max_req = constraints.get(seed['Code'], 1)
            
            while True:
                best_idx = -1
                best_score = float('inf')
                best_is_same_name = False
                
                for i, cand in enumerate(pool):
                    if STRICT_ZONE_MODE:
                        if last_lat != 0 and cand['Lat'] != 0:
                            zone_dist = haversine(last_lat, last_lon, cand['Lat'], cand['Lon'])
                            if zone_dist > MAX_ZONE_DISTANCE:
                                continue
                        
                        if not is_same_zone(seed['Code'], cand['Code'], region_map, geo):
                            continue
                    
                    new_w = curr_w + cand['Wgt']
                    new_c = curr_c + cand['Cube']
                    
                    if new_w > 5800: continue
                    if new_c > 22.0 * BUFFER: continue
                    
                    is_same_name = is_similar_name(last_name, cand['Name'])
                    dist = haversine(last_lat, last_lon, cand['Lat'], cand['Lon']) if last_lat!=0 and cand['Lat']!=0 else 999
                    is_nearby = (dist <= NEARBY_RADIUS)
                    
                    if drops >= TARGET_DROPS:
                        if drops >= MAX_DROPS_FLEX: 
                            continue
                        if not (is_same_name or is_nearby): 
                            continue
                    
                    score = dist
                    if is_same_name:
                        score -= 1000
                    
                    is_better = (score < best_score)
                    if is_same_name and not best_is_same_name:
                        is_better = True
                    elif best_is_same_name and not is_same_name:
                        is_better = False
                    
                    if is_better:
                        best_score = score
                        best_idx = i
                        best_is_same_name = is_same_name
                        
                if best_idx != -1:
                    sel = pool.pop(best_idx)
                    current_truck.append(sel)
                    
                    curr_w += sel['Wgt']
                    curr_c += sel['Cube']
                    drops += 1
                    
                    if sel['Lat']!=0: 
                        last_lat = sel['Lat']; last_lon = sel['Lon']
                    last_name = sel['Name']
                    max_req = max(max_req, constraints.get(sel['Code'], 1))
                else:
                    break
            
            v_type = select_truck(curr_w, curr_c, max_req)
            tid = f"AI-{trip_cnt:03d}"
            
            for item in current_truck:
                final_rows.append({
                    'Booking No': tid, 'à¸›à¸£à¸°à¹€à¸ à¸—à¸£à¸–': v_type,
                    'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²': item['Code'], 'à¸ªà¸²à¸‚à¸²': item['Name'],
                    'TOTALWGT': item['Wgt'], 'TOTALCUBE': item['Cube'],
                    'Remark': f"Drops:{drops}", 'Lat': item['Lat'], 'Lon': item['Lon']
                })
            trip_cnt += 1
            
    return pd.DataFrame(final_rows)

def export_styled_excel(df, filename):
    try:
        import xlsxwriter
        writer = pd.ExcelWriter(filename, engine='xlsxwriter')
        df.to_excel(writer, index=False, sheet_name='Plan')
        wb = writer.book; ws = writer.sheets['Plan']
        fmt_h = wb.add_format({'bold': True, 'bg_color': '#4472C4', 'font_color': 'white', 'border': 1})
        fmt_1 = wb.add_format({'bg_color': '#FFFFFF', 'border': 1})
        fmt_2 = wb.add_format({'bg_color': '#D9D9D9', 'border': 1})
        for c, val in enumerate(df.columns): ws.write(0, c, val, fmt_h)
        curr = None; toggle = False
        for r, row in df.iterrows():
            if row['Booking No'] != curr: toggle = not toggle; curr = row['Booking No']
            fmt = fmt_1 if toggle else fmt_2
            for c, val in enumerate(row): ws.write(r+1, c, val, fmt)
        writer.close()
    except:
        df.to_excel(filename, index=False)

# ==========================================
# 5. STREAMLIT UI
# ==========================================
def main():
    st.set_page_config(page_title="AI Logistics Planner", page_icon="ðŸšš", layout="wide")
    
    st.title("ðŸšš AI Logistics Planner: Sticky Routing Edition")
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info("âœ¨ **Sticky Routing**: à¸Šà¸·à¹ˆà¸­à¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸™à¹„à¸›à¸à¹ˆà¸­à¸™ + à¹ƒà¸à¸¥à¹‰à¸à¸±à¸™à¹„à¸›à¸à¹ˆà¸­à¸™")
    with col2:
        st.info("ðŸ“¦ **Drop Rules**: 1-10 âœ“ | 11-12 (à¸Šà¸·à¹ˆà¸­à¹€à¸«à¸¡à¸·à¸­à¸™/à¹ƒà¸à¸¥à¹‰â‰¤5km) âœ“ | 13+ âœ—")
    with col3:
        st.info("ðŸŒ **Zone Filter**: Geofence 100km + Province/Region Aware")
    
    st.markdown("---")
    
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC
    dc_folder = os.path.join(os.getcwd(), 'DC')
    dc_files_found = []
    if os.path.exists(dc_folder):
        dc_files_found = glob.glob(os.path.join(dc_folder, '*.xlsx')) + glob.glob(os.path.join(dc_folder, '*.xls'))
    
    # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸žà¸šà¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC
    if dc_files_found:
        with st.expander(f"ðŸ“‚ à¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™ DC/ : {len(dc_files_found)} à¹„à¸Ÿà¸¥à¹Œ", expanded=True):
            for f in dc_files_found:
                st.text(f"âœ“ {os.path.basename(f)}")
    else:
        st.warning("âš ï¸ à¹„à¸¡à¹ˆà¸žà¸šà¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ 'DC/' à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿà¸¥à¹Œ Excel à¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ")
    
    st.markdown("---")
    
    # File uploader - à¹€à¸‰à¸žà¸²à¸° Test
    st.subheader("ðŸŽ¯ à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸­à¸­à¹€à¸”à¸­à¸£à¹Œ (Test)")
    test_file = st.file_uploader("à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ Test à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸§à¸²à¸‡à¹à¸œà¸™", type=['xlsx', 'xls'], key='test')
    
    st.markdown("---")
    
    if st.button("ðŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸§à¸²à¸‡à¹à¸œà¸™", type="primary", use_container_width=True):
        if not test_file:
            st.error("âŒ à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Test")
            return
        
        if not dc_files_found:
            st.error("âŒ à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC/ à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC à¹à¸¥à¸°à¸§à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¹„à¸§à¹‰à¹ƒà¸™à¸™à¸±à¹‰à¸™")
            return
        
        with st.spinner("â³ à¸à¸³à¸¥à¸±à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥..."):
            # Load training data à¸ˆà¸²à¸à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC
            tr_dfs = []
            
            st.info(f"ðŸ“‚ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸ˆà¸²à¸à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC/ ({len(dc_files_found)} à¹„à¸Ÿà¸¥à¹Œ)")
            
            for dc_file_path in dc_files_found:
                try:
                    with open(dc_file_path, 'rb') as f:
                        file_content = f.read()
                        train_df = process_dataframe(load_excel(file_content))
                        if train_df is not None:
                            tr_dfs.append(train_df)
                            st.success(f"âœ… {os.path.basename(dc_file_path)}: {len(train_df)} à¸£à¸²à¸¢à¸à¸²à¸£")
                        else:
                            st.warning(f"âš ï¸ {os.path.basename(dc_file_path)}: à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰")
                except Exception as e:
                    st.error(f"âŒ {os.path.basename(dc_file_path)}: {str(e)}")
            
            if not tr_dfs:
                st.error("âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸”à¹† à¸ˆà¸²à¸à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC à¹„à¸”à¹‰")
                return
            
            st.info(f"ðŸ“š à¸£à¸§à¸¡à¹„à¸Ÿà¸¥à¹Œà¹€à¸—à¸£à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {len(tr_dfs)} à¹„à¸Ÿà¸¥à¹Œ")
            
            # Train AI
            G, const, regions = train_ai(tr_dfs)
            st.success(f"ðŸ§  à¹€à¸—à¸£à¸™ AI à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™: {len(regions)} à¸ªà¸²à¸‚à¸²à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ à¸¹à¸¡à¸´à¸ à¸²à¸„")
            
            # Load geo
            geo = {}
            if geo_file:
                geo = process_geo(load_excel(geo_file.read()))
                st.success(f"ðŸ“ à¹‚à¸«à¸¥à¸”à¸žà¸´à¸à¸±à¸”: {len(geo)} à¸ªà¸²à¸‚à¸²")
            
            # Process test data
            df_test = process_dataframe(load_excel(test_file.read()))
            if df_test is None:
                st.error("âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ Test")
                return
            
            st.info(f"ðŸ“¦ à¸­à¸­à¹€à¸”à¸­à¸£à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {len(df_test)} à¸£à¸²à¸¢à¸à¸²à¸£ | à¸ªà¸²à¸‚à¸²à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¹ˆà¸‡: {df_test['Code'].nunique()} à¸ªà¸²à¸‚à¸²")
            
            # Run prediction
            res = run_prediction(df_test, G, geo, const, regions)
            res = res.sort_values(by=['Booking No', 'Lat'])
            
            # Display results
            total_trips = res['Booking No'].nunique()
            trip_summary = res.groupby('Booking No').agg({
                'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²': 'count',
                'TOTALWGT': 'sum',
                'TOTALCUBE': 'sum'
            }).rename(columns={'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²': 'Drops'})
            
            st.markdown("---")
            st.success("### âœ… à¸§à¸²à¸‡à¹à¸œà¸™à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™!")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ðŸšš à¸ˆà¸³à¸™à¸§à¸™à¹€à¸—à¸µà¹ˆà¸¢à¸§", f"{total_trips} à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            with col2:
                st.metric("ðŸ“ à¸ˆà¸¸à¸”à¸ªà¹ˆà¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢", f"{trip_summary['Drops'].mean():.1f} à¸ˆà¸¸à¸”/à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            with col3:
                st.metric("âš–ï¸ à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¹€à¸‰à¸¥à¸µà¹ˆà¸¢", f"{trip_summary['TOTALWGT'].mean():.0f} kg/à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            with col4:
                st.metric("ðŸ“¦ à¸„à¸´à¸§à¹€à¸‰à¸¥à¸µà¹ˆà¸¢", f"{trip_summary['TOTALCUBE'].mean():.2f} cbm/à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            
            # Display dataframe
            st.subheader("ðŸ“‹ à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ")
            st.dataframe(res, use_container_width=True, height=400)
            
            # Export
            output_filename = 'AI_Sticky_Routing_Plan.xlsx'
            export_styled_excel(res, output_filename)
            
            with open(output_filename, 'rb') as f:
                st.download_button(
                    label="ðŸ’¾ à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Excel",
                    data=f,
                    file_name=output_filename,
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    use_container_width=True
                )
            
            st.balloons()

if __name__ == "__main__":
    main()
