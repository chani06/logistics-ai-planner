import streamlit as st
import pandas as pd
import pickle
import json
import os
from datetime import datetime

# ==========================================
# CONFIG
# ==========================================
MODEL_DIR = 'models'
MODEL_PATH = os.path.join(MODEL_DIR, 'trip_pairs.pkl')
MODEL_INFO_PATH = os.path.join(MODEL_DIR, 'model_info.json')

# ==========================================
# FUNCTIONS
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def load_excel_sheet(file_content, sheet_name=None):
    """‡πÇ‡∏´‡∏•‡∏î Excel ‡πÅ‡∏•‡∏∞‡∏´‡∏≤ sheet ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£"""
    try:
        import io
        xls = pd.ExcelFile(io.BytesIO(file_content))
        
        # ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠ sheet
        if sheet_name and sheet_name in xls.sheet_names:
            df = pd.read_excel(xls, sheet_name=sheet_name)
        else:
            # ‡∏´‡∏≤ sheet ‡∏ó‡∏µ‡πà‡∏°‡∏µ "punthai" ‡∏´‡∏£‡∏∑‡∏≠ sheet ‡πÅ‡∏£‡∏Å
            target_sheet = None
            for s in xls.sheet_names:
                if 'punthai' in s.lower() or '2.' in s.lower():
                    target_sheet = s
                    break
            
            if not target_sheet:
                target_sheet = xls.sheet_names[0]
            
            df = pd.read_excel(xls, sheet_name=target_sheet)
        
        return df
    except Exception as e:
        st.error(f"‚ùå Error loading Excel: {e}")
        return None

def process_dataframe(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    if df is None:
        return None
    
    # Rename columns
    rename_map = {}
    for col in df.columns:
        col_upper = str(col).upper().replace(' ', '').replace('_', '')
        if 'BRANCHCODE' in col_upper or '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in col:
            rename_map[col] = 'Code'
        elif 'BRANCH' in col_upper and 'CODE' not in col_upper:
            rename_map[col] = 'Name'
        elif col.strip() == 'Trip':
            rename_map[col] = 'Trip'
        elif 'TRIPNO' in col_upper or col.strip() == 'Trip no':
            rename_map[col] = 'Vehicle'
        elif 'WGT' in col_upper or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col:
            rename_map[col] = 'Wgt'
        elif 'CUBE' in col_upper or '‡∏Ñ‡∏¥‡∏ß' in col:
            rename_map[col] = 'Cube'
    
    df = df.rename(columns=rename_map)
    
    # Normalize Code
    if 'Code' in df.columns:
        df['Code'] = df['Code'].apply(normalize)
    
    return df.reset_index(drop=True)

def learn_trip_patterns(df):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥"""
    if 'Trip' not in df.columns or 'Code' not in df.columns:
        return {}
    
    # ‡πÅ‡∏õ‡∏•‡∏á Trip ‡πÄ‡∏õ‡πá‡∏ô string
    df = df.copy()
    df['Trip'] = df['Trip'].astype(str)
    df = df[df['Trip'].notna() & (df['Trip'] != 'nan') & (df['Trip'] != '')]
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dictionary ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    trip_pairs = {}
    
    for trip_id, group in df.groupby('Trip'):
        codes = sorted(group['Code'].unique())
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ
        for i in range(len(codes)):
            for j in range(i+1, len(codes)):
                pair = tuple(sorted([codes[i], codes[j]]))
                trip_pairs[pair] = trip_pairs.get(pair, 0) + 1
    
    return trip_pairs

def test_accuracy(trip_pairs, test_df):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    if 'Trip' not in test_df.columns:
        return None
    
    test_df = test_df.copy()
    test_df['Trip'] = test_df['Trip'].astype(str)
    test_df = test_df[test_df['Trip'].notna() & (test_df['Trip'] != 'nan') & (test_df['Trip'] != '')]
    
    total_pairs = 0
    matched_pairs = 0
    missing_pairs = []
    
    for trip_id, group in test_df.groupby('Trip'):
        codes = sorted(group['Code'].unique())
        
        if len(codes) < 2:
            continue
        
        for i in range(len(codes)):
            for j in range(i+1, len(codes)):
                total_pairs += 1
                pair = tuple(sorted([codes[i], codes[j]]))
                
                if pair in trip_pairs:
                    matched_pairs += 1
                else:
                    missing_pairs.append((trip_id, codes[i], codes[j]))
    
    accuracy = (matched_pairs / total_pairs * 100) if total_pairs > 0 else 0
    
    return {
        'total_pairs': total_pairs,
        'matched_pairs': matched_pairs,
        'missing_pairs': missing_pairs[:20],
        'accuracy': accuracy
    }

def save_model(trip_pairs, source_files, stats):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå"""
    os.makedirs(MODEL_DIR, exist_ok=True)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(trip_pairs, f)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    model_info = {
        'created_at': datetime.now().isoformat(),
        'source_files': source_files,
        'total_pairs': len(trip_pairs),
        'stats': stats
    }
    
    with open(MODEL_INFO_PATH, 'w', encoding='utf-8') as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)
    
    return model_info

def load_model():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"""
    if not os.path.exists(MODEL_PATH):
        return None, None
    
    try:
        with open(MODEL_PATH, 'rb') as f:
            trip_pairs = pickle.load(f)
        
        with open(MODEL_INFO_PATH, 'r', encoding='utf-8') as f:
            model_info = json.load(f)
        
        return trip_pairs, model_info
    except Exception as e:
        st.error(f"‚ùå Error loading model: {e}")
        return None, None

def predict_trips(df, trip_pairs):
    """‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏ï‡∏≤‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    if 'Code' not in df.columns:
        return None
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Trip ID ‡πÉ‡∏´‡∏°‡πà
    used_codes = set()
    trips = []
    trip_id = 1
    
    df = df.copy()
    df['Code'] = df['Code'].apply(normalize)
    codes = df['Code'].unique().tolist()
    
    while codes:
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å
        seed = codes.pop(0)
        current_trip = [seed]
        used_codes.add(seed)
        
        # ‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        for code in codes[:]:
            pair = tuple(sorted([seed, code]))
            if pair in trip_pairs:
                current_trip.append(code)
                codes.remove(code)
                used_codes.add(code)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏£‡∏¥‡∏õ
        for code in current_trip:
            trips.append({'Code': code, 'Trip': f"AI-{trip_id:03d}"})
        
        trip_id += 1
    
    # ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
    trip_df = pd.DataFrame(trips)
    result = df.merge(trip_df, on='Code', how='left', suffixes=('_old', ''))
    
    return result

# ==========================================
# STREAMLIT UI
# ==========================================
def main():
    st.set_page_config(page_title="üöö Logistics AI Planner", layout="wide")
    st.title("üöö Logistics AI Planner - Simple Model")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_exists = os.path.exists(MODEL_PATH)
    if model_exists:
        trip_pairs, model_info = load_model()
        if model_info:
            st.success(f"‚úÖ ‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß (‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠: {model_info['created_at'][:19]})")
            st.info(f"üìä ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏à‡∏î‡∏à‡∏≥: {model_info['total_pairs']} ‡∏Ñ‡∏π‡πà")
    else:
        st.warning("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    
    st.markdown("---")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Tabs
    tab1, tab2 = st.tabs(["üéØ ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡∏∞‡∏ö‡∏ö", "üéì ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•"])
    
    # ========== TAB 1: ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ==========
    with tab1:
        st.markdown("### üì§ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÉ‡∏´‡∏°‡πà")
        
        test_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel", type=['xlsx'], key='test')
        
        if st.button("üöÄ ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ", type="primary"):
            if not test_file:
                st.error("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå")
            elif not model_exists:
                st.error("‚ùå ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏• - ‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö '‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•' ‡∏Å‡πà‡∏≠‡∏ô")
            else:
                with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
                    trip_pairs, model_info = load_model()
                    
                    # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Test
                    test_content = test_file.read()
                    test_df = load_excel_sheet(test_content)
                    test_df = process_dataframe(test_df)
                    
                    if test_df is not None:
                        # ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
                        result = predict_trips(test_df, trip_pairs)
                        
                        if result is not None:
                            st.success("‚úÖ ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")
                            st.dataframe(result)
                            
                            # Export
                            output = io.BytesIO()
                            result.to_excel(output, index=False)
                            st.download_button(
                                "üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå",
                                data=output.getvalue(),
                                file_name=f"result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            )
    
    # ========== TAB 2: ‡πÄ‡∏ó‡∏£‡∏ô ==========
    with tab2:
        st.markdown("### üéì ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥")
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô DC folder
        dc_files = []
        if os.path.exists('Dc'):
            import glob
            dc_files = glob.glob('Dc/*.xlsx')
        
        if dc_files:
            st.success(f"üìÇ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ {len(dc_files)} ‡πÑ‡∏ü‡∏•‡πå:")
            for f in dc_files:
                st.text(f"  ‚Ä¢ {os.path.basename(f)}")
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Dc/")
        
        # ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏ó‡∏£‡∏ô
        col1, col2 = st.columns([1, 3])
        with col1:
            train_button = st.button("üöÄ ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•", type="primary", use_container_width=True)
        with col2:
            if model_exists:
                if st.button("üóëÔ∏è ‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤", use_container_width=True):
                    if os.path.exists(MODEL_PATH):
                        os.remove(MODEL_PATH)
                    if os.path.exists(MODEL_INFO_PATH):
                        os.remove(MODEL_INFO_PATH)
                    st.success("‚úÖ ‡∏•‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡πâ‡∏ß")
                    st.rerun()
        
        if train_button:
            if not dc_files:
                st.error("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå Dc/")
            else:
                with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•..."):
                    all_pairs = {}
                    source_files = []
                    total_trips = 0
                    
                    # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                    for file_path in dc_files:
                        try:
                            with open(file_path, 'rb') as f:
                                content = f.read()
                            
                            df = load_excel_sheet(content)
                            df = process_dataframe(df)
                            
                            if df is not None and 'Trip' in df.columns:
                                pairs = learn_trip_patterns(df)
                                
                                # ‡∏£‡∏ß‡∏°‡∏Ñ‡∏π‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                                for pair, count in pairs.items():
                                    all_pairs[pair] = all_pairs.get(pair, 0) + count
                                
                                source_files.append(os.path.basename(file_path))
                                total_trips += df['Trip'].nunique()
                                
                                st.text(f"‚úÖ {os.path.basename(file_path)}: {len(pairs)} ‡∏Ñ‡∏π‡πà")
                        except Exception as e:
                            st.error(f"‚ùå Error: {os.path.basename(file_path)}: {e}")
                    
                    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å
                    st.markdown("---")
                    st.markdown("### üéØ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥")
                    
                    with open(dc_files[0], 'rb') as f:
                        test_content = f.read()
                    test_df = load_excel_sheet(test_content)
                    test_df = process_dataframe(test_df)
                    
                    accuracy_result = test_accuracy(all_pairs, test_df)
                    
                    if accuracy_result:
                        acc = accuracy_result['accuracy']
                        
                        if acc >= 95:
                            st.success(f"‚úÖ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {acc:.1f}% - ‡∏¢‡∏≠‡∏î‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°!")
                        elif acc >= 80:
                            st.warning(f"‚ö†Ô∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {acc:.1f}% - ‡∏û‡∏≠‡πÉ‡∏ä‡πâ")
                        else:
                            st.error(f"‚ùå ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {acc:.1f}% - ‡∏ï‡πà‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ")
                        
                        st.metric("‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô", f"{accuracy_result['matched_pairs']}/{accuracy_result['total_pairs']}")
                        
                        if accuracy_result['missing_pairs']:
                            with st.expander("üîç ‡∏î‡∏π‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (20 ‡∏Ñ‡∏π‡πà‡πÅ‡∏£‡∏Å)"):
                                for trip, code1, code2 in accuracy_result['missing_pairs']:
                                    st.text(f"Trip {trip}: {code1} ‚Üî {code2}")
                    
                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
                    stats = {
                        'total_trips': total_trips,
                        'total_files': len(source_files)
                    }
                    
                    model_info = save_model(all_pairs, source_files, stats)
                    
                    st.markdown("---")
                    st.success("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!")
                    st.json(model_info)
                    st.balloons()

if __name__ == "__main__":
    import io
    main()
