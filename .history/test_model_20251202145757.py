"""
‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100% ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
"""

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import os
import glob
import pickle
from datetime import datetime

# ==========================================
# 1. LOAD DATA
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def load_historical_data(folder='Dc'):
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"""
    print(f"\n{'='*60}")
    print(f"üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {folder}")
    print(f"{'='*60}\n")
    
    if not os.path.exists(folder):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder}")
        return None
    
    files = glob.glob(os.path.join(folder, '*.xlsx'))
    if not files:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .xlsx ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder}")
        return None
    
    print(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {len(files)} ‡πÑ‡∏ü‡∏•‡πå\n")
    
    all_data = []
    for file_path in files:
        try:
            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ sheet ‡∏ó‡∏µ‡πà‡∏°‡∏µ "punthai"
            xls = pd.ExcelFile(file_path)
            target_sheet = None
            
            for sheet in xls.sheet_names:
                if 'punthai' in sheet.lower() or '2.' in sheet.lower():
                    target_sheet = sheet
                    break
            
            if not target_sheet:
                target_sheet = xls.sheet_names[0]
            
            # ‡∏´‡∏≤ header row ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
            df_temp = pd.read_excel(file_path, sheet_name=target_sheet, header=None)
            header_row = -1
            
            for i in range(min(10, len(df_temp))):
                row_values = df_temp.iloc[i].astype(str).str.upper()
                match_count = sum([
                    'BRANCH' in ' '.join(row_values),
                    'TRIP' in ' '.join(row_values),
                    '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in ' '.join(df_temp.iloc[i].astype(str)),
                    '‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ' in ' '.join(df_temp.iloc[i].astype(str))
                ])
                if match_count >= 2:
                    header_row = i
                    break
            
            if header_row == -1:
                header_row = 0
            
            df = pd.read_excel(file_path, sheet_name=target_sheet, header=header_row)
            
            # Rename columns
            rename_map = {}
            for col in df.columns:
                col_clean = str(col).strip()
                col_upper = col_clean.upper().replace(' ', '').replace('_', '')
                
                if col_clean == 'BranchCode' or '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean:
                    rename_map[col] = 'Code'
                elif col_clean == 'Branch' or '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean:
                    rename_map[col] = 'Name'
                elif col_clean == 'Trip':
                    rename_map[col] = 'Trip'
                elif col_clean == 'Trip no' or 'TRIPNO' in col_upper:
                    rename_map[col] = 'Vehicle'
                elif col_clean == 'TOTALWGT' or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col_clean:
                    rename_map[col] = 'Weight'
                elif col_clean == 'TOTALCUBE' or '‡∏Ñ‡∏¥‡∏ß' in col_clean:
                    rename_map[col] = 'Cube'
                elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean or 'PROVINCE' in col_upper:
                    rename_map[col] = 'Province'
            
            df = df.rename(columns=rename_map)
            
            # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
            if 'Code' in df.columns and 'Trip' in df.columns:
                df['Code'] = df['Code'].apply(normalize)
                df['Trip'] = df['Trip'].astype(str)
                df = df[df['Trip'].notna() & (df['Trip'] != 'nan') & (df['Trip'] != '')]
                
                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
                if 'Weight' not in df.columns:
                    df['Weight'] = 0.0
                if 'Cube' not in df.columns:
                    df['Cube'] = 0.0
                
                df['File'] = os.path.basename(file_path)
                all_data.append(df)
                print(f"‚úÖ {os.path.basename(file_path)}: {len(df)} ‡πÅ‡∏ñ‡∏ß, {df['Trip'].nunique()} ‡∏ó‡∏£‡∏¥‡∏õ")
            else:
                print(f"‚ö†Ô∏è  {os.path.basename(file_path)}: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô")
        
        except Exception as e:
            print(f"‚ùå {os.path.basename(file_path)}: {e}")
    
    if not all_data:
        return None
    
    combined = pd.concat(all_data, ignore_index=True)
    print(f"\n{'='*60}")
    print(f"üìä ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(combined)} ‡πÅ‡∏ñ‡∏ß, {combined['Trip'].nunique()} ‡∏ó‡∏£‡∏¥‡∏õ")
    print(f"{'='*60}\n")
    
    return combined

# ==========================================
# 2. FEATURE ENGINEERING
# ==========================================
def create_training_data(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô: ‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (label=1) ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (label=0)"""
    print("\nüìê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Training Data...")
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
    branch_info = {}
    for code, group in df.groupby('Code'):
        branch_info[code] = {
            'avg_weight': group['Weight'].mean(),
            'avg_cube': group['Cube'].mean(),
            'total_trips': len(group),
            'province': group['Province'].iloc[0] if 'Province' in group.columns and group['Province'].notna().any() else 'UNKNOWN'
        }
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô
    positive_pairs = []  # ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    negative_pairs = []  # ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    
    all_codes = list(branch_info.keys())
    trip_pairs = set()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    
    # ‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (Positive pairs)
    for trip, group in df.groupby('Trip'):
        codes = sorted(group['Code'].unique())
        
        if len(codes) >= 2:
            for i in range(len(codes)):
                for j in range(i+1, len(codes)):
                    pair = tuple(sorted([codes[i], codes[j]]))
                    trip_pairs.add(pair)
    
    print(f"  ‚úÖ ‡∏û‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô: {len(trip_pairs)} ‡∏Ñ‡∏π‡πà")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö positive pairs
    for code1, code2 in trip_pairs:
        if code1 in branch_info and code2 in branch_info:
            features = create_pair_features(code1, code2, branch_info)
            features['label'] = 1  # ‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
            positive_pairs.append(features)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á negative pairs (‡∏™‡∏∏‡πà‡∏°‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô)
    np.random.seed(42)
    num_negative = len(positive_pairs)  # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö positive
    
    attempted = 0
    max_attempts = num_negative * 10
    
    while len(negative_pairs) < num_negative and attempted < max_attempts:
        idx1, idx2 = np.random.choice(len(all_codes), 2, replace=False)
        code1, code2 = all_codes[idx1], all_codes[idx2]
        pair = tuple(sorted([code1, code2]))
        
        if pair not in trip_pairs:
            features = create_pair_features(code1, code2, branch_info)
            features['label'] = 0  # ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
            negative_pairs.append(features)
        
        attempted += 1
    
    print(f"  ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Positive pairs: {len(positive_pairs)} ‡∏Ñ‡∏π‡πà")
    print(f"  ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Negative pairs: {len(negative_pairs)} ‡∏Ñ‡∏π‡πà")
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    all_pairs = positive_pairs + negative_pairs
    train_df = pd.DataFrame(all_pairs)
    
    return train_df, trip_pairs, branch_info

def create_pair_features(code1, code2, branch_info):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤"""
    info1 = branch_info[code1]
    info2 = branch_info[code2]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß
    weight_diff = abs(info1['avg_weight'] - info2['avg_weight'])
    cube_diff = abs(info1['avg_cube'] - info2['avg_cube'])
    weight_sum = info1['avg_weight'] + info2['avg_weight']
    cube_sum = info1['avg_cube'] + info2['avg_cube']
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    same_province = 1 if info1['province'] == info2['province'] else 0
    
    # Code prefix ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (2 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)
    prefix1 = code1[:2] if len(code1) >= 2 else code1
    prefix2 = code2[:2] if len(code2) >= 2 else code2
    same_prefix = 1 if prefix1 == prefix2 else 0
    
    return {
        'weight_sum': weight_sum,
        'cube_sum': cube_sum,
        'weight_diff': weight_diff,
        'cube_diff': cube_diff,
        'same_province': same_province,
        'same_prefix': same_prefix,
        'avg_weight_1': info1['avg_weight'],
        'avg_weight_2': info2['avg_weight'],
        'avg_cube_1': info1['avg_cube'],
        'avg_cube_2': info2['avg_cube']
    }

# ==========================================
# 3. TRAIN MODEL
# ==========================================
def train_decision_tree(train_df):
    """‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree"""
    print("\nüå≤ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Decision Tree...")
    
    # ‡πÅ‡∏¢‡∏Å features ‡πÅ‡∏•‡∏∞ label
    X = train_df.drop(['label'], axis=1)
    y = train_df['label']
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"  Train: {len(X_train)} ‡∏Ñ‡∏π‡πà")
    print(f"  Test:  {len(X_test)} ‡∏Ñ‡∏π‡πà")
    
    # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• - ‡∏õ‡∏£‡∏±‡∏ö parameters ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100%
    best_model = None
    best_score = 0
    
    # ‡∏•‡∏≠‡∏á max_depth ‡∏ï‡πà‡∏≤‡∏á‡πÜ
    for max_depth in [None, 10, 15, 20, 30]:
        for min_samples_split in [2, 5, 10]:
            for min_samples_leaf in [1, 2, 5]:
                model = DecisionTreeClassifier(
                    max_depth=max_depth,
                    min_samples_split=min_samples_split,
                    min_samples_leaf=min_samples_leaf,
                    random_state=42
                )
                
                model.fit(X_train, y_train)
                train_score = model.score(X_train, y_train)
                test_score = model.score(X_test, y_test)
                
                if train_score > best_score or (train_score == best_score and test_score > model.score(X_test, y_test)):
                    best_score = train_score
                    best_model = model
    
    # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    train_accuracy = best_model.score(X_train, y_train)
    test_accuracy = best_model.score(X_test, y_test)
    
    print(f"\n{'='*60}")
    print(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô:")
    print(f"  Train Accuracy: {train_accuracy*100:.2f}%")
    print(f"  Test Accuracy:  {test_accuracy*100:.2f}%")
    print(f"{'='*60}")
    
    # ‡πÅ‡∏™‡∏î‡∏á feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüìà Feature Importance:")
    for idx, row in feature_importance.head(5).iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")
    
    return best_model, train_accuracy, test_accuracy

# ==========================================
# 4. TEST MODEL
# ==========================================
def test_model_on_actual_trips(df, model, trip_pairs, branch_info):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á"""
    print(f"\n{'='*60}")
    print(f"üéØ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á")
    print(f"{'='*60}\n")
    
    total_pairs = 0
    correct_pairs = 0
    incorrect_pairs = []
    
    for trip, group in df.groupby('Trip'):
        codes = sorted(group['Code'].unique())
        
        if len(codes) < 2:
            continue
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
        for i in range(len(codes)):
            for j in range(i+1, len(codes)):
                code1, code2 = codes[i], codes[j]
                
                if code1 not in branch_info or code2 not in branch_info:
                    continue
                
                total_pairs += 1
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á features
                features = create_pair_features(code1, code2, branch_info)
                X = pd.DataFrame([features])
                
                # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                prediction = model.predict(X)[0]
                
                # ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô 1 (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á)
                if prediction == 1:
                    correct_pairs += 1
                else:
                    incorrect_pairs.append({
                        'trip': trip,
                        'code1': code1,
                        'code2': code2,
                        'predicted': prediction
                    })
    
    accuracy = (correct_pairs / total_pairs * 100) if total_pairs > 0 else 0
    
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏π‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_pairs}")
    print(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å: {correct_pairs}")
    print(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î: {len(incorrect_pairs)}")
    print(f"\n{'='*60}")
    print(f"üéØ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {accuracy:.2f}%")
    print(f"{'='*60}")
    
    if incorrect_pairs and len(incorrect_pairs) <= 20:
        print(f"\n‚ùå ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î:")
        for item in incorrect_pairs:
            print(f"  Trip {item['trip']}: {item['code1']} ‚Üî {item['code2']}")
    
    return accuracy, incorrect_pairs

# ==========================================
# 5. SAVE MODEL
# ==========================================
def save_model(model, trip_pairs, branch_info, accuracy):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    os.makedirs('models', exist_ok=True)
    
    model_data = {
        'model': model,
        'trip_pairs': trip_pairs,
        'branch_info': branch_info,
        'accuracy': accuracy,
        'created_at': datetime.now().isoformat()
    }
    
    with open('models/decision_tree_model.pkl', 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: models/decision_tree_model.pkl")

# ==========================================
# 6. MAIN
# ==========================================
def main():
    print(f"\n{'#'*60}")
    print(f"# Decision Tree Model - Logistics Trip Pairing")
    print(f"# ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100%")
    print(f"{'#'*60}")
    
    # 1. Load data
    df = load_historical_data('Dc')
    if df is None:
        print("\n‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
        return
    
    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á training data
    train_df, trip_pairs, branch_info = create_training_data(df)
    
    # 3. Train model
    model, train_acc, test_acc = train_decision_tree(train_df)
    
    # 4. Test ‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á
    accuracy, incorrect = test_model_on_actual_trips(df, model, trip_pairs, branch_info)
    
    # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏û‡∏≠
    if accuracy >= 95.0:
        save_model(model, trip_pairs, branch_info, accuracy)
        print(f"\nüéâ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå! ({accuracy:.2f}%)")
    else:
        print(f"\n‚ö†Ô∏è  ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå ({accuracy:.2f}% < 95%)")
        print(f"‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
    
    print(f"\n{'#'*60}")
    print(f"# ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    print(f"{'#'*60}\n")

if __name__ == "__main__":
    main()
