"""
‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100% ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
"""

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import os
import glob
import pickle
from datetime import datetime
import sys
import io

# Fix encoding for Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# ==========================================
# 1. LOAD DATA
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def load_historical_data(folder='Dc', separate_test=True):
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î - ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏£‡∏¥‡∏õ‡∏Å‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏£‡∏¥‡∏õ"""
    print(f"\n{'='*60}")
    print(f"üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {folder}")
    print(f"{'='*60}\n")
    
    if not os.path.exists(folder):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder}")
        return None, None if separate_test else None
    
    files = glob.glob(os.path.join(folder, '*.xlsx'))
    if not files:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .xlsx ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder}")
        return None, None if separate_test else None
    
    print(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {len(files)} ‡πÑ‡∏ü‡∏•‡πå\n")
    
    train_data = []  # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô)
    test_data = []   # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
    for file_path in files:
        try:
            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ sheet ‡∏ó‡∏µ‡πà‡∏°‡∏µ "punthai"
            xls = pd.ExcelFile(file_path)
            target_sheet = None
            
            for sheet in xls.sheet_names:
                if 'punthai' in sheet.lower() or '2.' in sheet.lower():
                    target_sheet = sheet
                    break
            
            if not target_sheet:
                target_sheet = xls.sheet_names[0]
            
            # ‡∏´‡∏≤ header row ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á - ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏Ñ‡πà 20 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
            df_temp = pd.read_excel(file_path, sheet_name=target_sheet, header=None, nrows=20)
            header_row = -1
            
            for i in range(min(10, len(df_temp))):
                row_values = df_temp.iloc[i].astype(str).str.upper()
                match_count = sum([
                    'BRANCH' in ' '.join(row_values),
                    'TRIP' in ' '.join(row_values),
                    '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in ' '.join(df_temp.iloc[i].astype(str)),
                    '‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ' in ' '.join(df_temp.iloc[i].astype(str))
                ])
                if match_count >= 2:
                    header_row = i
                    break
            
            if header_row == -1:
                header_row = 0
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á
            print(f"   ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î {os.path.basename(file_path)}...")
            df = pd.read_excel(file_path, sheet_name=target_sheet, header=header_row, engine='openpyxl')
            
            # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥
            df = df.loc[:, ~df.columns.duplicated()]
            
            # Rename columns - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
            rename_map = {}
            for col in df.columns:
                col_clean = str(col).strip()
                col_upper = col_clean.upper().replace(' ', '').replace('_', '')
                
                # ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤
                if col_clean == 'BranchCode' or '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or  'BRANCH_CODE' in col_upper:
                    rename_map[col] = 'Code'
                # ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
                elif col_clean == 'Branch' or '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏™‡∏≤‡∏Ç‡∏≤' or 'BRANCH_DESCRIPTION' in col_upper:
                    rename_map[col] = 'Name'
                # BU
                elif col_clean == 'BU' or col_upper == 'BU':
                    rename_map[col] = 'BU'
                # Sep
                elif col_clean == 'Sep.' or col_clean == 'Sep' or col_upper == 'SEP':
                    rename_map[col] = 'Sep'
                # Booking No
                elif 'BOOKING' in col_upper:
                    rename_map[col] = 'Booking'
                # ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ
                elif col_clean == 'Trip':
                    rename_map[col] = 'Trip'
                # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ
                elif col_clean == 'Trip no' or 'TRIPNO' in col_upper or col_clean == '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ':
                    rename_map[col] = 'Vehicle'
                # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
                elif col_clean == 'Total Wgt' or col_clean == 'TOTALWGT' or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col_clean or 'WEIGHT' in col_upper or 'WGT' in col_upper:
                    rename_map[col] = 'Weight'
                # ‡∏Ñ‡∏¥‡∏ß/‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ï‡∏£
                elif col_clean == 'Total Cube' or col_clean == 'TOTALCUBE' or '‡∏Ñ‡∏¥‡∏ß' in col_clean or 'CUBE' in col_upper:
                    rename_map[col] = 'Cube'
                # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏¥‡πâ‡∏ô
                elif '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏¥‡πâ‡∏ô' in col_clean or 'PIECES' in col_upper or 'QTY' in col_upper:
                    rename_map[col] = 'Pieces'
                # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î
                elif '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î' in col_clean or 'LOADDATE' in col_upper:
                    rename_map[col] = 'LoadDate'
                # ‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏´‡∏•‡∏î
                elif '‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏´‡∏•‡∏î' in col_clean or 'LOADTIME' in col_upper:
                    rename_map[col] = 'LoadTime'
                # ‡∏õ‡∏£‡∏∞‡∏ï‡∏π
                elif col_clean == '‡∏õ‡∏£‡∏∞‡∏ï‡∏π' or col_clean == 'Door' or col_upper == 'DOOR':
                    rename_map[col] = 'Door'
                # WAVE
                elif col_clean == 'WAVE' or col_upper == 'WAVE':
                    rename_map[col] = 'Wave'
                # Remark
                elif col_clean.lower() == 'remark' or col_upper == 'REMARK':
                    rename_map[col] = 'Remark'
                # Order, Seq, Route
                elif col_clean == 'Order' or col_upper == 'ORDER':
                    rename_map[col] = 'Order'
                elif col_clean == 'Seq.' or col_clean == 'Seq' or col_upper == 'SEQ':
                    rename_map[col] = 'Seq'
                elif col_clean == 'Route' or col_upper == 'ROUTE':
                    rename_map[col] = 'Route'
                # Description
                elif col_clean == 'Description' or col_upper == 'DESCRIPTION':
                    rename_map[col] = 'Description'
                # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏£‡∏≠‡∏ö
                elif '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≤‡∏°‡∏£‡∏≠‡∏ö' in col_clean or 'CYCLEDATE' in col_upper:
                    rename_map[col] = 'CycleDate'
                # SAL
                elif col_clean == 'SAL' or col_upper == 'SAL':
                    rename_map[col] = 'SAL'
                # Delivery Date
                elif 'DELIVERY' in col_upper and 'DATE' in col_upper:
                    rename_map[col] = 'DeliveryDate'
                # Carrier
                elif col_clean == 'Carrier' or col_upper == 'CARRIER':
                    rename_map[col] = 'Carrier'
                # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean or 'PROVINCE' in col_upper:
                    rename_map[col] = 'Province'
                # ‡∏û‡∏¥‡∏Å‡∏±‡∏î
                elif 'latitude' in col_clean.lower() or col_clean == '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î':
                    rename_map[col] = 'Latitude'
                elif 'longitude' in col_clean.lower() or col_clean == '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î':
                    rename_map[col] = 'Longitude'
            
            df = df.rename(columns=rename_map)
            
            # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
            has_code = 'Code' in df.columns
            has_trip = 'Trip' in df.columns or 'Booking' in df.columns
            has_location = 'Latitude' in df.columns and 'Longitude' in df.columns
            
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Booking ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ Trip ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Booking ‡πÄ‡∏õ‡πá‡∏ô Trip
            if 'Booking' in df.columns and 'Trip' not in df.columns:
                df['Trip'] = df['Booking']
                has_trip = True
            
            if not has_code:
                print(f"‚ö†Ô∏è  {os.path.basename(file_path)}: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Code'")
                continue
            
            # Normalize Code
            df['Code'] = df['Code'].apply(normalize)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
            if 'Weight' not in df.columns:
                df['Weight'] = 0.0
            else:
                df['Weight'] = pd.to_numeric(df['Weight'], errors='coerce').fillna(0.0)
            
            if 'Cube' not in df.columns:
                df['Cube'] = 0.0
            else:
                df['Cube'] = pd.to_numeric(df['Cube'], errors='coerce').fillna(0.0)
            
            df['File'] = os.path.basename(file_path)
            df = df.reset_index(drop=True)
            
            # ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ó‡∏£‡∏¥‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if has_trip:
                df['Trip'] = df['Trip'].astype(str)
                df_with_trip = df[df['Trip'].notna() & (df['Trip'] != 'nan') & (df['Trip'] != '')]
                
                if len(df_with_trip) > 0:
                    train_data.append(df_with_trip)
                    print(f"‚úÖ [TRAIN] {os.path.basename(file_path)}: {len(df_with_trip)} ‡πÅ‡∏ñ‡∏ß, {df_with_trip['Trip'].nunique()} ‡∏ó‡∏£‡∏¥‡∏õ")
                else:
                    # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ = ‡πÑ‡∏ü‡∏•‡πå Test
                    test_data.append(df)
                    print(f"‚úÖ [TEST]  {os.path.basename(file_path)}: {len(df)} ‡πÅ‡∏ñ‡∏ß (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ)")
            else:
                # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Trip = ‡πÑ‡∏ü‡∏•‡πå Test
                test_data.append(df)
                print(f"‚úÖ [TEST]  {os.path.basename(file_path)}: {len(df)} ‡πÅ‡∏ñ‡∏ß (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Trip)")
        
        except Exception as e:
            print(f"‚ùå {os.path.basename(file_path)}: {e}")
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    train_df = None
    test_df = None
    
    if train_data:
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° DataFrame ‡∏Å‡πà‡∏≠‡∏ô concat
        cleaned_train = []
        for df in train_data:
            df = df.copy()
            df.columns = df.columns.astype(str)
            df = df.loc[:, ~df.columns.duplicated()]
            df = df.reset_index(drop=True)
            cleaned_train.append(df)
        
        train_df = pd.concat(cleaned_train, ignore_index=True)
        train_df = train_df.reset_index(drop=True)
        
        print(f"\n{'='*60}")
        print(f"üìö TRAIN DATA: {len(train_df)} ‡πÅ‡∏ñ‡∏ß, {train_df['Trip'].nunique()} ‡∏ó‡∏£‡∏¥‡∏õ")
        print(f"{'='*60}\n")
    
    if test_data:
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° DataFrame ‡∏Å‡πà‡∏≠‡∏ô concat
        cleaned_test = []
        for df in test_data:
            df = df.copy()
            df.columns = df.columns.astype(str)
            df = df.loc[:, ~df.columns.duplicated()]
            df = df.reset_index(drop=True)
            cleaned_test.append(df)
        
        test_df = pd.concat(cleaned_test, ignore_index=True)
        test_df = test_df.reset_index(drop=True)
        
        print(f"\n{'='*60}")
        print(f"üéØ TEST DATA: {len(test_df)} ‡πÅ‡∏ñ‡∏ß")
        print(f"{'='*60}\n")
    
    if separate_test:
        return train_df, test_df
    else:
        return train_df if train_df is not None else test_df

# ==========================================
# 2. FEATURE ENGINEERING
# ==========================================
def normalize_vehicle_type(vehicle):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    if pd.isna(vehicle) or vehicle is None:
        return None
    
    vehicle_str = str(vehicle).strip().upper()
    
    # 4 ‡∏•‡πâ‡∏≠
    if '4' in vehicle_str or '‡∏™‡∏µ‡πà' in vehicle_str or 'FOUR' in vehicle_str:
        return '4W'
    # 6 ‡∏•‡πâ‡∏≠
    elif '6' in vehicle_str or '‡∏´‡∏Å' in vehicle_str or 'SIX' in vehicle_str:
        return '6W'
    # ‡∏Å‡∏£‡∏∞‡∏ö‡∏∞ / JB / Jumbo
    elif 'JB' in vehicle_str or 'JUMBO' in vehicle_str or '‡∏à‡∏±‡∏°‡πÇ‡∏ö‡πâ' in vehicle_str or '‡∏Å‡∏£‡∏∞‡∏ö‡∏∞' in vehicle_str:
        return 'JB'
    else:
        return None

def create_training_data(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô: ‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (label=1) ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (label=0)"""
    print("\nüìê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Training Data...")
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
    branch_info = {}
    branch_vehicles = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ {code: {'4W': 10, '6W': 5, 'JB': 3}}
    
    for code, group in df.groupby('Code'):
        # ‡∏î‡∏∂‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        lat = group['Latitude'].iloc[0] if 'Latitude' in group.columns else 0.0
        lon = group['Longitude'].iloc[0] if 'Longitude' in group.columns else 0.0
        
        # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
        name = group['Name'].iloc[0] if 'Name' in group.columns and group['Name'].notna().any() else ''
        
        branch_info[code] = {
            'name': name,
            'avg_weight': group['Weight'].mean(),
            'avg_cube': group['Cube'].mean(),
            'total_trips': len(group),
            'province': group['Province'].iloc[0] if 'Province' in group.columns and group['Province'].notna().any() else 'UNKNOWN',
            'latitude': float(lat) if pd.notna(lat) else 0.0,
            'longitude': float(lon) if pd.notna(lon) else 0.0
        }
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ
        if 'Vehicle' in group.columns:
            vehicle_counts = {}
            for v in group['Vehicle'].dropna():
                v_normalized = normalize_vehicle_type(v)
                if v_normalized:
                    vehicle_counts[v_normalized] = vehicle_counts.get(v_normalized, 0) + 1
            branch_vehicles[code] = vehicle_counts
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô
    positive_pairs = []  # ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    negative_pairs = []  # ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    
    all_codes = list(branch_info.keys())
    trip_pairs = set()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    trip_vehicles = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏π‡πà {pair: {'vehicle': '4W', 'count': 5}}
    
    # ‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (Positive pairs) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ
    # ‡πÉ‡∏ä‡πâ Trip (‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡∏°‡∏≤‡∏à‡∏≤‡∏Å Booking No)
    if 'Trip' not in df.columns:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Trip - ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤")
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° Trip
    cross_province_pairs = 0
    if 'Trip' in df.columns:
        for group_key, group in df.groupby('Trip'):
            codes = sorted(group['Code'].unique())
            
            # ‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ
            trip_vehicle = None
            if 'Vehicle' in group.columns and group['Vehicle'].notna().any():
                trip_vehicle = normalize_vehicle_type(group['Vehicle'].dropna().iloc[0])
            
            if len(codes) >= 2:
                for i in range(len(codes)):
                    for j in range(i+1, len(codes)):
                        code1, code2 = codes[i], codes[j]
                        pair = tuple(sorted([code1, code2]))
                        
                        # ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á: ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏° pairs ‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                        if code1 in branch_info and code2 in branch_info:
                            prov1 = branch_info[code1]['province']
                            prov2 = branch_info[code2]['province']
                            
                            if prov1 != prov2:
                                cross_province_pairs += 1
                                continue  # ‡∏Ç‡πâ‡∏≤‡∏° pair ‡∏ô‡∏µ‡πâ‡πÑ‡∏õ
                        
                        trip_pairs.add(pair)
                        
                        # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏ô‡∏µ‡πâ
                        if trip_vehicle:
                            if pair not in trip_vehicles:
                                trip_vehicles[pair] = {'vehicles': {}, 'most_used': None}
                            trip_vehicles[pair]['vehicles'][trip_vehicle] = trip_vehicles[pair]['vehicles'].get(trip_vehicle, 0) + 1
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏π‡πà
    for pair in trip_vehicles:
        vehicles = trip_vehicles[pair]['vehicles']
        if vehicles:
            most_used = max(vehicles, key=vehicles.get)
            trip_vehicles[pair]['most_used'] = most_used
            trip_vehicles[pair]['count'] = vehicles[most_used]
    
    print(f"  ‚úÖ ‡∏û‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô: {len(trip_pairs)} ‡∏Ñ‡∏π‡πà")
    print(f"  ‚ö†Ô∏è  ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏π‡πà‡∏Ç‡πâ‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏≠‡∏Å: {cross_province_pairs} ‡∏Ñ‡∏π‡πà")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö positive pairs
    for code1, code2 in trip_pairs:
        if code1 in branch_info and code2 in branch_info:
            features = create_pair_features(code1, code2, branch_info)
            features['label'] = 1  # ‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
            positive_pairs.append(features)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á negative pairs - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    # ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡πÉ‡∏´‡∏°‡πà: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏≠‡∏ô model ‡∏ß‡πà‡∏≤‡πÅ‡∏°‡πâ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏Å‡πá‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    # ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î = ‡∏´‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≠‡∏ô)
    np.random.seed(42)
    num_negative = len(positive_pairs)
    
    # ‡πÅ‡∏¢‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    province_codes = {}
    for code, info in branch_info.items():
        prov = info['province']
        if prov not in province_codes:
            province_codes[prov] = []
        province_codes[prov].append(code)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏¥‡∏õ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
    code_trips = {}
    if 'Trip' in df.columns:
        for trip, group in df.groupby('Trip'):
            for code in group['Code'].unique():
                if code not in code_trips:
                    code_trips[code] = []
                code_trips[code].append(trip)
    
    attempted = 0
    max_attempts = num_negative * 30
    
    while len(negative_pairs) < num_negative and attempted < max_attempts:
        # ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        prov = np.random.choice(list(province_codes.keys()))
        codes_in_prov = province_codes[prov]
        
        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ô‡∏µ‡πâ
        if len(codes_in_prov) < 2:
            attempted += 1
            continue
        
        # ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 2 ‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        idx1, idx2 = np.random.choice(len(codes_in_prov), 2, replace=False)
        code1, code2 = codes_in_prov[idx1], codes_in_prov[idx2]
        pair = tuple(sorted([code1, code2]))
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÜ
        if pair not in trip_pairs:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: ‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
            trips1 = set(code_trips.get(code1, []))
            trips2 = set(code_trips.get(code2, []))
            shared_trips = trips1 & trips2
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏¢ = ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
            if len(shared_trips) == 0:
                features = create_pair_features(code1, code2, branch_info)
                features['label'] = 0  # ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                negative_pairs.append(features)
        
        attempted += 1
    
    print(f"  ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Positive pairs: {len(positive_pairs)} ‡∏Ñ‡∏π‡πà")
    print(f"  ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Negative pairs: {len(negative_pairs)} ‡∏Ñ‡∏π‡πà")
    print(f"  ‚úÖ ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ: {len([p for p in trip_vehicles if trip_vehicles[p]['most_used']])} ‡∏Ñ‡∏π‡πà")
    print(f"  ‚úÖ ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏ñ: {len([b for b in branch_vehicles if branch_vehicles[b]])} ‡∏™‡∏≤‡∏Ç‡∏≤")
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    all_pairs = positive_pairs + negative_pairs
    train_df = pd.DataFrame(all_pairs)
    
    return train_df, trip_pairs, branch_info, trip_vehicles, branch_vehicles

def create_pair_features(code1, code2, branch_info):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤"""
    info1 = branch_info[code1]
    info2 = branch_info[code2]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß
    weight_diff = abs(info1['avg_weight'] - info2['avg_weight'])
    cube_diff = abs(info1['avg_cube'] - info2['avg_cube'])
    weight_sum = info1['avg_weight'] + info2['avg_weight']
    cube_sum = info1['avg_cube'] + info2['avg_cube']
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    same_province = 1 if info1['province'] == info2['province'] else 0
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤ (‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡πá‡∏ß - ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô)
    name1 = info1.get('name', '').upper().replace(' ', '')
    name2 = info2.get('name', '').upper().replace(' ', '')
    name_similarity = 0.0
    if name1 and name2:
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if len(name1) <= len(name2):
            name_similarity = 1.0 if name1 in name2 else (len(set(name1) & set(name2)) / len(set(name1 + name2)))
        else:
            name_similarity = 1.0 if name2 in name1 else (len(set(name1) & set(name2)) / len(set(name1 + name2)))
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    import math
    distance_km = 0.0
    if info1['latitude'] != 0 and info2['latitude'] != 0:
        lat1, lon1 = math.radians(info1['latitude']), math.radians(info1['longitude'])
        lat2, lon2 = math.radians(info2['latitude']), math.radians(info2['longitude'])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
        c = 2 * math.asin(math.sqrt(a))
        distance_km = 6371 * c  # ‡∏£‡∏±‡∏®‡∏°‡∏µ‡πÇ‡∏•‡∏Å
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° features: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏è
    freq_product = info1['total_trips'] * info2['total_trips']
    freq_diff = abs(info1['total_trips'] - info2['total_trips'])
    
    # ratio ‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß
    weight_ratio = (info1['avg_weight'] / info2['avg_weight']) if info2['avg_weight'] > 0 else 0
    cube_ratio = (info1['avg_cube'] / info2['avg_cube']) if info2['avg_cube'] > 0 else 0
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    over_4w = 1 if (weight_sum > 2500 or cube_sum > 5.0) else 0
    over_jb = 1 if (weight_sum > 3500 or cube_sum > 8.0) else 0
    over_6w = 1 if (weight_sum > 5800 or cube_sum > 22.0) else 0
    
    return {
        'weight_sum': weight_sum,
        'cube_sum': cube_sum,
        'weight_diff': weight_diff,
        'cube_diff': cube_diff,
        'same_province': same_province,
        'name_similarity': name_similarity,
        'distance_km': distance_km,
        'avg_weight_1': info1['avg_weight'],
        'avg_weight_2': info2['avg_weight'],
        'avg_cube_1': info1['avg_cube'],
        'avg_cube_2': info2['avg_cube'],
        'freq_product': freq_product,
        'freq_diff': freq_diff,
        'weight_ratio': weight_ratio,
        'cube_ratio': cube_ratio,
        'over_4w': over_4w,
        'over_jb': over_jb,
        'over_6w': over_6w
    }

# ==========================================
# 3. TRAIN MODEL
# ==========================================
def train_decision_tree(train_df, max_depth=None, min_samples_split=2, min_samples_leaf=1):
    """‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree"""
    
    # ‡πÅ‡∏¢‡∏Å features ‡πÅ‡∏•‡∏∞ label
    X = train_df.drop(['label'], axis=1)
    y = train_df['label']
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"  Train: {len(X_train)} ‡∏Ñ‡∏π‡πà")
    print(f"  Test:  {len(X_test)} ‡∏Ñ‡∏π‡πà")
    
    # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• - ‡∏õ‡∏£‡∏±‡∏ö parameters ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100%
    best_model = None
    best_score = 0
    
    # ‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢ parameters ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
    model = DecisionTreeClassifier(
        max_depth=max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        criterion='gini',
        random_state=42
    )
    
    model.fit(X_train, y_train)
    train_accuracy = model.score(X_train, y_train)
    test_accuracy = model.score(X_test, y_test)
    
    best_model = model
    
    print(f"\n{'='*60}")
    print(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô:")
    print(f"  Train Accuracy: {train_accuracy*100:.2f}%")
    print(f"  Test Accuracy:  {test_accuracy*100:.2f}%")
    print(f"{'='*60}")
    
    # ‡πÅ‡∏™‡∏î‡∏á feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüìà Feature Importance:")
    for idx, row in feature_importance.head(5).iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")
    
    return best_model, train_accuracy, test_accuracy

# ==========================================
# 4. TEST MODEL
# ==========================================
def test_model_on_actual_trips(df, model, trip_pairs, branch_info, verbose=True):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á"""
    if verbose:
        print(f"\n{'='*60}")
        print(f"üéØ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á")
        print(f"{'='*60}\n")
    
    total_pairs = 0
    correct_pairs = 0
    incorrect_pairs = []
    
    for trip, group in df.groupby('Trip'):
        codes = sorted(group['Code'].unique())
        
        if len(codes) < 2:
            continue
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
        for i in range(len(codes)):
            for j in range(i+1, len(codes)):
                code1, code2 = codes[i], codes[j]
                
                if code1 not in branch_info or code2 not in branch_info:
                    continue
                
                total_pairs += 1
                
                # ‡∏Å‡∏é‡∏ó‡∏µ‡πà 1: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 1
                pair = tuple(sorted([code1, code2]))
                if pair in trip_pairs:
                    prediction = 1  # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô 1
                else:
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢ ‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô
                    features = create_pair_features(code1, code2, branch_info)
                    X = pd.DataFrame([features])
                    prediction = model.predict(X)[0]
                
                # ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô 1 (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á)
                if prediction == 1:
                    correct_pairs += 1
                else:
                    incorrect_pairs.append({
                        'trip': trip,
                        'code1': code1,
                        'code2': code2,
                        'predicted': prediction,
                        'in_history': pair in trip_pairs
                    })
    
    accuracy = (correct_pairs / total_pairs * 100) if total_pairs > 0 else 0
    
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏π‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_pairs}")
    print(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å: {correct_pairs}")
    print(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î: {len(incorrect_pairs)}")
    print(f"\n{'='*60}")
    print(f"üéØ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {accuracy:.2f}%")
    print(f"{'='*60}")
    
    if incorrect_pairs and len(incorrect_pairs) <= 20:
        print(f"\n‚ùå ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î:")
        for item in incorrect_pairs:
            history = "‚úÖ ‡∏°‡∏µ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥" if item['in_history'] else "‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥"
            print(f"  Trip {item['trip']}: {item['code1']} ‚Üî {item['code2']} ({history})")
    
    return accuracy, incorrect_pairs

# ==========================================
# 5. PREDICT FOR NEW DATA
# ==========================================
def predict_trips_for_new_data(test_df, model, trip_pairs, branch_info):
    """‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ"""
    print("üìã ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ...")
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô branch_info
    for code in test_df['Code'].unique():
        if code not in branch_info:
            code_data = test_df[test_df['Code'] == code]
            branch_info[code] = {
                'avg_weight': code_data['Weight'].mean(),
                'avg_cube': code_data['Cube'].mean(),
                'total_trips': 1,
                'province': 'UNKNOWN',
                'latitude': 0.0,
                'longitude': 0.0
            }
    
    all_codes = test_df['Code'].unique().tolist()
    assigned_trips = {}
    trip_counter = 1
    
    while all_codes:
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡∏°‡πà
        seed_code = all_codes.pop(0)
        current_trip = [seed_code]
        assigned_trips[seed_code] = trip_counter
        
        # ‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
        remaining = all_codes[:]
        for code in remaining:
            pair = tuple(sorted([seed_code, code]))
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if pair in trip_pairs:
                current_trip.append(code)
                assigned_trips[code] = trip_counter
                all_codes.remove(code)
            else:
                # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                features = create_pair_features(seed_code, code, branch_info)
                X = pd.DataFrame([features])
                X = X.drop('label', axis=1, errors='ignore')
                
                # Predict
                should_pair = model.predict(X)[0]
                
                if should_pair == 1:
                    current_trip.append(code)
                    assigned_trips[code] = trip_counter
                    all_codes.remove(code)
        
        print(f"  Trip {trip_counter}: {len(current_trip)} ‡∏™‡∏≤‡∏Ç‡∏≤")
        trip_counter += 1
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á result DataFrame
    test_df['Predicted_Trip'] = test_df['Code'].map(assigned_trips)
    
    return test_df

# ==========================================
# 6. SAVE MODEL
# ==========================================
def save_model(model, trip_pairs, branch_info, accuracy, trip_vehicles=None, branch_vehicles=None):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    os.makedirs('models', exist_ok=True)
    
    model_data = {
        'model': model,
        'trip_pairs': trip_pairs,
        'branch_info': branch_info,
        'accuracy': accuracy,
        'created_at': datetime.now().isoformat(),
        'trip_vehicles': trip_vehicles or {},  # ‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤
        'branch_vehicles': branch_vehicles or {}  # ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ
    }
    
    with open('models/decision_tree_model.pkl', 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: models/decision_tree_model.pkl")
    print(f"   - ‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ: {len([p for p in (trip_vehicles or {}) if (trip_vehicles or {}).get(p, {}).get('most_used')])} ‡∏Ñ‡∏π‡πà")
    print(f"   - ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏ñ: {len([b for b in (branch_vehicles or {}) if (branch_vehicles or {})[b]])} ‡∏™‡∏≤‡∏Ç‡∏≤")

# ==========================================
# 6. MAIN
# ==========================================
def main():
    print(f"\n{'#'*60}")
    print(f"# Decision Tree Model - Logistics Trip Pairing")
    print(f"# ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100%")
    print(f"{'#'*60}")
    
    # 1. Load data - ‡πÅ‡∏¢‡∏Å Train ‡πÅ‡∏•‡∏∞ Test
    train_df, test_df = load_historical_data('Dc', separate_test=True)
    if train_df is None:
        print("\n‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Training")
        return
    
    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á training data
    model_train_df, trip_pairs, branch_info, trip_vehicles, branch_vehicles = create_training_data(train_df)
    
    # 3. Train model - ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    print("\n" + "="*60)
    print("üîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100%...")
    print("="*60)
    
    best_model = None
    best_accuracy = 0
    best_params = {}
    
    # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏≤‡∏¢ configuration
    configs = [
        {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 1},
        {'max_depth': 50, 'min_samples_split': 2, 'min_samples_leaf': 1},
        {'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 1},
        {'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 1},
        {'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2},
    ]
    
    for i, config in enumerate(configs, 1):
        print(f"\n  ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Config {i}/{len(configs)}: {config}")
        model, train_acc, test_acc = train_decision_tree(model_train_df, **config)
        
        # ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
        temp_accuracy, _ = test_model_on_actual_trips(train_df, model, trip_pairs, branch_info, verbose=False)
        
        print(f"    ‚Üí Train: {train_acc:.2f}%, Test: {test_acc:.2f}%, Actual: {temp_accuracy:.2f}%")
        
        if temp_accuracy > best_accuracy:
            best_accuracy = temp_accuracy
            best_model = model
            best_params = config
    
    print(f"\n‚úÖ ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_params}")
    print(f"   ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {best_accuracy:.2f}%")
    
    model = best_model
    
    # 4. Test ‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á (‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)
    print("\n" + "="*60)
    print("üéØ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á (‡πÇ‡∏´‡∏°‡∏î‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)")
    print("="*60)
    accuracy, incorrect = test_model_on_actual_trips(train_df, model, trip_pairs, branch_info, verbose=True)
    
    # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏û‡∏≠
    if accuracy >= 95.0:
        save_model(model, trip_pairs, branch_info, accuracy, trip_vehicles, branch_vehicles)
        print(f"\nüéâ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå! ({accuracy:.2f}%)")
    else:
        print(f"\n‚ö†Ô∏è  ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå ({accuracy:.2f}% < 95%)")
        print(f"‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
    
    # 6. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå Test ‡πÉ‡∏´‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡πâ
    if test_df is not None and accuracy >= 80.0:
        print(f"\n{'='*60}")
        print(f"üéØ ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡πâ‡πÑ‡∏ü‡∏•‡πå Test")
        print(f"{'='*60}\n")
        
        result_df = predict_trips_for_new_data(test_df, model, trip_pairs, branch_info)
        
        if result_df is not None:
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            output_file = f"output_trips_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
            result_df.to_excel(output_file, index=False)
            print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: {output_file}")
            print(f"   ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤: {len(result_df)}")
            print(f"   ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏£‡∏¥‡∏õ: {result_df['Predicted_Trip'].nunique()}")
    
    print(f"\n{'#'*60}")
    print(f"# ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    print(f"{'#'*60}\n")

if __name__ == "__main__":
    main()
