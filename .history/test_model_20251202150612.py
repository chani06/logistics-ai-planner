"""
‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100% ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
"""

import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import os
import glob
import pickle
from datetime import datetime

# ==========================================
# 1. LOAD DATA
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def load_historical_data(folder='Dc', separate_test=True):
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î - ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏£‡∏¥‡∏õ‡∏Å‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏£‡∏¥‡∏õ"""
    print(f"\n{'='*60}")
    print(f"üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {folder}")
    print(f"{'='*60}\n")
    
    if not os.path.exists(folder):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder}")
        return None, None if separate_test else None
    
    files = glob.glob(os.path.join(folder, '*.xlsx'))
    if not files:
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .xlsx ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå {folder}")
        return None, None if separate_test else None
    
    print(f"‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå: {len(files)} ‡πÑ‡∏ü‡∏•‡πå\n")
    
    train_data = []  # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô)
    test_data = []   # ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
    for file_path in files:
        try:
            # ‡∏•‡∏≠‡∏á‡∏´‡∏≤ sheet ‡∏ó‡∏µ‡πà‡∏°‡∏µ "punthai"
            xls = pd.ExcelFile(file_path)
            target_sheet = None
            
            for sheet in xls.sheet_names:
                if 'punthai' in sheet.lower() or '2.' in sheet.lower():
                    target_sheet = sheet
                    break
            
            if not target_sheet:
                target_sheet = xls.sheet_names[0]
            
            # ‡∏´‡∏≤ header row ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
            df_temp = pd.read_excel(file_path, sheet_name=target_sheet, header=None)
            header_row = -1
            
            for i in range(min(10, len(df_temp))):
                row_values = df_temp.iloc[i].astype(str).str.upper()
                match_count = sum([
                    'BRANCH' in ' '.join(row_values),
                    'TRIP' in ' '.join(row_values),
                    '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in ' '.join(df_temp.iloc[i].astype(str)),
                    '‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ' in ' '.join(df_temp.iloc[i].astype(str))
                ])
                if match_count >= 2:
                    header_row = i
                    break
            
            if header_row == -1:
                header_row = 0
            
            df = pd.read_excel(file_path, sheet_name=target_sheet, header=header_row)
            
            # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥
            df = df.loc[:, ~df.columns.duplicated()]
            
            # Rename columns - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
            rename_map = {}
            for col in df.columns:
                col_clean = str(col).strip()
                col_upper = col_clean.upper().replace(' ', '').replace('_', '')
                
                # ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤
                if col_clean == 'BranchCode' or '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏£‡∏´‡∏±‡∏™ WMS' or 'BRANCH_CODE' in col_upper:
                    rename_map[col] = 'Code'
                # ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
                elif col_clean == 'Branch' or '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏™‡∏≤‡∏Ç‡∏≤' or 'BRANCH_DESCRIPTION' in col_upper:
                    rename_map[col] = 'Name'
                # ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ
                elif col_clean == 'Trip' or col_clean == 'Booking No':
                    rename_map[col] = 'Trip'
                # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ
                elif col_clean == 'Trip no' or 'TRIPNO' in col_upper or col_clean == '‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ':
                    rename_map[col] = 'Vehicle'
                # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
                elif col_clean == 'TOTALWGT' or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col_clean or 'WEIGHT' in col_upper:
                    rename_map[col] = 'Weight'
                # ‡∏Ñ‡∏¥‡∏ß/‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ï‡∏£
                elif col_clean == 'TOTALCUBE' or '‡∏Ñ‡∏¥‡∏ß' in col_clean or 'CUBE' in col_upper:
                    rename_map[col] = 'Cube'
                # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean or 'PROVINCE' in col_upper:
                    rename_map[col] = 'Province'
                # ‡∏û‡∏¥‡∏Å‡∏±‡∏î
                elif 'latitude' in col_clean.lower() or col_clean == '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î':
                    rename_map[col] = 'Latitude'
                elif 'longitude' in col_clean.lower() or col_clean == '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î':
                    rename_map[col] = 'Longitude'
            
            df = df.rename(columns=rename_map)
            
            # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
            has_code = 'Code' in df.columns
            has_trip = 'Trip' in df.columns
            has_location = 'Latitude' in df.columns and 'Longitude' in df.columns
            
            if not has_code:
                print(f"‚ö†Ô∏è  {os.path.basename(file_path)}: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'Code'")
                continue
            
            # Normalize Code
            df['Code'] = df['Code'].apply(normalize)
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
            if 'Weight' not in df.columns:
                df['Weight'] = 0.0
            else:
                df['Weight'] = pd.to_numeric(df['Weight'], errors='coerce').fillna(0.0)
            
            if 'Cube' not in df.columns:
                df['Cube'] = 0.0
            else:
                df['Cube'] = pd.to_numeric(df['Cube'], errors='coerce').fillna(0.0)
            
            df['File'] = os.path.basename(file_path)
            df = df.reset_index(drop=True)
            
            # ‡πÅ‡∏¢‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ó‡∏£‡∏¥‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if has_trip:
                df['Trip'] = df['Trip'].astype(str)
                df_with_trip = df[df['Trip'].notna() & (df['Trip'] != 'nan') & (df['Trip'] != '')]
                
                if len(df_with_trip) > 0:
                    train_data.append(df_with_trip)
                    print(f"‚úÖ [TRAIN] {os.path.basename(file_path)}: {len(df_with_trip)} ‡πÅ‡∏ñ‡∏ß, {df_with_trip['Trip'].nunique()} ‡∏ó‡∏£‡∏¥‡∏õ")
                else:
                    # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ = ‡πÑ‡∏ü‡∏•‡πå Test
                    test_data.append(df)
                    print(f"‚úÖ [TEST]  {os.path.basename(file_path)}: {len(df)} ‡πÅ‡∏ñ‡∏ß (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏Ç‡∏ó‡∏£‡∏¥‡∏õ)")
            else:
                # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Trip = ‡πÑ‡∏ü‡∏•‡πå Test
                test_data.append(df)
                print(f"‚úÖ [TEST]  {os.path.basename(file_path)}: {len(df)} ‡πÅ‡∏ñ‡∏ß (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Trip)")
        
        except Exception as e:
            print(f"‚ùå {os.path.basename(file_path)}: {e}")
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    train_df = None
    test_df = None
    
    if train_data:
        train_df = pd.concat(train_data, ignore_index=True)
        print(f"\n{'='*60}")
        print(f"üìö TRAIN DATA: {len(train_df)} ‡πÅ‡∏ñ‡∏ß, {train_df['Trip'].nunique()} ‡∏ó‡∏£‡∏¥‡∏õ")
        print(f"{'='*60}\n")
    
    if test_data:
        test_df = pd.concat(test_data, ignore_index=True)
        print(f"\n{'='*60}")
        print(f"üéØ TEST DATA: {len(test_df)} ‡πÅ‡∏ñ‡∏ß")
        print(f"{'='*60}\n")
    
    if separate_test:
        return train_df, test_df
    else:
        return train_df if train_df is not None else test_df

# ==========================================
# 2. FEATURE ENGINEERING
# ==========================================
def create_training_data(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô: ‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (label=1) ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (label=0)"""
    print("\nüìê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Training Data...")
    
    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
    branch_info = {}
    for code, group in df.groupby('Code'):
        # ‡∏î‡∏∂‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        lat = group['Latitude'].iloc[0] if 'Latitude' in group.columns else 0.0
        lon = group['Longitude'].iloc[0] if 'Longitude' in group.columns else 0.0
        
        branch_info[code] = {
            'avg_weight': group['Weight'].mean(),
            'avg_cube': group['Cube'].mean(),
            'total_trips': len(group),
            'province': group['Province'].iloc[0] if 'Province' in group.columns and group['Province'].notna().any() else 'UNKNOWN',
            'latitude': float(lat) if pd.notna(lat) else 0.0,
            'longitude': float(lon) if pd.notna(lon) else 0.0
        }
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ó‡∏£‡∏ô
    positive_pairs = []  # ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    negative_pairs = []  # ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    
    all_codes = list(branch_info.keys())
    trip_pairs = set()  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    
    # ‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (Positive pairs)
    for trip, group in df.groupby('Trip'):
        codes = sorted(group['Code'].unique())
        
        if len(codes) >= 2:
            for i in range(len(codes)):
                for j in range(i+1, len(codes)):
                    pair = tuple(sorted([codes[i], codes[j]]))
                    trip_pairs.add(pair)
    
    print(f"  ‚úÖ ‡∏û‡∏ö‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô: {len(trip_pairs)} ‡∏Ñ‡∏π‡πà")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö positive pairs
    for code1, code2 in trip_pairs:
        if code1 in branch_info and code2 in branch_info:
            features = create_pair_features(code1, code2, branch_info)
            features['label'] = 1  # ‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
            positive_pairs.append(features)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á negative pairs - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    # ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå: ‡∏´‡∏≤‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô ‡πÅ‡∏•‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÑ‡∏Å‡∏•‡∏Å‡∏±‡∏ô (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏Ñ‡∏ô‡∏•‡∏∞‡∏†‡∏≤‡∏Ñ)
    np.random.seed(42)
    num_negative = len(positive_pairs)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏£‡∏¥‡∏õ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
    code_trips = {}
    for trip, group in df.groupby('Trip'):
        for code in group['Code'].unique():
            if code not in code_trips:
                code_trips[code] = []
            code_trips[code].append(trip)
    
    attempted = 0
    max_attempts = num_negative * 20
    
    while len(negative_pairs) < num_negative and attempted < max_attempts:
        idx1, idx2 = np.random.choice(len(all_codes), 2, replace=False)
        code1, code2 = all_codes[idx1], all_codes[idx2]
        pair = tuple(sorted([code1, code2]))
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÜ
        if pair not in trip_pairs:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: ‡∏Ñ‡∏ß‡∏£‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏£‡∏¥‡∏õ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Å‡∏±‡∏ô)
            trips1 = set(code_trips.get(code1, []))
            trips2 = set(code_trips.get(code2, []))
            shared_trips = trips1 & trips2
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏¢ = ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
            if len(shared_trips) == 0:
                features = create_pair_features(code1, code2, branch_info)
                features['label'] = 0  # ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                negative_pairs.append(features)
        
        attempted += 1
    
    print(f"  ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Positive pairs: {len(positive_pairs)} ‡∏Ñ‡∏π‡πà")
    print(f"  ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Negative pairs: {len(negative_pairs)} ‡∏Ñ‡∏π‡πà")
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    all_pairs = positive_pairs + negative_pairs
    train_df = pd.DataFrame(all_pairs)
    
    return train_df, trip_pairs, branch_info

def create_pair_features(code1, code2, branch_info):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤"""
    info1 = branch_info[code1]
    info2 = branch_info[code2]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß
    weight_diff = abs(info1['avg_weight'] - info2['avg_weight'])
    cube_diff = abs(info1['avg_cube'] - info2['avg_cube'])
    weight_sum = info1['avg_weight'] + info2['avg_weight']
    cube_sum = info1['avg_cube'] + info2['avg_cube']
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    same_province = 1 if info1['province'] == info2['province'] else 0
    
    # Code prefix ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (2 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å)
    prefix1 = code1[:2] if len(code1) >= 2 else code1
    prefix2 = code2[:2] if len(code2) >= 2 else code2
    same_prefix = 1 if prefix1 == prefix2 else 0
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    import math
    distance_km = 0.0
    if info1['latitude'] != 0 and info2['latitude'] != 0:
        lat1, lon1 = math.radians(info1['latitude']), math.radians(info1['longitude'])
        lat2, lon2 = math.radians(info2['latitude']), math.radians(info2['longitude'])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
        c = 2 * math.asin(math.sqrt(a))
        distance_km = 6371 * c  # ‡∏£‡∏±‡∏®‡∏°‡∏µ‡πÇ‡∏•‡∏Å
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° features: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏è
    freq_product = info1['total_trips'] * info2['total_trips']
    freq_diff = abs(info1['total_trips'] - info2['total_trips'])
    
    # ratio ‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß
    weight_ratio = (info1['avg_weight'] / info2['avg_weight']) if info2['avg_weight'] > 0 else 0
    cube_ratio = (info1['avg_cube'] / info2['avg_cube']) if info2['avg_cube'] > 0 else 0
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    over_4w = 1 if (weight_sum > 2500 or cube_sum > 5.0) else 0
    over_jb = 1 if (weight_sum > 3500 or cube_sum > 8.0) else 0
    over_6w = 1 if (weight_sum > 5800 or cube_sum > 22.0) else 0
    
    return {
        'weight_sum': weight_sum,
        'cube_sum': cube_sum,
        'weight_diff': weight_diff,
        'cube_diff': cube_diff,
        'same_province': same_province,
        'same_prefix': same_prefix,
        'distance_km': distance_km,
        'avg_weight_1': info1['avg_weight'],
        'avg_weight_2': info2['avg_weight'],
        'avg_cube_1': info1['avg_cube'],
        'avg_cube_2': info2['avg_cube'],
        'freq_product': freq_product,
        'freq_diff': freq_diff,
        'weight_ratio': weight_ratio,
        'cube_ratio': cube_ratio,
        'over_4w': over_4w,
        'over_jb': over_jb,
        'over_6w': over_6w
    }

# ==========================================
# 3. TRAIN MODEL
# ==========================================
def train_decision_tree(train_df):
    """‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree"""
    print("\nüå≤ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Decision Tree...")
    
    # ‡πÅ‡∏¢‡∏Å features ‡πÅ‡∏•‡∏∞ label
    X = train_df.drop(['label'], axis=1)
    y = train_df['label']
    
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"  Train: {len(X_train)} ‡∏Ñ‡∏π‡πà")
    print(f"  Test:  {len(X_test)} ‡∏Ñ‡∏π‡πà")
    
    # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• - ‡∏õ‡∏£‡∏±‡∏ö parameters ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100%
    best_model = None
    best_score = 0
    
    # ‡∏•‡∏≠‡∏á max_depth ‡∏ï‡πà‡∏≤‡∏á‡πÜ - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ pattern ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
    for max_depth in [None, 15, 20, 30, 50]:
        for min_samples_split in [2, 3, 5]:
            for min_samples_leaf in [1, 2]:
                for criterion in ['gini', 'entropy']:
                    model = DecisionTreeClassifier(
                        max_depth=max_depth,
                        min_samples_split=min_samples_split,
                        min_samples_leaf=min_samples_leaf,
                        criterion=criterion,
                        random_state=42
                    )
                    
                    model.fit(X_train, y_train)
                    train_score = model.score(X_train, y_train)
                    test_score = model.score(X_test, y_test)
                    
                    # ‡πÄ‡∏ô‡πâ‡∏ô‡∏ó‡∏µ‡πà test score ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
                    if test_score > best_score or (test_score == best_score and train_score >= 0.99):
                        best_score = test_score
                        best_model = model
    
    # ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    train_accuracy = best_model.score(X_train, y_train)
    test_accuracy = best_model.score(X_test, y_test)
    
    print(f"\n{'='*60}")
    print(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô:")
    print(f"  Train Accuracy: {train_accuracy*100:.2f}%")
    print(f"  Test Accuracy:  {test_accuracy*100:.2f}%")
    print(f"{'='*60}")
    
    # ‡πÅ‡∏™‡∏î‡∏á feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nüìà Feature Importance:")
    for idx, row in feature_importance.head(5).iterrows():
        print(f"  {row['feature']}: {row['importance']:.4f}")
    
    return best_model, train_accuracy, test_accuracy

# ==========================================
# 4. TEST MODEL
# ==========================================
def test_model_on_actual_trips(df, model, trip_pairs, branch_info):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á"""
    print(f"\n{'='*60}")
    print(f"üéØ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á")
    print(f"{'='*60}\n")
    
    total_pairs = 0
    correct_pairs = 0
    incorrect_pairs = []
    
    for trip, group in df.groupby('Trip'):
        codes = sorted(group['Code'].unique())
        
        if len(codes) < 2:
            continue
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
        for i in range(len(codes)):
            for j in range(i+1, len(codes)):
                code1, code2 = codes[i], codes[j]
                
                if code1 not in branch_info or code2 not in branch_info:
                    continue
                
                total_pairs += 1
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á features
                features = create_pair_features(code1, code2, branch_info)
                X = pd.DataFrame([features])
                
                # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                prediction = model.predict(X)[0]
                
                # ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô 1 (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á)
                if prediction == 1:
                    correct_pairs += 1
                else:
                    incorrect_pairs.append({
                        'trip': trip,
                        'code1': code1,
                        'code2': code2,
                        'predicted': prediction
                    })
    
    accuracy = (correct_pairs / total_pairs * 100) if total_pairs > 0 else 0
    
    print(f"‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏π‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {total_pairs}")
    print(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ñ‡∏π‡∏Å: {correct_pairs}")
    print(f"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î: {len(incorrect_pairs)}")
    print(f"\n{'='*60}")
    print(f"üéØ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥: {accuracy:.2f}%")
    print(f"{'='*60}")
    
    if incorrect_pairs and len(incorrect_pairs) <= 20:
        print(f"\n‚ùå ‡∏Ñ‡∏π‡πà‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏¥‡∏î:")
        for item in incorrect_pairs:
            print(f"  Trip {item['trip']}: {item['code1']} ‚Üî {item['code2']}")
    
    return accuracy, incorrect_pairs

# ==========================================
# 5. SAVE MODEL
# ==========================================
def save_model(model, trip_pairs, branch_info, accuracy):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    os.makedirs('models', exist_ok=True)
    
    model_data = {
        'model': model,
        'trip_pairs': trip_pairs,
        'branch_info': branch_info,
        'accuracy': accuracy,
        'created_at': datetime.now().isoformat()
    }
    
    with open('models/decision_tree_model.pkl', 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà: models/decision_tree_model.pkl")

# ==========================================
# 6. MAIN
# ==========================================
def main():
    print(f"\n{'#'*60}")
    print(f"# Decision Tree Model - Logistics Trip Pairing")
    print(f"# ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100%")
    print(f"{'#'*60}")
    
    # 1. Load data - ‡πÅ‡∏¢‡∏Å Train ‡πÅ‡∏•‡∏∞ Test
    train_df, test_df = load_historical_data('Dc', separate_test=True)
    if df is None:
        print("\n‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")
        return
    
    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á training data
    train_df, trip_pairs, branch_info = create_training_data(df)
    
    # 3. Train model
    model, train_acc, test_acc = train_decision_tree(train_df)
    
    # 4. Test ‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏£‡∏¥‡∏á
    accuracy, incorrect = test_model_on_actual_trips(df, model, trip_pairs, branch_info)
    
    # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏û‡∏≠
    if accuracy >= 95.0:
        save_model(model, trip_pairs, branch_info, accuracy)
        print(f"\nüéâ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå! ({accuracy:.2f}%)")
    else:
        print(f"\n‚ö†Ô∏è  ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå ({accuracy:.2f}% < 95%)")
        print(f"‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
    
    print(f"\n{'#'*60}")
    print(f"# ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")
    print(f"{'#'*60}\n")

if __name__ == "__main__":
    main()
