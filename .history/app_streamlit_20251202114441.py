import streamlit as st
import pandas as pd
import numpy as np
import io
import os
import glob
import networkx as nx
from sklearn.cluster import DBSCAN
import math
import warnings

warnings.filterwarnings('ignore')

# ==========================================
# 1. CONFIG
# ==========================================
LIMITS = {'4W': {'max_w': 2500, 'max_c': 5.0}, 'JB': {'max_w': 3500, 'max_c': 8.0}, '6W': {'max_w': 5800, 'max_c': 22.0}}
BUFFER = 1.05
MAX_KM_CLUSTER = 30.0
TARGET_DROPS = 10
MAX_DROPS_FLEX = 12
NEARBY_RADIUS = 5.0
MAX_ZONE_DISTANCE = 100.0
STRICT_ZONE_MODE = True
EXCLUDE = ['PTDC', 'Distribution Center', 'DCà¸§à¸±à¸‡à¸™à¹‰à¸­à¸¢', 'DC011']

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def normalize(val):
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def haversine(lat1, lon1, lat2, lon2):
    R = 6371
    dLat = math.radians(lat2 - lat1)
    dLon = math.radians(lon2 - lon1)
    a = math.sin(dLat/2) * math.sin(dLat/2) + \
        math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * \
        math.sin(dLon/2) * math.sin(dLon/2)
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    return R * c

def is_similar_name(name1, name2):
    def clean(n):
        return ''.join([c for c in str(n) if c.isalpha()])
    return clean(name1) == clean(name2) and len(clean(name1)) > 3

def get_province_zone(province):
    if not province or pd.isna(province):
        return 'UNKNOWN'
    
    prov = str(province).strip()
    
    central = ['à¸à¸£à¸¸à¸‡à¹€à¸—à¸ž', 'à¸™à¸™à¸—à¸šà¸¸à¸£à¸µ', 'à¸›à¸—à¸¸à¸¡à¸˜à¸²à¸™à¸µ', 'à¸ªà¸¡à¸¸à¸—à¸£à¸›à¸£à¸²à¸à¸²à¸£', 'à¸ªà¸¡à¸¸à¸—à¸£à¸ªà¸²à¸„à¸£', 'à¸™à¸„à¸£à¸›à¸à¸¡', 
               'à¸ªà¸¡à¸¸à¸—à¸£à¸ªà¸‡à¸„à¸£à¸²à¸¡', 'à¸£à¸²à¸Šà¸šà¸¸à¸£à¸µ', 'à¸à¸²à¸à¸ˆà¸™à¸šà¸¸à¸£à¸µ', 'à¸ªà¸¸à¸žà¸£à¸£à¸“à¸šà¸¸à¸£à¸µ', 'à¸Šà¸±à¸¢à¸™à¸²à¸—', 'à¸ªà¸´à¸‡à¸«à¹Œà¸šà¸¸à¸£à¸µ', 
               'à¸­à¹ˆà¸²à¸‡à¸—à¸­à¸‡', 'à¸¥à¸žà¸šà¸¸à¸£à¸µ', 'à¸ªà¸£à¸°à¸šà¸¸à¸£à¸µ', 'à¸­à¸¢à¸¸à¸˜à¸¢à¸²', 'à¸žà¸£à¸°à¸™à¸„à¸£à¸¨à¸£à¸µà¸­à¸¢à¸¸à¸˜à¸¢à¸²']
    
    northeast = ['à¸™à¸„à¸£à¸£à¸²à¸Šà¸ªà¸µà¸¡à¸²', 'à¹‚à¸„à¸£à¸²à¸Š', 'à¸šà¸¸à¸£à¸µà¸£à¸±à¸¡à¸¢à¹Œ', 'à¸ªà¸¸à¸£à¸´à¸™à¸—à¸£à¹Œ', 'à¸¨à¸µà¸‚à¸£à¸ à¸¹à¸¡à¸´', 'à¸‚à¸­à¸™à¹à¸à¹ˆà¸™', 
                 'à¸­à¸¸à¸”à¸£à¸˜à¸²à¸™à¸µ', 'à¹€à¸¥à¸¢', 'à¸«à¸™à¸­à¸‡à¸„à¸²à¸¢', 'à¸¡à¸«à¸²à¸ªà¸²à¸£à¸„à¸²à¸¡', 'à¸£à¹‰à¸­à¸¢à¹€à¸­à¹‡à¸”', 'à¸à¸²à¸¬à¸ªà¸´à¸™à¸˜à¸¸à¹Œ', 
                 'à¸ªà¸à¸¥à¸™à¸„à¸£', 'à¸™à¸„à¸£à¸žà¸™à¸¡', 'à¸¡à¸¸à¸à¸”à¸²à¸«à¸²à¸£', 'à¸¢à¹‚à¸ªà¸˜à¸£', 'à¸­à¸³à¸™à¸²à¸ˆà¹€à¸ˆà¸£à¸´à¸', 'à¸­à¸¸à¸šà¸¥à¸£à¸²à¸Šà¸˜à¸²à¸™à¸µ', 
                 'à¸Šà¸±à¸¢à¸ à¸¹à¸¡à¸´', 'à¸šà¸¶à¸‡à¸à¸²à¸¬']
    
    north = ['à¹€à¸Šà¸µà¸¢à¸‡à¹ƒà¸«à¸¡à¹ˆ', 'à¹€à¸Šà¸µà¸¢à¸‡à¸£à¸²à¸¢', 'à¸¥à¸³à¸žà¸¹à¸™', 'à¸¥à¸³à¸›à¸²à¸‡', 'à¸žà¸°à¹€à¸¢à¸²', 'à¹à¸žà¸£à¹ˆ', 'à¸™à¹ˆà¸²à¸™', 
             'à¸­à¸¸à¸•à¸£à¸”à¸´à¸•à¸–à¹Œ', 'à¸•à¸²à¸', 'à¸ªà¸¸à¹‚à¸‚à¸—à¸±à¸¢', 'à¸žà¸´à¸©à¸“à¸¸à¹‚à¸¥à¸', 'à¸žà¸´à¸ˆà¸´à¸•à¸£', 'à¹€à¸žà¸Šà¸£à¸šà¸¹à¸£à¸“à¹Œ', 'à¸à¸³à¹à¸žà¸‡à¹€à¸žà¸Šà¸£']
    
    south = ['à¸Šà¸¸à¸¡à¸žà¸£', 'à¸ªà¸¸à¸£à¸²à¸©à¸Žà¸£à¹Œà¸˜à¸²à¸™à¸µ', 'à¸£à¸°à¸™à¸­à¸‡', 'à¸žà¸±à¸‡à¸‡à¸²', 'à¸ à¸¹à¹€à¸à¹‡à¸•', 'à¸à¸£à¸°à¸šà¸µà¹ˆ', 'à¸™à¸„à¸£à¸¨à¸£à¸µà¸˜à¸£à¸£à¸¡à¸£à¸²à¸Š', 
             'à¸•à¸£à¸±à¸‡', 'à¸žà¸±à¸—à¸¥à¸¸à¸‡', 'à¸ªà¸‡à¸‚à¸¥à¸²', 'à¸ªà¸•à¸¹à¸¥', 'à¸›à¸±à¸•à¸•à¸²à¸™à¸µ', 'à¸¢à¸°à¸¥à¸²', 'à¸™à¸£à¸²à¸˜à¸´à¸§à¸²à¸ª']
    
    east = ['à¸‰à¸°à¹€à¸Šà¸´à¸‡à¹€à¸—à¸£à¸²', 'à¸Šà¸¥à¸šà¸¸à¸£à¸µ', 'à¸£à¸°à¸¢à¸­à¸‡', 'à¸ˆà¸±à¸™à¸—à¸šà¸¸à¸£à¸µ', 'à¸•à¸£à¸²à¸”', 'à¸›à¸£à¸²à¸ˆà¸µà¸™à¸šà¸¸à¸£à¸µ', 'à¸ªà¸£à¸°à¹à¸à¹‰à¸§']
    
    west = ['à¸à¸²à¸à¸ˆà¸™à¸šà¸¸à¸£à¸µ', 'à¸•à¸²à¸', 'à¸›à¸£à¸°à¸ˆà¸§à¸šà¸„à¸µà¸£à¸µà¸‚à¸±à¸™à¸˜à¹Œ', 'à¹€à¸žà¸Šà¸£à¸šà¸¸à¸£à¸µ']
    
    for p in central:
        if p in prov: return 'CENTRAL'
    for p in northeast:
        if p in prov: return 'NORTHEAST'
    for p in north:
        if p in prov: return 'NORTH'
    for p in south:
        if p in prov: return 'SOUTH'
    for p in east:
        if p in prov: return 'EAST'
    for p in west:
        if p in prov: return 'WEST'
    
    return 'UNKNOWN'

def is_same_zone(code1, code2, zone_map, geo):
    if not STRICT_ZONE_MODE:
        return True
    
    if code1 in geo and code2 in geo:
        lat1, lon1 = geo[code1]
        lat2, lon2 = geo[code2]
        if lat1 != 0 and lat2 != 0:
            dist = haversine(lat1, lon1, lat2, lon2)
            if dist > MAX_ZONE_DISTANCE:
                return False
    
    zone1 = zone_map.get(code1, 'UNKNOWN')
    zone2 = zone_map.get(code2, 'UNKNOWN')
    
    if zone1 != 'UNKNOWN' and zone2 != 'UNKNOWN':
        if zone1 != zone2:
            return False
    
    return True

# ==========================================
# 3. LOADERS & PROCESSORS
# ==========================================
def load_excel(content):
    try:
        xls = pd.ExcelFile(io.BytesIO(content))
        target_sheet = None
        
        # à¸¥à¸³à¸”à¸±à¸šà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¹ƒà¸™à¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸à¸Šà¸µà¸•: 2.Punthai > 2. > punthai > order > history
        priority = ['2.punthai', '2.', 'punthai', 'order', 'history']
        
        for p in priority:
            for s in xls.sheet_names:
                if p in s.lower(): 
                    target_sheet = s
                    break
            if target_sheet: break
        
        if not target_sheet: target_sheet = xls.sheet_names[0]
        
        df_tmp = pd.read_excel(xls, sheet_name=target_sheet, nrows=20, header=None)
        h_row = -1
        for i, r in df_tmp.iterrows():
            row_str = r.astype(str).str.upper().tolist()
            if sum(1 for k in ['CODE','BRANCH','à¸ªà¸²à¸‚à¸²','WGT'] if any(k in s for s in row_str)) >= 2:
                h_row = i; break
        if h_row == -1: h_row = 1
        return pd.read_excel(xls, sheet_name=target_sheet, header=h_row)
    except: return None

def process_dataframe(df):
    if df is None: return None
    df.columns = df.columns.astype(str).str.strip()
    df = df.loc[:, ~df.columns.duplicated()]
    rename_map = {}
    for c in df.columns:
        cu = c.upper().replace(' ','').replace('_','')
        if 'BRANCHCODE' in cu or 'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²' in cu: rename_map[c] = 'Code'
        elif 'BRANCH' in cu or 'à¸Šà¸·à¹ˆà¸­à¸ªà¸²à¸‚à¸²' in cu or 'à¸ªà¸²à¸‚à¸²'==c: rename_map[c] = 'Name'
        elif 'WGT' in cu or 'à¸™à¹‰à¸³à¸«à¸™à¸±à¸' in cu: rename_map[c] = 'Wgt'
        elif 'CUBE' in cu or 'à¸„à¸´à¸§' in cu: rename_map[c] = 'Cube'
        elif 'LAT' in cu: rename_map[c] = 'Lat'
        elif 'LON' in cu: rename_map[c] = 'Lon'
        elif 'TRIP' in cu or 'BOOKING' in cu: rename_map[c] = 'Trip'
        elif 'VEHICLE' in cu or 'TRIPNO' in cu: rename_map[c] = 'Vehicle'
        elif 'à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”' in cu: rename_map[c] = 'Province'
    
    df.rename(columns=rename_map, inplace=True)
    if 'Code' not in df.columns:
        if 'Name' in df.columns: df['Code'] = df['Name']
        else: return None
        
    df['Code'] = df['Code'].apply(normalize)
    for c in ['Wgt','Cube','Lat','Lon']:
        if c not in df.columns: df[c] = 0.0
        else: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0.0)
        
    mask_ex = df['Code'].isin(EXCLUDE)
    if 'Name' in df.columns: mask_ex |= df['Name'].apply(lambda x: any(k in str(x) for k in EXCLUDE))
    return df[~mask_ex].copy()

def process_geo(df):
    if df is None: return {}
    df = process_dataframe(df)
    geo = {}
    if df is not None:
        for _, r in df.iterrows():
            if r['Lat']!=0: geo[r['Code']] = (r['Lat'], r['Lon'])
    return geo

# ==========================================
# 4. AI CORE
# ==========================================
def train_ai(df_list):
    G = nx.Graph()
    req = {}
    zones = {}
    regions = {}
    trip_distances = {}  # à¹€à¸à¹‡à¸šà¸£à¸°à¸¢à¸°à¸—à¸²à¸‡à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸—à¸£à¸´à¸›
    trip_patterns = []   # à¹€à¸à¹‡à¸šà¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸ˆà¸±à¸”
    
    for df in df_list:
        if df is None or 'Trip' not in df.columns: continue
        
        # à¸ªà¸£à¹‰à¸²à¸‡ copy à¹à¸¥à¸°à¸¥à¸šà¸„à¸­à¸¥à¸±à¸¡à¸™à¹Œà¸‹à¹‰à¸³
        df = df.copy()
        df = df.loc[:, ~df.columns.duplicated()]
        
        # à¹à¸à¹‰à¹„à¸‚à¸›à¸±à¸à¸«à¸² Trip à¹€à¸›à¹‡à¸™ DataFrame
        if isinstance(df['Trip'], pd.DataFrame):
            df['Trip'] = df['Trip'].iloc[:,0]
        
        # à¹à¸›à¸¥à¸‡ Trip à¹€à¸›à¹‡à¸™ string à¹à¸¥à¸°à¸à¸£à¸­à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥
        df['Trip'] = df['Trip'].astype(str)
        df = df[(df['Trip'].notna()) & (df['Trip'] != 'nan') & (df['Trip'] != '') & (df['Trip'] != 'None')]
        
        if len(df) == 0:
            continue
        
        # à¹€à¸à¹‡à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸±à¸‡à¸«à¸§à¸±à¸”à¹à¸¥à¸°à¸ à¸¹à¸¡à¸´à¸ à¸²à¸„
        for idx, r in df.iterrows():
            if 'Province' in df.columns and pd.notna(r['Province']):
                prov = str(r['Province']).strip()
                zones[r['Code']] = prov
                regions[r['Code']] = get_province_zone(prov)
        
        # à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸ˆà¸±à¸”à¸—à¸£à¸´à¸›
        for t, g in df.groupby('Trip'):
            codes = g['Code'].unique()
            veh = str(g['Vehicle'].iloc[0]).upper() if 'Vehicle' in g.columns else ''
            rank = 3 if '6' in veh else (2 if 'J' in veh else 1)
            
            # à¸šà¸±à¸™à¸—à¸¶à¸ requirement à¸‚à¸­à¸‡à¹à¸•à¹ˆà¸¥à¸°à¸ªà¸²à¸‚à¸²
            for c in codes: 
                req[c] = max(req.get(c,1), rank)
            
            # à¸„à¸³à¸™à¸§à¸“à¸£à¸°à¸¢à¸°à¸—à¸²à¸‡à¸£à¸§à¸¡à¸‚à¸­à¸‡à¸—à¸£à¸´à¸› (à¸–à¹‰à¸²à¸¡à¸µà¸žà¸´à¸à¸±à¸”)
            if 'Lat' in g.columns and 'Lon' in g.columns:
                total_dist = 0
                coords = g[['Lat', 'Lon']].values
                for i in range(len(coords)-1):
                    if coords[i][0] != 0 and coords[i+1][0] != 0:
                        total_dist += haversine(coords[i][0], coords[i][1], 
                                               coords[i+1][0], coords[i+1][1])
                
                if total_dist > 0:
                    trip_distances[t] = total_dist
            
            # à¸šà¸±à¸™à¸—à¸¶à¸à¸£à¸¹à¸›à¹à¸šà¸šà¸à¸²à¸£à¸ˆà¸±à¸”à¸—à¸£à¸´à¸›
            trip_info = {
                'trip': t,
                'branches': len(codes),
                'vehicle': veh,
                'weight': g['Wgt'].sum() if 'Wgt' in g.columns else 0,
                'cube': g['Cube'].sum() if 'Cube' in g.columns else 0,
                'codes': list(codes),
                'region': regions.get(codes[0], 'UNKNOWN') if len(codes) > 0 else 'UNKNOWN'
            }
            trip_patterns.append(trip_info)
            
            # à¸ªà¸£à¹‰à¸²à¸‡à¸à¸£à¸²à¸Ÿà¸„à¸§à¸²à¸¡à¸ªà¸±à¸¡à¸žà¸±à¸™à¸˜à¹Œ (à¸ªà¸²à¸‚à¸²à¸—à¸µà¹ˆà¹€à¸„à¸¢à¹„à¸›à¸”à¹‰à¸§à¸¢à¸à¸±à¸™)
            if len(codes)>1:
                for i in range(len(codes)):
                    for j in range(i+1, len(codes)): 
                        G.add_edge(codes[i], codes[j])
            elif len(codes)==1: 
                G.add_node(codes[0])
    
    # à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸–à¸´à¸•à¸´à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰
    learning_stats = {
        'total_trips': len(trip_patterns),
        'total_branches': len(req),
        'avg_drops': sum(p['branches'] for p in trip_patterns) / len(trip_patterns) if trip_patterns else 0,
        'avg_distance': sum(trip_distances.values()) / len(trip_distances) if trip_distances else 0,
        'region_distribution': {},
        'vehicle_usage': {}
    }
    
    # à¸™à¸±à¸šà¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸²à¸¡à¸ à¸¹à¸¡à¸´à¸ à¸²à¸„
    for pattern in trip_patterns:
        region = pattern['region']
        learning_stats['region_distribution'][region] = learning_stats['region_distribution'].get(region, 0) + 1
        
        veh = pattern['vehicle']
        if '6' in veh:
            veh_type = '6W'
        elif 'J' in veh or 'à¸ˆà¸±à¸¡à¹‚à¸š' in veh:
            veh_type = '4W-JB'
        else:
            veh_type = '4W'
        learning_stats['vehicle_usage'][veh_type] = learning_stats['vehicle_usage'].get(veh_type, 0) + 1
    
    return G, req, regions, learning_stats

def select_truck(w, c, min_rank):
    s = min_rank
    if s >= 3: return '6 à¸¥à¹‰à¸­ à¸•à¸¹à¹‰à¸—à¸¶à¸š'
    if s <= 1 and c <= LIMITS['4W']['max_c']*BUFFER and w <= LIMITS['4W']['max_w']: return '4 à¸¥à¹‰à¸­ à¸•à¸¹à¹‰à¸—à¸¶à¸š'
    if s <= 2 and c <= LIMITS['JB']['max_c']*BUFFER and w <= LIMITS['JB']['max_w']: return '4 à¸¥à¹‰à¸­ à¸ˆà¸±à¸¡à¹‚à¸šà¹‰ à¸•à¸¹à¹‰à¸—à¸¶à¸š'
    return '6 à¸¥à¹‰à¸­ à¸•à¸¹à¹‰à¸—à¸¶à¸š'

def run_prediction(df_test, G, geo, constraints, region_map):
    df_test['Lat'] = df_test.apply(lambda r: geo.get(r['Code'],(0,0))[0] if r['Lat']==0 else r['Lat'], axis=1)
    df_test['Lon'] = df_test.apply(lambda r: geo.get(r['Code'],(0,0))[1] if r['Lon']==0 else r['Lon'], axis=1)
    df_test['Region'] = df_test['Code'].map(lambda x: region_map.get(x, 'UNKNOWN'))
    
    hist_map = {n:i for i,c in enumerate(nx.connected_components(G)) for n in c}
    df_test['Cluster'] = df_test['Code'].map(lambda x: f"H-{hist_map[x]}" if x in hist_map else "UNK")
    
    if STRICT_ZONE_MODE:
        new_clusters = []
        for idx, row in df_test.iterrows():
            if row['Cluster'] != 'UNK' and row['Region'] != 'UNKNOWN':
                new_clusters.append(f"{row['Cluster']}-{row['Region']}")
            else:
                new_clusters.append(row['Cluster'])
        df_test['Cluster'] = new_clusters
    
    mask_unk = df_test['Cluster']=="UNK"
    if mask_unk.any():
        mask_geo = (df_test['Lat']!=0) & mask_unk
        if mask_geo.any():
            coords = np.radians(df_test.loc[mask_geo, ['Lat','Lon']].values)
            db = DBSCAN(eps=MAX_KM_CLUSTER/6371.0, min_samples=1).fit(coords)
            df_test.loc[mask_geo, 'Cluster'] = [f"G-{x}" if x!=-1 else "NOISE" for x in db.labels_]
    
    mask_fin = df_test['Cluster'].isin(["UNK","NOISE"])
    if mask_fin.any():
        df_test.loc[mask_fin, 'Cluster'] = df_test.loc[mask_fin, 'Code'].map(
            lambda x: f"Z-{region_map.get(x, 'NEW')}" if x in region_map else f"NEW-{x}"
        )
    
    final_rows = []
    trip_cnt = 1
    
    for cid, group in df_test.groupby('Cluster'):
        pool = []
        for code, sub in group.groupby('Code'):
            pool.append({
                'Code': code, 'Name': sub.iloc[0]['Name'],
                'Wgt': sub['Wgt'].sum(), 'Cube': sub['Cube'].sum(),
                'Lat': sub.iloc[0]['Lat'], 'Lon': sub.iloc[0]['Lon']
            })
            
        while pool:
            pool.sort(key=lambda x: x['Cube'], reverse=True)
            current_truck = []
            seed = pool.pop(0)
            current_truck.append(seed)
            
            curr_w = seed['Wgt']
            curr_c = seed['Cube']
            last_lat = seed['Lat']
            last_lon = seed['Lon']
            last_name = seed['Name']
            drops = 1
            max_req = constraints.get(seed['Code'], 1)
            
            while True:
                best_idx = -1
                best_score = float('inf')
                best_is_same_name = False
                
                for i, cand in enumerate(pool):
                    if STRICT_ZONE_MODE:
                        if last_lat != 0 and cand['Lat'] != 0:
                            zone_dist = haversine(last_lat, last_lon, cand['Lat'], cand['Lon'])
                            if zone_dist > MAX_ZONE_DISTANCE:
                                continue
                        
                        if not is_same_zone(seed['Code'], cand['Code'], region_map, geo):
                            continue
                    
                    new_w = curr_w + cand['Wgt']
                    new_c = curr_c + cand['Cube']
                    
                    if new_w > 5800: continue
                    if new_c > 22.0 * BUFFER: continue
                    
                    is_same_name = is_similar_name(last_name, cand['Name'])
                    dist = haversine(last_lat, last_lon, cand['Lat'], cand['Lon']) if last_lat!=0 and cand['Lat']!=0 else 999
                    is_nearby = (dist <= NEARBY_RADIUS)
                    
                    if drops >= TARGET_DROPS:
                        if drops >= MAX_DROPS_FLEX: 
                            continue
                        if not (is_same_name or is_nearby): 
                            continue
                    
                    score = dist
                    if is_same_name:
                        score -= 1000
                    
                    is_better = (score < best_score)
                    if is_same_name and not best_is_same_name:
                        is_better = True
                    elif best_is_same_name and not is_same_name:
                        is_better = False
                    
                    if is_better:
                        best_score = score
                        best_idx = i
                        best_is_same_name = is_same_name
                        
                if best_idx != -1:
                    sel = pool.pop(best_idx)
                    current_truck.append(sel)
                    
                    curr_w += sel['Wgt']
                    curr_c += sel['Cube']
                    drops += 1
                    
                    if sel['Lat']!=0: 
                        last_lat = sel['Lat']; last_lon = sel['Lon']
                    last_name = sel['Name']
                    max_req = max(max_req, constraints.get(sel['Code'], 1))
                else:
                    break
            
            v_type = select_truck(curr_w, curr_c, max_req)
            tid = f"AI-{trip_cnt:03d}"
            
            for item in current_truck:
                final_rows.append({
                    'Booking No': tid, 'à¸›à¸£à¸°à¹€à¸ à¸—à¸£à¸–': v_type,
                    'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²': item['Code'], 'à¸ªà¸²à¸‚à¸²': item['Name'],
                    'TOTALWGT': item['Wgt'], 'TOTALCUBE': item['Cube'],
                    'Remark': f"Drops:{drops}", 'Lat': item['Lat'], 'Lon': item['Lon']
                })
            trip_cnt += 1
            
    return pd.DataFrame(final_rows)

def export_styled_excel(df, filename):
    try:
        import xlsxwriter
        writer = pd.ExcelWriter(filename, engine='xlsxwriter')
        df.to_excel(writer, index=False, sheet_name='Plan')
        wb = writer.book; ws = writer.sheets['Plan']
        fmt_h = wb.add_format({'bold': True, 'bg_color': '#4472C4', 'font_color': 'white', 'border': 1})
        fmt_1 = wb.add_format({'bg_color': '#FFFFFF', 'border': 1})
        fmt_2 = wb.add_format({'bg_color': '#D9D9D9', 'border': 1})
        for c, val in enumerate(df.columns): ws.write(0, c, val, fmt_h)
        curr = None; toggle = False
        for r, row in df.iterrows():
            if row['Booking No'] != curr: toggle = not toggle; curr = row['Booking No']
            fmt = fmt_1 if toggle else fmt_2
            for c, val in enumerate(row): ws.write(r+1, c, val, fmt)
        writer.close()
    except:
        df.to_excel(filename, index=False)

# ==========================================
# 5. STREAMLIT UI
# ==========================================
def main():
    st.set_page_config(page_title="AI Logistics Planner", page_icon="ðŸšš", layout="wide")
    
    st.title("ðŸšš AI Logistics Planner: Sticky Routing Edition")
    st.markdown("---")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.info("âœ¨ **Sticky Routing**: à¸Šà¸·à¹ˆà¸­à¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸±à¸™à¹„à¸›à¸à¹ˆà¸­à¸™ + à¹ƒà¸à¸¥à¹‰à¸à¸±à¸™à¹„à¸›à¸à¹ˆà¸­à¸™")
    with col2:
        st.info("ðŸ“¦ **Drop Rules**: 1-10 âœ“ | 11-12 (à¸Šà¸·à¹ˆà¸­à¹€à¸«à¸¡à¸·à¸­à¸™/à¹ƒà¸à¸¥à¹‰â‰¤5km) âœ“ | 13+ âœ—")
    with col3:
        st.info("ðŸŒ **Zone Filter**: Geofence 100km + Province/Region Aware")
    
    st.markdown("---")
    
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC
    dc_folder = os.path.join(os.getcwd(), 'DC')
    dc_files_found = []
    if os.path.exists(dc_folder):
        dc_files_found = glob.glob(os.path.join(dc_folder, '*.xlsx')) + glob.glob(os.path.join(dc_folder, '*.xls'))
    
    # à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸žà¸šà¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC
    if dc_files_found:
        with st.expander(f"ðŸ“‚ à¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™ DC/ : {len(dc_files_found)} à¹„à¸Ÿà¸¥à¹Œ", expanded=True):
            for f in dc_files_found:
                st.text(f"âœ“ {os.path.basename(f)}")
    else:
        st.warning("âš ï¸ à¹„à¸¡à¹ˆà¸žà¸šà¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ 'DC/' à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆà¸¡à¸µà¹„à¸Ÿà¸¥à¹Œ Excel à¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ")
    
    st.markdown("---")
    
    # File uploader - à¹€à¸‰à¸žà¸²à¸° Test
    st.subheader("ðŸŽ¯ à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸­à¸­à¹€à¸”à¸­à¸£à¹Œ (Test)")
    
    # à¹€à¸à¹‡à¸šà¹„à¸Ÿà¸¥à¹Œà¹€à¸à¹ˆà¸²à¹ƒà¸™ session state
    if 'last_uploaded_file' not in st.session_state:
        st.session_state.last_uploaded_file = None
    
    test_file = st.file_uploader("à¹€à¸¥à¸·à¸­à¸à¹„à¸Ÿà¸¥à¹Œ Test à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸§à¸²à¸‡à¹à¸œà¸™", type=['xlsx', 'xls'], key='test')
    
    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¸¡à¸µà¸à¸²à¸£à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆà¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    if test_file is not None:
        current_file_name = test_file.name
        if st.session_state.last_uploaded_file != current_file_name:
            # à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¹ˆà¸²à¹€à¸¡à¸·à¹ˆà¸­à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ
            st.session_state.last_uploaded_file = current_file_name
            st.cache_data.clear()
            st.info(f"ðŸ“„ à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸«à¸¡à¹ˆ: {current_file_name}")
    elif test_file is None and st.session_state.last_uploaded_file is not None:
        # à¸–à¹‰à¸²à¸¥à¸šà¹„à¸Ÿà¸¥à¹Œà¸­à¸­à¸ à¹ƒà¸«à¹‰à¹€à¸„à¸¥à¸µà¸¢à¸£à¹Œ session
        st.session_state.last_uploaded_file = None
        st.cache_data.clear()
    
    st.markdown("---")
    
    if st.button("ðŸš€ à¹€à¸£à¸´à¹ˆà¸¡à¸§à¸²à¸‡à¹à¸œà¸™", type="primary", use_container_width=True):
        if not test_file:
            st.error("âŒ à¸à¸£à¸¸à¸“à¸²à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Test")
            return
        
        if not dc_files_found:
            st.error("âŒ à¹„à¸¡à¹ˆà¸žà¸šà¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC/ à¸à¸£à¸¸à¸“à¸²à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC à¹à¸¥à¸°à¸§à¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¹„à¸§à¹‰à¹ƒà¸™à¸™à¸±à¹‰à¸™")
            return
        
        with st.spinner("â³ à¸à¸³à¸¥à¸±à¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥..."):
            # Load training data à¸ˆà¸²à¸à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC
            tr_dfs = []
            
            st.info(f"ðŸ“‚ à¸à¸³à¸¥à¸±à¸‡à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¸ˆà¸²à¸à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC/ ({len(dc_files_found)} à¹„à¸Ÿà¸¥à¹Œ)")
            
            for dc_file_path in dc_files_found:
                try:
                    with open(dc_file_path, 'rb') as f:
                        file_content = f.read()
                        train_df = process_dataframe(load_excel(file_content))
                        if train_df is not None:
                            tr_dfs.append(train_df)
                            st.success(f"âœ… {os.path.basename(dc_file_path)}: {len(train_df)} à¸£à¸²à¸¢à¸à¸²à¸£")
                        else:
                            st.warning(f"âš ï¸ {os.path.basename(dc_file_path)}: à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¹„à¸”à¹‰")
                except Exception as e:
                    st.error(f"âŒ {os.path.basename(dc_file_path)}: {str(e)}")
            
            if not tr_dfs:
                st.error("âŒ à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸”à¹† à¸ˆà¸²à¸à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ DC à¹„à¸”à¹‰")
                return
            
            st.info(f"ðŸ“š à¸£à¸§à¸¡à¹„à¸Ÿà¸¥à¹Œà¹€à¸—à¸£à¸™à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {len(tr_dfs)} à¹„à¸Ÿà¸¥à¹Œ")
            
            # Train AI
            G, const, regions, learning_stats = train_ai(tr_dfs)
            
            # à¹à¸ªà¸”à¸‡à¸ªà¸–à¸´à¸•à¸´à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰
            st.success(f"ðŸ§  à¹€à¸—à¸£à¸™ AI à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™!")
            
            with st.expander("ðŸ“Š à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰à¸ˆà¸²à¸à¸›à¸£à¸°à¸§à¸±à¸•à¸´", expanded=True):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ðŸšš à¸ˆà¸³à¸™à¸§à¸™à¸—à¸£à¸´à¸›à¸—à¸µà¹ˆà¹€à¸£à¸µà¸¢à¸™à¸£à¸¹à¹‰", f"{learning_stats['total_trips']}")
                with col2:
                    st.metric("ðŸª à¸ˆà¸³à¸™à¸§à¸™à¸ªà¸²à¸‚à¸²à¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”", f"{learning_stats['total_branches']}")
                with col3:
                    st.metric("ðŸ“ à¸ˆà¸¸à¸”à¸ªà¹ˆà¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢/à¸—à¸£à¸´à¸›", f"{learning_stats['avg_drops']:.1f}")
                with col4:
                    st.metric("ðŸ—ºï¸ à¸£à¸°à¸¢à¸°à¸—à¸²à¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢", f"{learning_stats['avg_distance']:.0f} km")
                
                st.markdown("---")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write("**ðŸŒ à¸à¸²à¸£à¸à¸£à¸°à¸ˆà¸²à¸¢à¸•à¸²à¸¡à¸ à¸¹à¸¡à¸´à¸ à¸²à¸„:**")
                    for region, count in sorted(learning_stats['region_distribution'].items(), key=lambda x: x[1], reverse=True):
                        if region != 'UNKNOWN':
                            st.write(f"- {region}: {count} à¸—à¸£à¸´à¸›")
                
                with col2:
                    st.write("**ðŸš› à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸£à¸–à¸•à¸²à¸¡à¸›à¸£à¸°à¹€à¸ à¸—:**")
                    for veh, count in sorted(learning_stats['vehicle_usage'].items(), key=lambda x: x[1], reverse=True):
                        st.write(f"- {veh}: {count} à¸—à¸£à¸´à¸›")
                
                st.info(f"ðŸ’¡ à¸£à¸°à¸šà¸šà¸ˆà¸°à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¹ƒà¸™à¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸¥à¸¸à¹ˆà¸¡à¸ªà¸²à¸‚à¸²à¸—à¸µà¹ˆà¹€à¸„à¸¢à¹„à¸›à¸”à¹‰à¸§à¸¢à¸à¸±à¸™ à¹à¸¥à¸°à¹€à¸¥à¸·à¸­à¸à¸£à¸–à¸•à¸²à¸¡à¸›à¸£à¸°à¸§à¸±à¸•à¸´")
            
            # Load geo - à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸ training files
            geo = {}
            for df in tr_dfs:
                if df is not None:
                    temp_geo = process_geo(df)
                    geo.update(temp_geo)
            
            if geo:
                st.success(f"ðŸ“ à¸”à¸¶à¸‡à¸žà¸´à¸à¸±à¸”à¸ˆà¸²à¸à¹„à¸Ÿà¸¥à¹Œà¹€à¸—à¸£à¸™: {len(geo)} à¸ªà¸²à¸‚à¸²")
            else:
                st.info("ðŸ“ à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸žà¸´à¸à¸±à¸”à¹ƒà¸™à¹„à¸Ÿà¸¥à¹Œà¹€à¸—à¸£à¸™")
            
            # Process test data
            df_test = process_dataframe(load_excel(test_file.read()))
            if df_test is None:
                st.error("âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸­à¹ˆà¸²à¸™à¹„à¸Ÿà¸¥à¹Œ Test")
                return
            
            st.info(f"ðŸ“¦ à¸­à¸­à¹€à¸”à¸­à¸£à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”: {len(df_test)} à¸£à¸²à¸¢à¸à¸²à¸£ | à¸ªà¸²à¸‚à¸²à¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¹ˆà¸‡: {df_test['Code'].nunique()} à¸ªà¸²à¸‚à¸²")
            
            # Run prediction
            res = run_prediction(df_test, G, geo, const, regions)
            res = res.sort_values(by=['Booking No', 'Lat'])
            
            # Display results
            total_trips = res['Booking No'].nunique()
            trip_summary = res.groupby('Booking No').agg({
                'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²': 'count',
                'TOTALWGT': 'sum',
                'TOTALCUBE': 'sum'
            }).rename(columns={'à¸£à¸«à¸±à¸ªà¸ªà¸²à¸‚à¸²': 'Drops'})
            
            st.markdown("---")
            st.success("### âœ… à¸§à¸²à¸‡à¹à¸œà¸™à¹€à¸ªà¸£à¹‡à¸ˆà¸ªà¸´à¹‰à¸™!")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ðŸšš à¸ˆà¸³à¸™à¸§à¸™à¹€à¸—à¸µà¹ˆà¸¢à¸§", f"{total_trips} à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            with col2:
                st.metric("ðŸ“ à¸ˆà¸¸à¸”à¸ªà¹ˆà¸‡à¹€à¸‰à¸¥à¸µà¹ˆà¸¢", f"{trip_summary['Drops'].mean():.1f} à¸ˆà¸¸à¸”/à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            with col3:
                st.metric("âš–ï¸ à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¹€à¸‰à¸¥à¸µà¹ˆà¸¢", f"{trip_summary['TOTALWGT'].mean():.0f} kg/à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            with col4:
                st.metric("ðŸ“¦ à¸„à¸´à¸§à¹€à¸‰à¸¥à¸µà¹ˆà¸¢", f"{trip_summary['TOTALCUBE'].mean():.2f} cbm/à¹€à¸—à¸µà¹ˆà¸¢à¸§")
            
            # Display dataframe
            st.subheader("ðŸ“‹ à¸œà¸¥à¸¥à¸±à¸žà¸˜à¹Œ")
            st.dataframe(res, use_container_width=True, height=400)
            
            # Export
            output_filename = 'AI_Sticky_Routing_Plan.xlsx'
            export_styled_excel(res, output_filename)
            
            with open(output_filename, 'rb') as f:
                st.download_button(
                    label="ðŸ’¾ à¸”à¸²à¸§à¸™à¹Œà¹‚à¸«à¸¥à¸”à¹„à¸Ÿà¸¥à¹Œ Excel",
                    data=f,
                    file_name=output_filename,
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                    use_container_width=True
                )
            
            st.balloons()

if __name__ == "__main__":
    main()
