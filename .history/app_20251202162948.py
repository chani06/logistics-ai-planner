"""
Logistics Planner 
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import glob
from datetime import datetime
import io

# ==========================================
# CONFIG
# ==========================================
MODEL_PATH = 'models/decision_tree_model.pkl'

# ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
LIMITS = {
    '4W': {'max_w': 2500, 'max_c': 5.0},
    '6W': {'max_w': 5800, 'max_c': 22.0},
    'JB': {'max_w': 3500, 'max_c': 8.0}
}

# ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÑ‡∏î‡πâ‡πÄ‡∏Å‡∏¥‡∏ô 5%
BUFFER = 1.05

# ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ
MAX_BRANCHES_PER_TRIP = 12  # ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 12 ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ
TARGET_BRANCHES_PER_TRIP = 10  # ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 10 ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡πà‡∏á (‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å)
EXCLUDE_BRANCHES = ['DC011', 'PTDC', 'PTG DISTRIBUTION CENTER']

# ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å (‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠)
EXCLUDE_NAMES = ['Distribution Center', 'PTG Distribution', '‡∏ö.‡∏û‡∏µ‡∏ó‡∏µ‡∏à‡∏µ ‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏ô‡∏≠‡∏¢‡∏µ']

# ==========================================
# HELPER FUNCTIONS
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def can_fit_truck(total_weight, total_cube, truck_type):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡πÉ‡∏™‡πà‡∏£‡∏ñ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    limits = LIMITS[truck_type]
    max_w = limits['max_w'] * BUFFER
    max_c = limits['max_c'] * BUFFER
    return total_weight <= max_w and total_cube <= max_c

def suggest_truck(total_weight, total_cube):
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°"""
    for truck in ['4W', 'JB', '6W']:
        if can_fit_truck(total_weight, total_cube, truck):
            return truck
    return '6W+'  # ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏•‡∏±‡∏á 6W

def can_branch_use_vehicle(code, vehicle_type, branch_vehicles):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡πá‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
    if not branch_vehicles or code not in branch_vehicles:
        return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    if vehicle_type in vehicle_history:
        return True
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (6W > JB > 4W)
    vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
    requested_size = vehicle_sizes.get(vehicle_type, 0)
    
    for v in vehicle_history:
        if vehicle_sizes.get(v, 0) >= requested_size:
            return True
    
    return False

def get_most_used_vehicle_for_branch(code, branch_vehicles):
    """‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    if not branch_vehicles or code not in branch_vehicles:
        return None
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return None
    
    return max(vehicle_history, key=vehicle_history.get)

def is_similar_name(name1, name2):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤1, ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤2)"""
    def clean_name(name):
        if pd.isna(name) or name is None:
            return ""
        s = str(name).strip().upper()
        # ‡∏•‡∏ö prefix ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
        prefixes = ['PTC-MRT-', 'PTC-', 'PUN-', 'FC', 'MAXMART', 'MaxMart']
        for prefix in prefixes:
            s = s.replace(prefix.upper(), '')
        # ‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
        cleaned = ''.join([c for c in s if c.isalpha()])
        return cleaned
    
    clean1 = clean_name(name1)
    clean2 = clean_name(name2)
    
    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£
    if len(clean1) < 3 or len(clean2) < 3:
        return False
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    shorter = min(clean1, clean2, key=len)
    longer = max(clean1, clean2, key=len)
    
    # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏±‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡∏ß ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô 80%+ = ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
    if shorter in longer:
        return True
    
    # ‡∏ô‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
    matches = sum(1 for a, b in zip(clean1, clean2) if a == b)
    similarity = matches / max(len(clean1), len(clean2))
    
    return similarity >= 0.8  # ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô 80% ‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ

def is_nearby_province(prov1, prov2):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)"""
    if pd.isna(prov1) or pd.isna(prov2):
        return False
    
    if prov1 == prov2:
        return True
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ‡∏¢‡πà‡∏≠‡∏¢ (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
    province_groups = {
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û'],
        '‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•': ['‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£', '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤'],
        '‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤'],
        '‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ'],
        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': ['‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå', '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ'],
        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': ['‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ï‡∏£‡∏≤‡∏î', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': ['‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°', '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨', '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£', '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£', '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π', '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏•‡∏¢'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå', '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô', '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥', '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°', '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÉ‡∏ï‡πâ': ['‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä', '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå', '‡∏¢‡πÇ‡∏™‡∏ò‡∏£', '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©', '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå', '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç', '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ'],
        '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤', '‡∏•‡∏≥‡∏õ‡∏≤‡∏á', '‡∏•‡∏≥‡∏û‡∏π‡∏ô', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÅ‡∏û‡∏£‡πà', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô'],
        '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£', '‡∏ï‡∏≤‡∏Å', '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå', '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£', '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å', '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢', '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå', '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå'],
        '‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏î‡∏≤‡∏°‡∏±‡∏ô': ['‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏ï‡∏£‡∏±‡∏á', '‡∏û‡∏±‡∏á‡∏á‡∏≤', '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏£‡∏∞‡∏ô‡∏≠‡∏á', '‡∏™‡∏ï‡∏π‡∏•'],
        '‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡πà‡∏≤‡∏ß‡πÑ‡∏ó‡∏¢': ['‡∏ä‡∏∏‡∏°‡∏û‡∏£', '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™']
    }
    
    # ‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á 2 ‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    for group, provinces in province_groups.items():
        in_group_1 = any(p in str(prov1) for p in provinces)
        in_group_2 = any(p in str(prov2) for p in provinces)
        
        if in_group_1 and in_group_2:
            return True
    
    return False

def load_model():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
    if not os.path.exists(MODEL_PATH):
        return None
    
    try:
        with open(MODEL_PATH, 'rb') as f:
            model_data = pickle.load(f)
        return model_data
    except Exception as e:
        st.error(f"‚ùå Error loading model: {e}")
        return None

def create_pair_features(code1, code2, branch_info):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤"""
    import math
    
    info1 = branch_info[code1]
    info2 = branch_info[code2]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß
    weight_diff = abs(info1['avg_weight'] - info2['avg_weight'])
    cube_diff = abs(info1['avg_cube'] - info2['avg_cube'])
    weight_sum = info1['avg_weight'] + info2['avg_weight']
    cube_sum = info1['avg_cube'] + info2['avg_cube']
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    same_province = 1 if info1['province'] == info2['province'] else 0
    
    # Code prefix ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    prefix1 = code1[:2] if len(code1) >= 2 else code1
    prefix2 = code2[:2] if len(code2) >= 2 else code2
    same_prefix = 1 if prefix1 == prefix2 else 0
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î
    distance_km = 0.0
    if info1['latitude'] != 0 and info2['latitude'] != 0:
        lat1, lon1 = math.radians(info1['latitude']), math.radians(info1['longitude'])
        lat2, lon2 = math.radians(info2['latitude']), math.radians(info2['longitude'])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
        c = 2 * math.asin(math.sqrt(a))
        distance_km = 6371 * c
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
    freq_product = info1['total_trips'] * info2['total_trips']
    freq_diff = abs(info1['total_trips'] - info2['total_trips'])
    
    # Ratio
    weight_ratio = (info1['avg_weight'] / info2['avg_weight']) if info2['avg_weight'] > 0 else 0
    cube_ratio = (info1['avg_cube'] / info2['avg_cube']) if info2['avg_cube'] > 0 else 0
    
    # ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ
    over_4w = 1 if (weight_sum > 2500 or cube_sum > 5.0) else 0
    over_jb = 1 if (weight_sum > 3500 or cube_sum > 8.0) else 0
    over_6w = 1 if (weight_sum > 5800 or cube_sum > 22.0) else 0
    
    return {
        'weight_sum': weight_sum,
        'cube_sum': cube_sum,
        'weight_diff': weight_diff,
        'cube_diff': cube_diff,
        'same_province': same_province,
        'same_prefix': same_prefix,
        'distance_km': distance_km,
        'avg_weight_1': info1['avg_weight'],
        'avg_weight_2': info2['avg_weight'],
        'avg_cube_1': info1['avg_cube'],
        'avg_cube_2': info2['avg_cube'],
        'freq_product': freq_product,
        'freq_diff': freq_diff,
        'weight_ratio': weight_ratio,
        'cube_ratio': cube_ratio,
        'over_4w': over_4w,
        'over_jb': over_jb,
        'over_6w': over_6w
    }

def load_excel(file_content, sheet_name=None):
    """‡πÇ‡∏´‡∏•‡∏î Excel"""
    try:
        xls = pd.ExcelFile(io.BytesIO(file_content))
        
        target_sheet = None
        if sheet_name and sheet_name in xls.sheet_names:
            target_sheet = sheet_name
        else:
            for s in xls.sheet_names:
                if 'punthai' in s.lower() or '2.' in s.lower():
                    target_sheet = s
                    break
        
        if not target_sheet:
            target_sheet = xls.sheet_names[0]
        
        # ‡∏´‡∏≤ header row
        df_temp = pd.read_excel(xls, sheet_name=target_sheet, header=None)
        header_row = 0
        
        for i in range(min(10, len(df_temp))):
            row_values = df_temp.iloc[i].astype(str).str.upper()
            match_count = sum([
                'BRANCH' in ' '.join(row_values),
                'TRIP' in ' '.join(row_values),
                '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in ' '.join(df_temp.iloc[i].astype(str))
            ])
            if match_count >= 2:
                header_row = i
                break
        
        df = pd.read_excel(xls, sheet_name=target_sheet, header=header_row)
        df = df.loc[:, ~df.columns.duplicated()]
        
        return df
    except Exception as e:
        st.error(f"‚ùå Error: {e}")
        return None

def process_dataframe(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    if df is None:
        return None
    
    rename_map = {}
    for col in df.columns:
        col_clean = str(col).strip()
        col_upper = col_clean.upper().replace(' ', '').replace('_', '')
        
        if col_clean == 'BranchCode' or '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏£‡∏´‡∏±‡∏™ WMS':
            rename_map[col] = 'Code'
        elif col_clean == 'Branch' or '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏™‡∏≤‡∏Ç‡∏≤':
            rename_map[col] = 'Name'
        elif col_clean == 'TOTALWGT' or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col_clean:
            rename_map[col] = 'Weight'
        elif col_clean == 'TOTALCUBE' or '‡∏Ñ‡∏¥‡∏ß' in col_clean:
            rename_map[col] = 'Cube'
        elif 'latitude' in col_clean.lower() or col_clean == '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î':
            rename_map[col] = 'Latitude'
        elif 'longitude' in col_clean.lower() or col_clean == '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î':
            rename_map[col] = 'Longitude'
        elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean:
            rename_map[col] = 'Province'
    
    df = df.rename(columns=rename_map)
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥
    df = df.loc[:, ~df.columns.duplicated()]
    
    if 'Code' in df.columns:
        df['Code'] = df['Code'].apply(normalize)
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å (‡∏£‡∏´‡∏±‡∏™)
        df = df[~df['Code'].isin(EXCLUDE_BRANCHES)]
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ keyword ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        if 'Name' in df.columns:
            exclude_pattern = '|'.join(EXCLUDE_NAMES)
            df = df[~df['Name'].str.contains(exclude_pattern, case=False, na=False)]
    
    for col in ['Weight', 'Cube']:
        if col not in df.columns:
            df[col] = 0.0
        else:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)
    
    return df.reset_index(drop=True)

def predict_trips(test_df, model_data):
    """
    ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏é‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:
    
    ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö (‡∏ï‡πâ‡∏≠‡∏á‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô):
    0. ‚úÖ ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 12 ‡∏™‡∏≤‡∏Ç‡∏≤)
    0. ‚úÖ ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
    0. ‚úÖ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô 10 ‡∏™‡∏≤‡∏Ç‡∏≤ ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    0. ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
    
    ‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà (‡∏´‡∏•‡∏±‡∏á‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö):
    1. ‚úÖ ‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ (trip_pairs) + ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
    2. ‚úÖ ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤1, ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤2)
    3. ‚úÖ AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏à‡∏≤‡∏Å Decision Tree Model
    4. ‚úÖ ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ
    """
    model = model_data['model']
    trip_pairs = model_data['trip_pairs']
    branch_info = model_data['branch_info']
    trip_vehicles = model_data.get('trip_vehicles', {})  # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏π‡πà
    branch_vehicles = model_data.get('branch_vehicles', {})  # ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà
    for code in test_df['Code'].unique():
        if code not in branch_info:
            code_data = test_df[test_df['Code'] == code]
            branch_info[code] = {
                'avg_weight': code_data['Weight'].mean(),
                'avg_cube': code_data['Cube'].mean(),
                'total_trips': 1,
                'province': code_data['Province'].iloc[0] if 'Province' in code_data.columns else 'UNKNOWN',
                'latitude': 0.0,
                'longitude': 0.0
            }
    
    all_codes = test_df['Code'].unique().tolist()
    assigned_trips = {}
    trip_counter = 1
    trip_recommended_vehicles = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_codes = len(all_codes)
    processed = 0
    
    while all_codes:
        seed_code = all_codes.pop(0)
        current_trip = [seed_code]
        assigned_trips[seed_code] = trip_counter
        
        processed += 1
        progress_bar.progress(processed / total_codes)
        status_text.text(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ {trip_counter}... ({processed}/{total_codes} ‡∏™‡∏≤‡∏Ç‡∏≤)")
        
        remaining = all_codes[:]
        recommended_vehicle = None  # ‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ
        
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏Ç‡∏≠‡∏á seed
        seed_province = test_df[test_df['Code'] == seed_code]['Province'].iloc[0] if 'Province' in test_df.columns else 'UNKNOWN'
        
        for code in remaining:
            pair = tuple(sorted([seed_code, code]))
            code_province = test_df[test_df['Code'] == code]['Province'].iloc[0] if 'Province' in test_df.columns else 'UNKNOWN'
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏Å‡πà‡∏≠‡∏ô - ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô MAX ‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°
            if len(current_trip) >= MAX_BRANCHES_PER_TRIP:
                continue  # ‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß
            
            # ‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏™‡∏°‡∏≠ (‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
            # ‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô
            if not is_nearby_province(seed_province, code_province):
                continue  # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡πÄ‡∏•‡∏¢
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô TARGET_BRANCHES ‡πÅ‡∏•‡πâ‡∏ß ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            if len(current_trip) >= TARGET_BRANCHES_PER_TRIP:
                if seed_province != code_province:
                    continue
            
            # ‡∏Å‡∏é 1: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡∏à‡∏±‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô + ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
            if pair in trip_pairs:
                should_pair = True
                # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥
                if pair in trip_vehicles and recommended_vehicle is None:
                    vehicle_info = trip_vehicles[pair]
                    hist_vehicle = vehicle_info.get('most_used') or vehicle_info.get('vehicle', '6W')
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    seed_can_use = can_branch_use_vehicle(seed_code, hist_vehicle, branch_vehicles)
                    code_can_use = can_branch_use_vehicle(code, hist_vehicle, branch_vehicles)
                    
                    if seed_can_use and code_can_use:
                        recommended_vehicle = hist_vehicle
                    else:
                        # ‡∏ñ‡πâ‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô
                        seed_most_used = get_most_used_vehicle_for_branch(seed_code, branch_vehicles)
                        code_most_used = get_most_used_vehicle_for_branch(code, branch_vehicles)
                        
                        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ
                        vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
                        if seed_most_used and code_most_used:
                            if vehicle_sizes.get(seed_most_used, 0) >= vehicle_sizes.get(code_most_used, 0):
                                recommended_vehicle = seed_most_used
                            else:
                                recommended_vehicle = code_most_used
            else:
                # ‡∏Å‡∏é 2: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤1, ‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤2)
                seed_name = test_df[test_df['Code'] == seed_code]['Name'].iloc[0] if 'Name' in test_df.columns else ''
                code_name = test_df[test_df['Code'] == code]['Name'].iloc[0] if 'Name' in test_df.columns else ''
                
                if is_similar_name(seed_name, code_name):
                    should_pair = True
                else:
                    # ‡∏Å‡∏é 3: ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• AI ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
                    features = create_pair_features(seed_code, code, branch_info)
                    X = pd.DataFrame([features])
                    should_pair = model.predict(X)[0] == 1
            
            if should_pair:
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ
                trip_weight = test_df[test_df['Code'].isin(current_trip + [code])]['Weight'].sum()
                trip_cube = test_df[test_df['Code'].isin(current_trip + [code])]['Cube'].sum()
                
                # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏£‡∏ñ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡πÉ‡∏ä‡πâ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡∏ô‡∏±‡πâ‡∏ô
                if recommended_vehicle and recommended_vehicle in LIMITS:
                    max_w = LIMITS[recommended_vehicle]['max_w'] * BUFFER
                    max_c = LIMITS[recommended_vehicle]['max_c'] * BUFFER
                else:
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ 6W ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
                    max_w = LIMITS['6W']['max_w'] * BUFFER
                    max_c = LIMITS['6W']['max_c'] * BUFFER
                
                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if trip_weight <= max_w and trip_cube <= max_c:
                    current_trip.append(code)
                    assigned_trips[code] = trip_counter
                    all_codes.remove(code)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ
        if recommended_vehicle:
            trip_recommended_vehicles[trip_counter] = recommended_vehicle
        
        trip_counter += 1
    
    progress_bar.empty()
    status_text.empty()
    
    test_df['Trip'] = test_df['Code'].map(assigned_trips)
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ
    summary_data = []
    for trip_num in sorted(test_df['Trip'].unique()):
        trip_data = test_df[test_df['Trip'] == trip_num]
        total_w = trip_data['Weight'].sum()
        total_c = trip_data['Cube'].sum()
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡πá auto-suggest
        if trip_num in trip_recommended_vehicles:
            suggested = trip_recommended_vehicles[trip_num]
            source = "üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥"
        else:
            suggested = suggest_truck(total_w, total_c)
            source = "ü§ñ AI"
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ
        if suggested in LIMITS:
            w_util = (total_w / LIMITS[suggested]['max_w']) * 100
            c_util = (total_c / LIMITS[suggested]['max_c']) * 100
        else:
            w_util = c_util = 0
        
        summary_data.append({
            'Trip': trip_num,
            'Branches': len(trip_data),
            'Weight': total_w,
            'Cube': total_c,
            'Truck': f"{suggested} {source}",
            'Weight_Use%': w_util,
            'Cube_Use%': c_util
        })
    
    summary_df = pd.DataFrame(summary_data)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤
    trip_truck_map = {}
    trip_truck_type_map = {}  # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ (‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏° source)
    for _, row in summary_df.iterrows():
        trip_truck_map[row['Trip']] = row['Truck']
        # ‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ (‡∏ï‡∏±‡∏î emoji ‡πÅ‡∏•‡∏∞ source ‡∏≠‡∏≠‡∏Å)
        truck_type = row['Truck'].split()[0] if row['Truck'] else '6W'
        trip_truck_type_map[row['Trip']] = truck_type
    
    test_df['Truck'] = test_df['Trip'].map(trip_truck_map)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    def check_vehicle_history(row):
        code = row['Code']
        trip = row['Trip']
        truck_type = trip_truck_type_map.get(trip, '6W')
        
        if code not in branch_vehicles:
            return "‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ (‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà)"
        
        vehicle_history = branch_vehicles.get(code, {})
        if not vehicle_history:
            return "‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)"
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ
        if truck_type in vehicle_history:
            count = vehicle_history[truck_type]
            return f"‚úÖ ‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ ({count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)"
        
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤
        vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
        requested_size = vehicle_sizes.get(truck_type, 0)
        for v, count in vehicle_history.items():
            if vehicle_sizes.get(v, 0) >= requested_size:
                return f"‚úÖ ‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤ ({v}: {count} ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)"
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏Ç‡∏ô‡∏≤‡∏î‡∏ô‡∏µ‡πâ
        history_str = ", ".join([f"{v}:{c}" for v, c in vehicle_history.items()])
        return f"‚ö†Ô∏è ‡∏õ‡∏Å‡∏ï‡∏¥‡πÉ‡∏ä‡πâ: {history_str}"
    
    test_df['VehicleCheck'] = test_df.apply(check_vehicle_history, axis=1)
    
    return test_df, summary_df

# ==========================================
# STREAMLIT UI
# ==========================================
def main():
    st.set_page_config(
        page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß",
        page_icon="üöö",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # Header
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("üöö ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß")
    with col2:
        st.image("https://raw.githubusercontent.com/twitter/twemoji/master/assets/svg/1f69a.svg", width=100)
    
    st.markdown("---")
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_data = load_model()
    
    if not model_data:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.info("üí° ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: `python test_model.py`")
        st.stop()
    
    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    st.markdown("### üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå")
    uploaded_file = st.file_uploader(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel (.xlsx)", 
        type=['xlsx'],
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå"
    )
    
    if uploaded_file:
        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
            df = load_excel(uploaded_file.read())
            df = process_dataframe(df)
            
            if df is not None and 'Code' in df.columns:
                st.success(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: **{len(df):,}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", f"{df['Code'].nunique():,}")
                with col2:
                    st.metric("‚öñÔ∏è ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏ß‡∏°", f"{df['Weight'].sum():,.0f} kg")
                with col3:
                    st.metric("üì¶ ‡∏Ñ‡∏¥‡∏ß‡∏£‡∏ß‡∏°", f"{df['Cube'].sum():.1f} m¬≥")
                with col4:
                    provinces = df['Province'].nunique() if 'Province' in df.columns else 0
                    st.metric("üó∫Ô∏è ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", f"{provinces}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                with st.expander("üîç ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"):
                    st.dataframe(df.head(10), use_container_width=True)
                
                st.markdown("---")
                
                # ‡πÅ‡∏ó‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å
                tab1, tab2 = st.tabs(["üì¶ ‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)", "üó∫Ô∏è ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ (‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)"])
                    
                # ==========================================
                # ‡πÅ‡∏ó‡πá‡∏ö 1: ‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)
                # ==========================================
                with tab1:
                    # ‡∏õ‡∏∏‡πà‡∏°‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
                    if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß", type="primary", use_container_width=True):
                        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                            result_df, summary = predict_trips(df.copy(), model_data)
                            
                            st.balloons()
                            st.success(f"‚úÖ **‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!** ‡∏£‡∏ß‡∏° **{len(summary)}** ‡∏ó‡∏£‡∏¥‡∏õ")
                            
                            st.markdown("---")
                            
                            # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
                            st.markdown("### üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("üöö ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏£‡∏¥‡∏õ", len(summary))
                            with col2:
                                st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", len(result_df))
                            with col3:
                                avg_branches = len(result_df) / result_df['Trip'].nunique()
                                st.metric("üìä ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤/‡∏ó‡∏£‡∏¥‡∏õ", f"{avg_branches:.1f}")
                            with col4:
                                avg_util = summary['Cube_Use%'].mean()
                                st.metric("üìà ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_util:.0f}%")
                            
                            st.markdown("---")
                            
                            # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ
                            st.markdown("### üöõ ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ")
                            st.dataframe(
                                summary.style.format({
                                    'Weight': '{:.2f}',
                                    'Cube': '{:.2f}',
                                    'Weight_Use%': '{:.1f}%',
                                    'Cube_Use%': '{:.1f}%'
                                }).background_gradient(
                                    subset=['Weight_Use%', 'Cube_Use%'],
                                    cmap='RdYlGn',
                                    vmin=0,
                                    vmax=100
                                ),
                                use_container_width=True,
                                height=400
                            )
                            
                            # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ñ)
                            with st.expander("üìã ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤ (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ)"):
                                # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                                display_cols = ['Trip', 'Code', 'Name', 'Weight', 'Cube', 'Truck', 'VehicleCheck']
                                if 'Province' in result_df.columns:
                                    display_cols.insert(3, 'Province')
                                
                                display_df = result_df[display_cols].copy()
                                if 'Province' not in result_df.columns:
                                    display_df.columns = ['‡∏ó‡∏£‡∏¥‡∏õ', '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å(kg)', '‡∏Ñ‡∏¥‡∏ß(m¬≥)', '‡∏£‡∏ñ', '‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏ñ']
                                else:
                                    display_df.columns = ['‡∏ó‡∏£‡∏¥‡∏õ', '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å(kg)', '‡∏Ñ‡∏¥‡∏ß(m¬≥)', '‡∏£‡∏ñ', '‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏ñ']
                                
                                st.dataframe(display_df, use_container_width=True, height=400)
                            
                            # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
                            warning_branches = result_df[result_df['VehicleCheck'].str.contains('‚ö†Ô∏è', na=False)]
                            if len(warning_branches) > 0:
                                with st.expander(f"‚ö†Ô∏è ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏Å‡∏ï‡∏¥ ({len(warning_branches)} ‡∏™‡∏≤‡∏Ç‡∏≤)"):
                                    st.warning("‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏õ‡∏Å‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏∑‡πà‡∏ô ‡πÅ‡∏ï‡πà‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ")
                                    display_cols_warn = ['Trip', 'Code', 'Name', 'Truck', 'VehicleCheck']
                                    display_warn_df = warning_branches[display_cols_warn].copy()
                                    display_warn_df.columns = ['‡∏ó‡∏£‡∏¥‡∏õ', '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î', '‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ']
                                    st.dataframe(display_warn_df, use_container_width=True)
                            
                            st.markdown("---")
                            
                            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
                            output = io.BytesIO()
                            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                result_df.to_excel(writer, sheet_name='‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏£‡∏¥‡∏õ', index=False)
                                summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏£‡∏¥‡∏õ', index=False)
                            
                            col1, col2, col3 = st.columns([1, 2, 1])
                            with col2:
                                st.download_button(
                                    label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Excel)",
                                    data=output.getvalue(),
                                    file_name=f"‡∏ú‡∏•‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    use_container_width=True
                                )
    
    # ==========================================
    # ‡πÅ‡∏ó‡πá‡∏ö 2: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ (‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)
    # ==========================================
    with tab2:
        st.markdown("### üó∫Ô∏è ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ (‡πÑ‡∏°‡πà‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)")
        st.caption("‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏Ñ‡∏≥‡∏ô‡∏∂‡∏á‡∏ñ‡∏∂‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß")
        
        uploaded_file_region = st.file_uploader(
            "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel (.xlsx)", 
            type=['xlsx'],
            help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤",
            key="region_uploader"
        )
        
        if uploaded_file_region:
            with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
                df_region = load_excel(uploaded_file_region.read())
                df_region = process_dataframe(df_region)
                
                if df_region is not None and 'Code' in df_region.columns:
                    st.success(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: **{len(df_region):,}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£, **{df_region['Code'].nunique()}** ‡∏™‡∏≤‡∏Ç‡∏≤")
                    
                    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
                    branch_info = model_data.get('branch_info', {})
                    trip_pairs = model_data.get('trip_pairs', set())
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏Ñ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤ (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
                    region_groups = {
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ô': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≠‡∏Å': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•': ['‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': ['‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå', '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å-‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•': ['‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤'],
                        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': ['‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ï‡∏£‡∏≤‡∏î', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': ['‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°', '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨', '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£', '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£', '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π', '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏•‡∏¢'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå', '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô', '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥', '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°', '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÉ‡∏ï‡πâ': ['‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä', '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå', '‡∏¢‡πÇ‡∏™‡∏ò‡∏£', '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©', '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå', '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç', '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠-‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤', '‡∏•‡∏≥‡∏õ‡∏≤‡∏á', '‡∏•‡∏≥‡∏û‡∏π‡∏ô', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÅ‡∏û‡∏£‡πà', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô'],
                        '‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠-‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£', '‡∏ï‡∏≤‡∏Å', '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå', '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£', '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å', '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢', '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå', '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå'],
                        '‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ-‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏î‡∏≤‡∏°‡∏±‡∏ô': ['‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏ï‡∏£‡∏±‡∏á', '‡∏û‡∏±‡∏á‡∏á‡∏≤', '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏£‡∏∞‡∏ô‡∏≠‡∏á', '‡∏™‡∏ï‡∏π‡∏•'],
                        '‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ-‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡πà‡∏≤‡∏ß‡πÑ‡∏ó‡∏¢': ['‡∏ä‡∏∏‡∏°‡∏û‡∏£', '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™']
                    }
                    
                    def get_region(province):
                        if pd.isna(province):
                            return '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                        for region, provinces in region_groups.items():
                            if any(p in str(province) for p in provinces):
                                return region
                        return '‡∏≠‡∏∑‡πà‡∏ô‡πÜ'
                    
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏†‡∏≤‡∏Ñ
                    if 'Province' in df_region.columns:
                        df_region['Region'] = df_region['Province'].apply(get_region)
                    else:
                        df_region['Region'] = '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                    
                    # ‡∏´‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                    def find_paired_branches(code, all_codes):
                        paired = set()
                        for pair in trip_pairs:
                            if code in pair:
                                other = pair[0] if pair[1] == code else pair[1]
                                if other in all_codes:
                                    paired.add(other)
                        return paired
                    
                    all_codes_set = set(df_region['Code'].unique())
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤
                    groups = []
                    assigned = set()
                    
                    for _, row in df_region.drop_duplicates('Code').iterrows():
                        code = row['Code']
                        if code in assigned:
                            continue
                        
                        # ‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                        paired = find_paired_branches(code, all_codes_set)
                        group_codes = {code} | (paired - assigned)
                        
                        for c in group_codes:
                            assigned.add(c)
                        
                        groups.append({
                            'codes': group_codes,
                            'region': row.get('Region', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                            'province': row.get('Province', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')
                        })
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                    st.markdown("---")
                    st.markdown("### üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", df_region['Code'].nunique())
                    with col2:
                        st.metric("üóÇÔ∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°", len(groups))
                    with col3:
                        regions_count = df_region['Region'].nunique()
                        st.metric("üó∫Ô∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏Ñ", regions_count)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
                    st.markdown("---")
                    st.markdown("### üó∫Ô∏è ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ")
                    
                    region_summary = df_region.groupby('Region').agg({
                        'Code': 'nunique',
                        'Weight': 'sum',
                        'Cube': 'sum'
                    }).reset_index()
                    region_summary.columns = ['‡∏†‡∏≤‡∏Ñ', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏ß‡∏°', '‡∏Ñ‡∏¥‡∏ß‡∏£‡∏ß‡∏°']
                    st.dataframe(region_summary, use_container_width=True)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏Ñ
                    for region in sorted(df_region['Region'].unique()):
                        region_data = df_region[df_region['Region'] == region]
                        with st.expander(f"üìç {region} ({region_data['Code'].nunique()} ‡∏™‡∏≤‡∏Ç‡∏≤)"):
                            display_cols = ['Code', 'Name', 'Province', 'Weight', 'Cube']
                            display_cols = [c for c in display_cols if c in region_data.columns]
                            
                            region_display = region_data[display_cols].drop_duplicates('Code')
                            col_names = {'Code': '‡∏£‡∏´‡∏±‡∏™', 'Name': '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', 'Province': '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'Weight': '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å', 'Cube': '‡∏Ñ‡∏¥‡∏ß'}
                            region_display.columns = [col_names.get(c, c) for c in display_cols]
                            st.dataframe(region_display, use_container_width=True)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                    st.markdown("---")
                    st.markdown("### üîó ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)")
                    
                    paired_groups = [g for g in groups if len(g['codes']) > 1]
                    if paired_groups:
                        for i, group in enumerate(paired_groups, 1):
                            codes_list = list(group['codes'])
                            names = []
                            for c in codes_list:
                                name_row = df_region[df_region['Code'] == c]
                                if len(name_row) > 0 and 'Name' in name_row.columns:
                                    names.append(f"{c} ({name_row['Name'].iloc[0]})")
                                else:
                                    names.append(c)
                            
                            st.write(f"**‡∏Å‡∏•‡∏∏‡πà‡∏° {i}** - {group['region']}: {', '.join(names)}")
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ")
                    
                    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
                    st.markdown("---")
                    output_region = io.BytesIO()
                    with pd.ExcelWriter(output_region, engine='xlsxwriter') as writer:
                        df_region.to_excel(writer, sheet_name='‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î', index=False)
                        region_summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ', index=False)
                    
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        st.download_button(
                            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° (Excel)",
                            data=output_region.getvalue(),
                            file_name=f"‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )

if __name__ == "__main__":
    main()
