import pandas as pd

# =============================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏´‡πâ‡∏≤‡∏°‡∏£‡∏ñ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Auto planning (1).xlsx
# =============================
def load_vehicle_restrictions(filepath='Dc/Auto planning (1).xlsx', sheet='Info'):
    df = pd.read_excel(filepath, sheet_name=sheet)
    # ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏à‡∏£‡∏¥‡∏á
    print('Columns in file:', list(df.columns))
    # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö LocationNumber ‡πÅ‡∏•‡∏∞ MaxTruckType ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á/‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå
    def find_col(cols, key, must_contain=None):
        key_norm = key.replace(' ', '').lower()
        for c in cols:
            c_norm = c.replace(' ', '').lower()
            if key_norm in c_norm:
                if must_contain:
                    if all(word in c_norm for word in must_contain):
                        return c
                else:
                    return c
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ must_contain
        if must_contain:
            for c in cols:
                c_norm = c.replace(' ', '').lower()
                if all(word in c_norm for word in must_contain):
                    return c
        raise KeyError(f'Column for {key} not found!')
    # ‡∏´‡∏≤ column ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á 'location' ‡πÅ‡∏•‡∏∞ 'code' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤
    code_col = find_col(df.columns, 'Location', must_contain=['location','code'])
    # ‡∏´‡∏≤ column ‡∏ó‡∏µ‡πà‡∏°‡∏µ 'maxtrucktype' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ
    truck_col = find_col(df.columns, 'MaxTruckType')
    restrictions = {}
    for _, row in df.iterrows():
        code = str(row[code_col]).strip()
        max_truck = str(row[truck_col]).strip().upper()
        if max_truck == '4W':
            allowed = ['4W']
        elif max_truck == 'JB':
            allowed = ['4W', 'JB']
        elif max_truck == '6W':
            allowed = ['4W', 'JB', '6W']
        else:
            allowed = ['4W', 'JB', '6W']
        restrictions[code] = allowed
    return restrictions

# =============================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏° branch/zone
# =============================
def get_allowed_vehicle_for_branch(branch_code, zone, restrictions):
    allowed = restrictions.get(str(branch_code).strip(), ['4W', 'JB', '6W'])
    if zone == 'CENTRAL' and '6W' in allowed:
        allowed = [v for v in allowed if v != '6W']
    for v in ['6W', 'JB', '4W']:
        if v in allowed:
            return v
    return allowed[0]

# =============================
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (comment ‡πÑ‡∏ß‡πâ)
# =============================
# restrictions = load_vehicle_restrictions('Dc/Auto planning (1).xlsx', 'Info')
# vehicle = get_allowed_vehicle_for_branch(branch_code, zone, restrictions)
"""
Logistics Planner 
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import glob
from datetime import datetime, time
import io
from math import radians, sin, cos, sqrt, atan2

# Auto-refresh component
try:
    from streamlit_autorefresh import st_autorefresh
    AUTOREFRESH_AVAILABLE = True
except ImportError:
    AUTOREFRESH_AVAILABLE = False
    st.warning("‚ö†Ô∏è ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á streamlit-autorefresh: pip install streamlit-autorefresh")

# ==========================================
# CONFIG
# ==========================================
MODEL_PATH = 'models/decision_tree_model.pkl'

# ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)
LIMITS = {
    '4W': {'max_w': 2500, 'max_c': 5.0, 'max_drops': 12},   # ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 5
    'JB': {'max_w': 3500, 'max_c': 7.0, 'max_drops': 12},   # ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 7
    '6W': {'max_w': 6000, 'max_c': 20.0, 'max_drops': 999}  # ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î, Cube ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡πá‡∏°, Weight ‚â§ 6000
}

# üîí ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Punthai ‡∏•‡πâ‡∏ß‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 100%)
PUNTHAI_LIMITS = {
    '4W': {'max_w': 2500, 'max_c': 5.0, 'max_drops': 5},   # Punthai ‡∏•‡πâ‡∏ß‡∏ô 4W: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5 ‡∏™‡∏≤‡∏Ç‡∏≤
    'JB': {'max_w': 3500, 'max_c': 7.0, 'max_drops': 10},  # Punthai ‡∏•‡πâ‡∏ß‡∏ô JB: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 ‡∏™‡∏≤‡∏Ç‡∏≤
    '6W': {'max_w': 6000, 'max_c': 20.0, 'max_drops': 999}
}

# üéØ Minimum utilization ‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö balancing)
MIN_UTIL = {
    '4W': 70,   # 4W ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 70%
    'JB': 80,   # JB ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 80%
    '6W': 90    # 6W ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 90%
}

# Buffer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ (‡∏ï‡∏≤‡∏° BU)
BUFFER = 1.0  # Default buffer
PUNTHAI_BUFFER = 1.0  # üÖøÔ∏è Punthai ‡∏•‡πâ‡∏ß‡∏ô: ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 100%
MAXMART_BUFFER = 1.10  # üÖº Maxmart/‡∏ú‡∏™‡∏°: ‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏î‡πâ 10%

# ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö 4W/JB ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (6W ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î)
MAX_BRANCHES_PER_TRIP = 12  # ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 12 ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 4W/JB (6W ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î)

# Performance Config
MAX_DETOUR_KM = 12  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 15km ‡πÄ‡∏õ‡πá‡∏ô 12km ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
MAX_MERGE_ITERATIONS = 25  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏¥‡∏õ (‡∏•‡∏î‡∏à‡∏≤‡∏Å 50 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)

# ==========================================
# REGION ORDER CONFIG (Far-to-Near Sorting)
# ==========================================
# ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î: ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ ‚Üí ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô ‚Üí ‡πÉ‡∏ï‡πâ ‚Üí ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å ‚Üí ‡∏Å‡∏•‡∏≤‡∏á
REGION_ORDER = {
    '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': 1, 'NORTH': 1,
    '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô': 2, 'NE': 2,
    '‡πÉ‡∏ï‡πâ': 3, 'SOUTH': 3,
    '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': 4, 'EAST': 4,
    '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': 5, 'WEST': 5,
    '‡∏Å‡∏•‡∏≤‡∏á': 6, 'CENTRAL': 6,
    '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏': 99
}

# ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á: ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ 6W (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 4W, JB)
CENTRAL_REGIONS = ['‡∏Å‡∏•‡∏≤‡∏á', 'CENTRAL']
CENTRAL_ALLOWED_VEHICLES = ['4W', 'JB']  # NO 6W in Central

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡πà‡∏á (‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å)
EXCLUDE_BRANCHES = ['DC011', 'PTDC', 'PTG DISTRIBUTION CENTER']

# ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å (‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠)
EXCLUDE_NAMES = ['Distribution Center', 'PTG Distribution', '‡∏ö.‡∏û‡∏µ‡∏ó‡∏µ‡∏à‡∏µ ‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏ô‡∏≠‡∏¢‡∏µ']

# ‡∏û‡∏¥‡∏Å‡∏±‡∏î DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ (‡∏à‡∏∏‡∏î‡∏Å‡∏•‡∏≤‡∏á)
DC_WANG_NOI_LAT = 14.179394
DC_WANG_NOI_LON = 100.648149

# ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏ñ 6W (‡∏Å‡∏°.)
DISTANCE_REQUIRE_6W = 100  # ‡∏ñ‡πâ‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC ‡πÄ‡∏Å‡∏¥‡∏ô 100 ‡∏Å‡∏°. ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W

# ==========================================
# ZONE/REGION CONFIG - ‡∏£‡∏´‡∏±‡∏™‡∏†‡∏≤‡∏Ñ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
# ==========================================
# ‡∏£‡∏´‡∏±‡∏™‡∏†‡∏≤‡∏Ñ: 1=‡∏Å‡∏•‡∏≤‡∏á, 2=‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å, 3=‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å, 4=‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, 5=‡∏≠‡∏µ‡∏™‡∏≤‡∏ô, 6=‡πÉ‡∏ï‡πâ
REGION_CODE = {
    # ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á (‡∏£‡∏´‡∏±‡∏™ 1)
    '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£': '10', '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø': '10',
    '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ': '11',
    '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ': '12',
    '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤': '13', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤': '13',
    '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ': '14',
    '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ': '15',
    '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ': '16',
    '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á': '17',
    '‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó': '18',
    '‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°': '19',
    '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£': '1A',
    '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£': '1B',
    '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°': '1C',
    
    # ‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å (‡∏£‡∏´‡∏±‡∏™ 2)
    '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ': '20',
    '‡∏£‡∏∞‡∏¢‡∏≠‡∏á': '21',
    '‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ': '22',
    '‡∏ï‡∏£‡∏≤‡∏î': '23',
    '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤': '24',
    '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ': '25',
    '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß': '26',
    '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å': '27',
    
    # ‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å (‡∏£‡∏´‡∏±‡∏™ 3)
    '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ': '30',
    '‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ': '31',
    '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ': '32',
    '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ': '33',
    '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå': '34',
    
    # ‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ (‡∏£‡∏´‡∏±‡∏™ 4) - ‡πÑ‡∏Å‡∏• ‡πÉ‡∏ä‡πâ 6W ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
    '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå': '40',
    '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ': '41',
    '‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£': '42',
    '‡∏ï‡∏≤‡∏Å': '43',
    '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢': '44',
    '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å': '45',
    '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£': '46',
    '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå': '47',
    '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå': '48',
    '‡πÅ‡∏û‡∏£‡πà': '49',
    '‡∏ô‡πà‡∏≤‡∏ô': '4A',
    '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤': '4B',
    '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢': '4C',
    '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà': '4D',
    '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô': '4E',
    '‡∏•‡∏≥‡∏û‡∏π‡∏ô': '4F',
    '‡∏•‡∏≥‡∏õ‡∏≤‡∏á': '4G',
    
    # ‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏â‡∏µ‡∏¢‡∏á‡πÄ‡∏´‡∏ô‡∏∑‡∏≠/‡∏≠‡∏µ‡∏™‡∏≤‡∏ô (‡∏£‡∏´‡∏±‡∏™ 5)
    '‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤': '50', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä': '50',
    '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå': '51',
    '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå': '52',
    '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©': '53',
    '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ': '54',
    '‡∏¢‡πÇ‡∏™‡∏ò‡∏£': '55',
    '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥': '56',
    '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç': '57',
    '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π': '58',
    '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô': '59',
    '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ': '5A',
    '‡πÄ‡∏•‡∏¢': '5B',
    '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢': '5C',
    '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°': '5D',
    '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î': '5E',
    '‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå': '5F',
    '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£': '5G',
    '‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°': '5H',
    '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£': '5I',
    '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨': '5J',
    
    # ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ (‡∏£‡∏´‡∏±‡∏™ 6) - ‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å ‡πÉ‡∏ä‡πâ 6W
    '‡∏ä‡∏∏‡∏°‡∏û‡∏£': '60',
    '‡∏£‡∏∞‡∏ô‡∏≠‡∏á': '61',
    '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ': '62',
    '‡∏û‡∏±‡∏á‡∏á‡∏≤': '63',
    '‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà': '64',
    '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï': '65',
    '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä': '66',
    '‡∏ï‡∏£‡∏±‡∏á': '67',
    '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á': '68',
    '‡∏™‡∏á‡∏Ç‡∏•‡∏≤': '69',
    '‡∏™‡∏ï‡∏π‡∏•': '6A',
    '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ': '6B',
    '‡∏¢‡∏∞‡∏•‡∏≤': '6C',
    '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™': '6D',
}

# ‡∏†‡∏≤‡∏Ñ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (‡πÑ‡∏Å‡∏•‡∏à‡∏≤‡∏Å DC)
REGIONS_REQUIRE_6W = ['4', '5', '6']  # ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô, ‡πÉ‡∏ï‡πâ

# ‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏Ñ
REGION_NAMES = {
    '1': '‡∏Å‡∏•‡∏≤‡∏á',
    '2': '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å',
    '3': '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å',
    '4': '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠',
    '5': '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô',
    '6': '‡πÉ‡∏ï‡πâ',
    '9': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
}

# ==========================================
# HELPER: ZONE/REGION FUNCTIONS
# ==========================================
def get_region_code(province):
    """‡∏î‡∏∂‡∏á‡∏£‡∏´‡∏±‡∏™‡∏†‡∏≤‡∏Ñ/‡πÇ‡∏ã‡∏ô‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î"""
    if not province or str(province).strip() == '' or str(province) == 'nan':
        return '99'  # ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏
    province = str(province).strip()
    return REGION_CODE.get(province, '99')

def get_region_name(province):
    """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏Ñ‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î"""
    code = get_region_code(province)
    if code == '99':
        return '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
    region_prefix = code[0]
    return REGION_NAMES.get(region_prefix, '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')

def get_recommended_vehicle_by_region(province, distance_from_dc=None):
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ/‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á"""
    code = get_region_code(province)
    region_prefix = code[0] if code != '99' else '9'
    
    # ‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô, ‡πÉ‡∏ï‡πâ ‚Üí ‡πÉ‡∏ä‡πâ 6W
    if region_prefix in REGIONS_REQUIRE_6W:
        return '6W'
    
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô threshold ‚Üí ‡πÉ‡∏ä‡πâ 6W
    if distance_from_dc and distance_from_dc > DISTANCE_REQUIRE_6W:
        return '6W'
    
    # ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á, ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å, ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å ‚Üí ‡πÉ‡∏ä‡πâ 4W/JB ‡πÑ‡∏î‡πâ
    return 'JB'  # default ‡πÄ‡∏õ‡πá‡∏ô JB

def sort_branches_by_region_route(branches_df, master_data=None):
    """
    ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí Route
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î
    """
    if branches_df.empty:
        return branches_df
    
    df = branches_df.copy()
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sort
    df['_region_code'] = df['Province'].apply(get_region_code) if 'Province' in df.columns else '99'
    df['_province'] = df['Province'].fillna('') if 'Province' in df.columns else ''
    df['_district'] = df['District'].fillna('') if 'District' in df.columns else ''
    df['_subdistrict'] = df['Subdistrict'].fillna('') if 'Subdistrict' in df.columns else ''
    
    # ‡πÅ‡∏¢‡∏Å Route number
    if 'Route' in df.columns:
        df['_route_num'] = df['Route'].apply(lambda x: int(str(x).replace('CD', '')) if pd.notna(x) and str(x).startswith('CD') else 99999)
    else:
        df['_route_num'] = 99999
    
    # Sort
    df = df.sort_values(by=['_region_code', '_province', '_district', '_subdistrict', '_route_num'])
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
    df = df.drop(columns=['_region_code', '_province', '_district', '_subdistrict', '_route_num'])
    
    return df.reset_index(drop=True)

def check_trip_route_spread(trip_df):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏°‡∏µ Route ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡πÑ‡∏´‡∏°
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (route_range, is_spread, provinces)
    """
    if trip_df.empty or 'Route' not in trip_df.columns:
        return 0, False, []
    
    routes = trip_df['Route'].dropna().unique()
    route_nums = []
    for r in routes:
        if pd.notna(r) and str(r).startswith('CD'):
            try:
                route_nums.append(int(str(r).replace('CD', '')))
            except:
                pass
    
    if len(route_nums) < 2:
        return 0, False, trip_df['Province'].dropna().unique().tolist() if 'Province' in trip_df.columns else []
    
    route_range = max(route_nums) - min(route_nums)
    is_spread = route_range > 4000  # ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 4000 ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢
    
    provinces = trip_df['Province'].dropna().unique().tolist() if 'Province' in trip_df.columns else []
    
    return route_range, is_spread, provinces

def validate_trip_vehicle(trip_df, assigned_vehicle):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏Ñ/‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (is_valid, recommended_vehicle, reason)
    """
    if trip_df.empty:
        return True, assigned_vehicle, ''
    
    provinces = trip_df['Province'].dropna().unique() if 'Province' in trip_df.columns else []
    
    # ‡∏´‡∏≤‡∏†‡∏≤‡∏Ñ‡∏ó‡∏µ‡πà‡πÑ‡∏Å‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
    farthest_region = '1'  # default ‡∏Å‡∏•‡∏≤‡∏á
    for prov in provinces:
        code = get_region_code(prov)
        region = code[0] if code != '99' else '1'
        if region > farthest_region:
            farthest_region = region
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
    if farthest_region in REGIONS_REQUIRE_6W:
        # ‡∏†‡∏≤‡∏Ñ‡πÑ‡∏Å‡∏• ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ 6W
        if assigned_vehicle in ['4W', 'JB']:
            return False, '6W', f'‡∏†‡∏≤‡∏Ñ{REGION_NAMES.get(farthest_region, "‡πÑ‡∏Å‡∏•")} ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ 6W'
    
    return True, assigned_vehicle, ''

# ==========================================
# LOAD MASTER DATA
# ==========================================
@st.cache_data(ttl=7200)  # Cache 2 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)
def load_master_data():
    """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Master ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á (Optimized)"""
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
        usecols = ['Plan Code', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î']
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        possible_files = ['Dc/‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á.xlsx', 'Dc/Master ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á.xlsx']
        df_master = pd.DataFrame()
        for file_path in possible_files:
            try:
                df_master = pd.read_excel(file_path, usecols=usecols)
                break
            except:
                continue
        if df_master.empty:
            return pd.DataFrame()
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Plan Code (vectorized)
        if 'Plan Code' in df_master.columns:
            df_master['Plan Code'] = df_master['Plan Code'].astype(str).str.strip().str.upper()
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á dict ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß
        df_master = df_master[df_master['Plan Code'] != '']
        return df_master
    except FileNotFoundError:
        return pd.DataFrame()
    except Exception as e:
        try:
            st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Master: {e} (‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ó‡∏ô)")
        except:
            pass
        return pd.DataFrame()

# ‡πÇ‡∏´‡∏•‡∏î Master Data
MASTER_DATA = load_master_data()

# ==========================================
# CLEAN NAME FUNCTION (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥ Join_Key)
# ==========================================
def clean_name(text):
    """
    ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠: ‡∏•‡∏ö prefix ‡∏à./‡∏≠./‡∏ï. ‡πÅ‡∏•‡∏∞ trim whitespace
    ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Join_Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Master Data
    """
    if pd.isna(text) or text is None:
        return ''
    text = str(text)
    # ‡∏•‡∏ö prefix ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    text = text.replace('‡∏à. ', '').replace('‡∏à.', '')
    text = text.replace('‡∏≠. ', '').replace('‡∏≠.', '')
    text = text.replace('‡∏ï. ', '').replace('‡∏ï.', '')
    # ‡∏•‡∏ö prefix ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    text = text.replace('Tambon ', '').replace('Amphoe ', '').replace('Changwat ', '')
    return text.strip()

def normalize_province_name(province):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô)
    """
    if pd.isna(province) or province is None:
        return ''
    province = clean_name(province)
    # Mapping ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
    province_mapping = {
        '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤': '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤',
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø': '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£',
        '‡∏Å‡∏ó‡∏°': '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£',
        '‡∏Å‡∏ó‡∏°.': '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£',
        '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä': '‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤',
    }
    return province_mapping.get(province, province)

def load_master_dist_data():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Master Dist.xlsx ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:
    1. ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏≥‡∏ö‡∏•
    2. Sum_Code (Sort_Code) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå
    
    ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£: ‡πÉ‡∏ä‡πâ Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á Sum_Code ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Sort
    """
    try:
        file_path = 'Dc/Master Dist.xlsx'
        df = pd.read_excel(file_path)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á lookup dict - ‡∏™‡∏≠‡∏á key: Sum_Code ‡πÅ‡∏•‡∏∞ Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•)
        dist_lookup = {}   # key = Sum_Code
        name_lookup = {}   # key = Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•)
        
        for _, row in df.iterrows():
            sum_code = str(row.get('Sum_Code', '')).strip()
            
            # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° sum_code (Sort_Code) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢!
            data = {
                'sum_code': sum_code,  # üîë ‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sort!
                'region': row.get('Region', ''),
                'region_code': row.get('Region_Code', ''),
                'province': row.get('Province', ''),
                'prov_code': row.get('Prov_Code', ''),
                'district': row.get('District', ''),
                'dist_code': row.get('Dist_Code', ''),
                'subdistrict': row.get('Subdistrict', ''),
                'subdist_code': row.get('Subdist_Code', ''),
                'dist_from_dc_km': float(row.get('Dist_from_DC_km', 9999)) if pd.notna(row.get('Dist_from_DC_km')) else 9999,
                'prov_dist_km': float(row.get('Prov_Dist_km', 0)) if pd.notna(row.get('Prov_Dist_km')) else 0,
                'dist_subdist_km': float(row.get('Dist_Subdist_km', 0)) if pd.notna(row.get('Dist_Subdist_km')) else 0,
            }
            
            # Key 1: Sum_Code (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö lookup ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)
            if sum_code:
                dist_lookup[sum_code] = data
            
            # Key 2: Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•) - ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Lookup!
            prov_raw = str(row.get('Province', ''))
            dist_raw = str(row.get('District', ''))
            subdist_raw = str(row.get('Subdistrict', ''))
            
            # Clean name ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Join
            prov_clean = clean_name(prov_raw)
            dist_clean = clean_name(dist_raw)
            subdist_clean = clean_name(subdist_raw)
            
            # Join_Key ‡πÅ‡∏ö‡∏ö clean (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)
            join_key = f"{prov_clean}_{dist_clean}_{subdist_clean}"
            if join_key and join_key != '__':
                name_lookup[join_key] = data
            
            # Join_Key ‡πÅ‡∏ö‡∏ö normalized province (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô)
            prov_normalized = normalize_province_name(prov_raw)
            if prov_normalized != prov_clean:
                alt_key = f"{prov_normalized}_{dist_clean}_{subdist_clean}"
                if alt_key and alt_key != '__':
                    name_lookup[alt_key] = data
            
            # Join_Key ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ prefix (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ prefix)
            raw_key = f"{prov_raw.strip()}_{dist_raw.strip()}_{subdist_raw.strip()}"
            if raw_key and raw_key != '__' and raw_key not in name_lookup:
                name_lookup[raw_key] = data
        
        return {'by_code': dist_lookup, 'by_name': name_lookup}
    except Exception as e:
        return {'by_code': {}, 'by_name': {}}

# ‡πÇ‡∏´‡∏•‡∏î Master Dist Data
MASTER_DIST_DATA = load_master_dist_data()

# ==========================================
# PUNTHAI/MAXMART BUFFER FUNCTIONS
# ==========================================
def is_punthai_only(trip_data):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô Punthai ‡∏•‡πâ‡∏ß‡∏ô, Maxmart ‡∏•‡πâ‡∏ß‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏™‡∏°
    
    Returns:
        'punthai_only': ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô Punthai (BU = 211 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ PUNTHAI)
        'maxmart_only': ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô Maxmart (BU = 200 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ MAXMART)
        'mixed': ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á Punthai ‡πÅ‡∏•‡∏∞ Maxmart
        'other': ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• BU
    """
    if trip_data is None or len(trip_data) == 0:
        return 'other'
    
    punthai_count = 0
    maxmart_count = 0
    total_count = len(trip_data)
    
    for _, row in trip_data.iterrows():
        bu = row.get('BU', None)
        name = str(row.get('Name', '')).upper()
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ Punthai: BU = 211 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ PUNTHAI
        if bu == 211 or bu == '211' or 'PUNTHAI' in name or 'PUN-' in name:
            punthai_count += 1
        # ‡πÄ‡∏ä‡πá‡∏Ñ Maxmart: BU = 200 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ MAXMART/MAX MART
        elif bu == 200 or bu == '200' or 'MAXMART' in name or 'MAX MART' in name:
            maxmart_count += 1
    
    if punthai_count == total_count:
        return 'punthai_only'
    elif maxmart_count == total_count:
        return 'maxmart_only'
    elif punthai_count > 0 or maxmart_count > 0:
        return 'mixed'
    else:
        return 'other'

def get_buffer_for_trip(trip_data):
    """
    ‡∏î‡∏∂‡∏á Buffer ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏° BU ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ
    
    Rules:
    - Punthai ‡∏•‡πâ‡∏ß‡∏ô: BUFFER = 1.0 (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 100%)
    - Maxmart ‡∏•‡πâ‡∏ß‡∏ô/‡∏ú‡∏™‡∏°: BUFFER = 1.10 (‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏î‡πâ 10%)
    
    Returns:
        float: buffer multiplier (1.0 ‡∏´‡∏£‡∏∑‡∏≠ 1.10)
    """
    trip_type = is_punthai_only(trip_data)
    
    if trip_type == 'punthai_only':
        return PUNTHAI_BUFFER  # 1.0 - ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 100%
    elif trip_type in ['maxmart_only', 'mixed']:
        return MAXMART_BUFFER  # 1.10 - ‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏î‡πâ 10%
    else:
        return BUFFER  # default 1.0

def get_punthai_drop_limit(trip_data, vehicle_type):
    """
    ‡∏î‡∏∂‡∏á‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Drop ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Punthai ‡∏•‡πâ‡∏ß‡∏ô
    
    Rules:
    - Punthai ‡∏•‡πâ‡∏ß‡∏ô + 4W: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5 ‡∏™‡∏≤‡∏Ç‡∏≤
    - Punthai ‡∏•‡πâ‡∏ß‡∏ô + JB: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 7 drop
    - ‡∏≠‡∏∑‡πà‡∏ô‡πÜ: ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î (999)
    
    Returns:
        int: max drops allowed
    """
    trip_type = is_punthai_only(trip_data)
    
    if trip_type == 'punthai_only':
        return PUNTHAI_LIMITS.get(vehicle_type, {}).get('max_drops', 999)
    else:
        return 999  # ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î

@st.cache_data(ttl=3600)  # Cache 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
def load_booking_history_restrictions():
    """‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡∏à‡∏≤‡∏Å Booking History - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á 3,053 booking (Optimized)"""
    try:
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Booking History (‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö)
        possible_files = [
            'Dc/‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏™‡πà‡∏á DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢(1).xlsx',
            'Dc/‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏™‡πà‡∏á DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢.xlsx',
            'branch_vehicle_restrictions_from_booking.xlsx'
        ]
        
        file_path = None
        for path in possible_files:
            if os.path.exists(path):
                file_path = path
                break
        
        if not file_path:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (fallback)
            return load_learned_restrictions_fallback()
        
        df = pd.read_excel(file_path)
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ
        vehicle_mapping = {
            '4 ‡∏•‡πâ‡∏≠ ‡∏à‡∏±‡∏°‡πÇ‡∏ö‡πâ ‡∏ï‡∏π‡πâ‡∏ó‡∏∂‡∏ö': 'JB',
            '6 ‡∏•‡πâ‡∏≠ ‡∏ï‡∏π‡πâ‡∏ó‡∏∂‡∏ö': '6W',
            '4 ‡∏•‡πâ‡∏≠ ‡∏ï‡∏π‡πâ‡∏ó‡∏∂‡∏ö': '4W'
        }
        df['Vehicle_Type'] = df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ'].map(vehicle_mapping)
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏≤‡∏Ç‡∏≤-‡∏£‡∏ñ
        branch_vehicle_history = {}
        booking_groups = df.groupby('Booking No')
        
        for booking_no, booking_data in booking_groups:
            vehicle_types = booking_data['Vehicle_Type'].dropna().unique()
            if len(vehicle_types) > 0:
                vehicle = booking_data['Vehicle_Type'].mode()[0] if len(booking_data['Vehicle_Type'].mode()) > 0 else vehicle_types[0]
                for branch_code in booking_data['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤'].dropna().unique():
                    if branch_code not in branch_vehicle_history:
                        branch_vehicle_history[branch_code] = []
                    branch_vehicle_history[branch_code].append(vehicle)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á restrictions
        branch_restrictions = {}
        vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
        
        for branch_code, vehicle_list in branch_vehicle_history.items():
            vehicles_used = set(vehicle_list)
            vehicle_counts = pd.Series(vehicle_list).value_counts().to_dict()
            
            if len(vehicles_used) == 1:
                # STRICT - ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                vehicle = list(vehicles_used)[0]
                branch_restrictions[str(branch_code)] = {
                    'max_vehicle': vehicle,
                    'allowed': [vehicle],
                    'total_bookings': len(vehicle_list),
                    'restriction_type': 'STRICT'
                }
            else:
                # FLEXIBLE - ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                max_vehicle = max(vehicles_used, key=lambda v: vehicle_sizes.get(v, 0))
                branch_restrictions[str(branch_code)] = {
                    'max_vehicle': max_vehicle,
                    'allowed': list(vehicles_used),
                    'total_bookings': len(vehicle_list),
                    'restriction_type': 'FLEXIBLE'
                }
        
        stats = {
            'total_branches': len(branch_restrictions),
            'strict': len([b for b, r in branch_restrictions.items() if r['restriction_type'] == 'STRICT']),
            'flexible': len([b for b, r in branch_restrictions.items() if r['restriction_type'] == 'FLEXIBLE']),
            'total_bookings': len(booking_groups)
        }
        
        return {
            'branch_restrictions': branch_restrictions,
            'stats': stats
        }
    except Exception as e:
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î error ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ó‡∏ô
        return load_learned_restrictions_fallback()

def load_learned_restrictions_fallback():
    """
    ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å Booking History (backup)
    ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ
    
    ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå 3,053 bookings, 2,790 ‡∏™‡∏≤‡∏Ç‡∏≤:
    - JB: ‡∏£‡∏ñ‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 54.7%)
    - 6W: ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà (30.1%)
    - 4W: ‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å (0.2%)
    
    ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• default ‡πÄ‡∏õ‡πá‡∏ô JB (‡∏£‡∏ñ‡∏Å‡∏•‡∏≤‡∏á ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà)
    """
    return {
        'branch_restrictions': {},
        'stats': {
            'total_branches': 0,
            'strict': 0,
            'flexible': 0,
            'total_bookings': 0,
            'fallback': True,
            'message': '‡πÉ‡∏ä‡πâ Punthai ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Booking History)'
        }
    }

@st.cache_data(ttl=3600)  # Cache 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
def load_punthai_reference():
    """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Punthai Maxmart ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ (Location patterns - Optimized)"""
    try:
        file_path = 'Dc/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô Punthai Maxmart ‡∏£‡∏≠‡∏ö‡∏™‡∏±‡πà‡∏á 24‡∏´‡∏¢‡∏¥‡∏ö 25‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2568 To.‡πÄ‡∏ü‡∏¥(1) - ‡∏™‡∏≥‡πÄ‡∏ô‡∏≤.xlsx'
        df = pd.read_excel(file_path, sheet_name='2.Punthai', header=1)
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ Trip ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà DC/Distribution Center
        df_clean = df[df['Trip'].notna()].copy()
        df_clean = df_clean[~df_clean['BranchCode'].isin(['DC011', 'PTDC', 'PTG Distribution Center'])].copy()
        
        # Extract vehicle type from Trip no (‡πÄ‡∏ä‡πà‡∏ô 4W009 ‚Üí 4W)
        df_clean['Vehicle_Type'] = df_clean['Trip no'].apply(
            lambda x: str(x)[:2] if pd.notna(x) else 'Unknown'
        )
        
        # Merge ‡∏Å‡∏±‡∏ö Master ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡∏ö‡∏•/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        try:
            df_master = pd.read_excel('Dc/Master ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á.xlsx')
            df_clean = df_clean.merge(
                df_master[['Plan Code', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î']],
                left_on='BranchCode',
                right_on='Plan Code',
                how='left'
            )
        except:
            pass
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡∏à‡∏≤‡∏Å Punthai (‡πÅ‡∏ú‡∏ô) - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Booking
        punthai_restrictions = {}
        vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
        
        for branch_code in df_clean['BranchCode'].unique():
            branch_data = df_clean[df_clean['BranchCode'] == branch_code]
            vehicles_used = set(branch_data['Vehicle_Type'].dropna().tolist())
            vehicles_used = {v for v in vehicles_used if v in ['4W', 'JB', '6W']}
            
            if vehicles_used:
                if len(vehicles_used) == 1:
                    vehicle = list(vehicles_used)[0]
                    punthai_restrictions[str(branch_code)] = {
                        'max_vehicle': vehicle,
                        'allowed': [vehicle],
                        'source': 'PUNTHAI'
                    }
                else:
                    max_vehicle = max(vehicles_used, key=lambda v: vehicle_sizes.get(v, 0))
                    punthai_restrictions[str(branch_code)] = {
                        'max_vehicle': max_vehicle,
                        'allowed': list(vehicles_used),
                        'source': 'PUNTHAI'
                    }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á dictionary: Trip ‚Üí ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (location patterns)
        trip_patterns = {}
        location_stats = {
            'same_province': 0,
            'mixed_province': 0,
            'avg_branches': 0
        }
        
        for trip_num in df_clean['Trip'].unique():
            trip_data = df_clean[df_clean['Trip'] == trip_num]
            
            # Get location info
            provinces = set(trip_data['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'].dropna().tolist()) if '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in trip_data.columns else set()
            
            # Count same vs mixed province
            if len(provinces) == 1:
                location_stats['same_province'] += 1
            elif len(provinces) > 1:
                location_stats['mixed_province'] += 1
            
            trip_patterns[int(trip_num)] = {
                'branches': len(trip_data),
                'codes': trip_data['BranchCode'].tolist(),
                'weight': trip_data['TOTALWGT'].sum() if 'TOTALWGT' in trip_data.columns else 0,
                'cube': trip_data['TOTALCUBE'].sum() if 'TOTALCUBE' in trip_data.columns else 0,
                'provinces': list(provinces),
                'same_province': len(provinces) == 1
            }
        
        # Calculate stats
        if trip_patterns:
            location_stats['avg_branches'] = sum(t['branches'] for t in trip_patterns.values()) / len(trip_patterns)
            total = location_stats['same_province'] + location_stats['mixed_province']
            location_stats['same_province_pct'] = (location_stats['same_province'] / total * 100) if total > 0 else 0
        
        return {
            'patterns': trip_patterns, 
            'stats': location_stats,
            'punthai_restrictions': punthai_restrictions
        }
    except:
        return {'patterns': {}, 'stats': {}, 'punthai_restrictions': {}}

# ‡πÇ‡∏´‡∏•‡∏î Booking History (‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ)
BOOKING_RESTRICTIONS = load_booking_history_restrictions()

# ‡πÇ‡∏´‡∏•‡∏î Punthai Reference (location patterns)
PUNTHAI_PATTERNS = load_punthai_reference()

# ==========================================
# HELPER FUNCTIONS
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def calculate_distance(lat1, lon1, lat2, lon2):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏á‡∏à‡∏∏‡∏î (‡∏Å‡∏°.) - Haversine formula"""
    if lat1 == 0 or lon1 == 0 or lat2 == 0 or lon2 == 0:
        return 0
    import math
    lat1_rad, lon1_rad = math.radians(lat1), math.radians(lon1)
    lat2_rad, lon2_rad = math.radians(lat2), math.radians(lon2)
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad
    a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2)**2
    c = 2 * math.asin(math.sqrt(a))
    return 6371 * c

def calculate_distance_from_dc(lat, lon):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ (‡∏Å‡∏°.)"""
    return calculate_distance(DC_WANG_NOI_LAT, DC_WANG_NOI_LON, lat, lon)

def check_branch_vehicle_compatibility(branch_code, vehicle_type):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏° (‡∏£‡∏ß‡∏° Booking + Punthai)"""
    branch_code_str = str(branch_code).strip()
    
    # 1. ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Booking History ‡∏Å‡πà‡∏≠‡∏ô (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)
    booking_restrictions = BOOKING_RESTRICTIONS.get('branch_restrictions', {})
    if branch_code_str in booking_restrictions:
        allowed = booking_restrictions[branch_code_str].get('allowed', [])
        return vehicle_type in allowed
    
    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Punthai (‡πÅ‡∏ú‡∏ô)
    punthai_restrictions = PUNTHAI_PATTERNS.get('punthai_restrictions', {})
    if branch_code_str in punthai_restrictions:
        allowed = punthai_restrictions[branch_code_str].get('allowed', [])
        return vehicle_type in allowed
    
    # 3. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• = ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô
    return True

def get_max_vehicle_for_branch(branch_code):
    """‡∏î‡∏∂‡∏á‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (‡∏£‡∏ß‡∏° Booking History + Punthai)"""
    branch_code_str = str(branch_code).strip()
    
    # 1. ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Booking History ‡∏Å‡πà‡∏≠‡∏ô (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏™‡∏π‡∏á)
    booking_restrictions = BOOKING_RESTRICTIONS.get('branch_restrictions', {})
    if branch_code_str in booking_restrictions:
        return booking_restrictions[branch_code_str].get('max_vehicle', '6W')
    
    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Punthai (‡πÅ‡∏ú‡∏ô - ‡∏™‡∏≥‡∏£‡∏≠‡∏á)
    punthai_restrictions = PUNTHAI_PATTERNS.get('punthai_restrictions', {})
    if branch_code_str in punthai_restrictions:
        return punthai_restrictions[branch_code_str].get('max_vehicle', '6W')
    
    # 3. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á = ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏î‡πâ
    return '6W'

def get_max_vehicle_for_trip(trip_codes):
    """
    ‡∏´‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ)
    
    Args:
        trip_codes: set ‡∏Ç‡∏≠‡∏á branch codes ‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
    
    Returns:
        str: '4W', 'JB', ‡∏´‡∏£‡∏∑‡∏≠ '6W'
    """
    vehicle_priority = {'4W': 1, 'JB': 2, '6W': 3}
    max_allowed = '6W'  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤
    min_priority = 3  # ‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î
    
    for code in trip_codes:
        branch_max = get_max_vehicle_for_branch(code)
        priority = vehicle_priority.get(branch_max, 3)
        
        # üîí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î) ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
        if priority < min_priority:
            min_priority = priority
            max_allowed = branch_max
    
    return max_allowed

def get_required_vehicle_by_distance(branch_code):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC"""
    # ‡∏î‡∏∂‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏≤‡∏Å Master
    if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
        master_row = MASTER_DATA[MASTER_DATA['Plan Code'] == branch_code]
        if len(master_row) > 0:
            lat = master_row.iloc[0].get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
            lon = master_row.iloc[0].get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
            distance = calculate_distance_from_dc(lat, lon)
            
            # ‡∏ñ‡πâ‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W
            if distance > DISTANCE_REQUIRE_6W:
                return '6W', distance
    
    return None, 0

def can_fit_truck(total_weight, total_cube, truck_type):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡πÉ‡∏™‡πà‡∏£‡∏ñ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    limits = LIMITS[truck_type]
    max_w = limits['max_w'] * BUFFER
    max_c = limits['max_c'] * BUFFER
    return total_weight <= max_w and total_cube <= max_c

def suggest_truck(total_weight, total_cube, max_allowed='6W', trip_codes=None):
    """
    ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà:
    1. ‡πÉ‡∏™‡πà‡∏Ç‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏û‡∏≠‡∏î‡∏µ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î 105%)
    2. ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÉ‡∏Å‡∏•‡πâ 100% ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: 90-100%)
    3. ‡πÄ‡∏Ñ‡∏≤‡∏£‡∏û‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà 4W = ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 4W ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)
    """
    vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
    max_size = vehicle_sizes.get(max_allowed, 3)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°
    branch_max_vehicle = '4W'  # üîí ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà 4W (‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏∏‡∏î) ‡πÅ‡∏•‡πâ‡∏ß‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    if trip_codes is not None and len(trip_codes) > 0:
        for code in trip_codes:
            branch_max = get_max_vehicle_for_branch(code)
            # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
            if vehicle_sizes.get(branch_max, 3) < vehicle_sizes.get(branch_max_vehicle, 3):
                branch_max_vehicle = branch_max
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î max_allowed ‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤
        if vehicle_sizes.get(branch_max_vehicle, 3) < max_size:
            max_allowed = branch_max_vehicle
            max_size = vehicle_sizes.get(max_allowed, 3)
    
    best_truck = None
    best_utilization = 0
    best_distance_from_100 = 999  # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å 100%
    
    for truck in ['4W', 'JB', '6W']:
        truck_size = vehicle_sizes.get(truck, 0)
        # ‡∏ñ‡πâ‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ
        if truck_size > max_size:
            continue
        if can_fit_truck(total_weight, total_cube, truck):
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ
            limits = LIMITS[truck]
            w_util = (total_weight / limits['max_w']) * 100
            c_util = (total_cube / limits['max_c']) * 100
            utilization = max(w_util, c_util)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å 100%
            distance_from_100 = abs(100 - utilization)
            
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ 100% ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (90-105% ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢)
            # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤
            if best_truck is None:
                best_truck = truck
                best_utilization = utilization
                best_distance_from_100 = distance_from_100
            else:
                # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 90-105% ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ 100% ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                if 90 <= utilization <= 105:
                    if distance_from_100 < best_distance_from_100 or best_utilization < 90:
                        best_truck = truck
                        best_utilization = utilization
                        best_distance_from_100 = distance_from_100
                # ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤
                elif utilization > best_utilization:
                    best_truck = truck
                    best_utilization = utilization
                    best_distance_from_100 = distance_from_100
    
    if best_truck:
        return best_truck
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
    return max_allowed if max_allowed in LIMITS else '6W+'

def calculate_optimal_vehicle_split(total_weight, total_cube, max_allowed='6W', branch_count=0):
    """
    üöõ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
    
    ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç:
    - 4W: ‚â§12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 5
    - JB: ‚â§12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 8  
    - 6W: ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î, Cube ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡πá‡∏° ‚â•100%
    
    ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:
    1. 4W (‡∏ñ‡πâ‡∏≤ cube ‚â§ 5)
    2. JB (‡∏ñ‡πâ‡∏≤ cube ‚â§ 8)
    3. JB + 4W (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    4. JB + JB (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    5. 6W + JB (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    6. 4W + 4W (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    7. 6W (cube ‡∏ï‡πâ‡∏≠‡∏á ‚â•100%)
    
    Returns: (vehicle_type, split_needed, split_config)
    """
    vehicle_priority = {'4W': 1, 'JB': 2, '6W': 3}
    max_priority = vehicle_priority.get(max_allowed, 3)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì utilization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏ñ (‡πÉ‡∏ä‡πâ Cube ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å)
    cube_util_4w = (total_cube / LIMITS['4W']['max_c']) * 100  # max 5 cube
    cube_util_jb = (total_cube / LIMITS['JB']['max_c']) * 100  # max 8 cube
    cube_util_6w = (total_cube / LIMITS['6W']['max_c']) * 100  # max 20 cube
    
    weight_util_4w = (total_weight / LIMITS['4W']['max_w']) * 100
    weight_util_jb = (total_weight / LIMITS['JB']['max_w']) * 100
    weight_util_6w = (total_weight / LIMITS['6W']['max_w']) * 100
    
    # üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: Utilization 75%-95% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å, 95%-105% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    SPLIT_MIN = 75   # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å
    SPLIT_MAX = 95   # ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å
    SINGLE_MIN = 95  # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    SINGLE_MAX = 105 # ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤ (4W/JB ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 12 ‡∏à‡∏∏‡∏î)
    branch_ok_for_small = branch_count <= 12 or branch_count == 0
    
    # 1. ‡∏•‡∏≠‡∏á 4W ‡∏Å‡πà‡∏≠‡∏ô (‡∏ñ‡πâ‡∏≤ cube ‚â§ 5 ‡πÅ‡∏•‡∏∞ ‚â§12 ‡∏à‡∏∏‡∏î)
    if max_priority >= 1 and total_cube <= 5.0 and branch_ok_for_small:
        if cube_util_4w <= 105 and weight_util_4w <= 105:
            return ('4W', False, None)
    
    # 2. ‡∏•‡∏≠‡∏á JB (‡∏ñ‡πâ‡∏≤ cube ‚â§ 8 ‡πÅ‡∏•‡∏∞ ‚â§12 ‡∏à‡∏∏‡∏î)
    if max_priority >= 2 and total_cube <= 8.0 and branch_ok_for_small:
        if cube_util_jb <= 105 and weight_util_jb <= 105:
            return ('JB', False, None)
    
    # 3. ‡∏ñ‡πâ‡∏≤‡∏£‡∏ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏°‡πà‡∏û‡∏≠ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏¢‡∏Å (cube > 8 ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏∏‡∏î > 12)
    need_split = total_cube > 8.0 or not branch_ok_for_small
    
    if need_split:
        # üîÑ ‡∏•‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö - ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô
        
        # JB + 4W (JB 8 cube + 4W 5 cube = 13 cube max)
        if max_priority >= 2 and total_cube <= 13.0:
            # ‡πÅ‡∏ö‡πà‡∏á: JB ‡∏£‡∏±‡∏ö cube ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤, 4W ‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
            jb_cube = min(total_cube * 0.6, 8.0)  # JB ‡∏£‡∏±‡∏ö 60% ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 8
            four_w_cube = total_cube - jb_cube
            
            jb_util = (jb_cube / LIMITS['JB']['max_c']) * 100
            four_w_util = (four_w_cube / LIMITS['4W']['max_c']) * 100
            
            if SPLIT_MIN <= jb_util <= SPLIT_MAX and SPLIT_MIN <= four_w_util <= SPLIT_MAX:
                return ('JB', True, {'split': ['JB', '4W'], 'ratio': [jb_cube/total_cube, four_w_cube/total_cube]})
        
        # JB + JB (JB 8 + JB 8 = 16 cube max)
        if max_priority >= 2 and total_cube <= 16.0:
            jb_util_half = (total_cube / 2 / LIMITS['JB']['max_c']) * 100
            if SPLIT_MIN <= jb_util_half <= SPLIT_MAX:
                return ('JB', True, {'split': ['JB', 'JB'], 'ratio': [0.5, 0.5]})
        
        # 6W + JB (6W 20 + JB 8 = 28 cube max)
        if max_priority >= 3 and total_cube <= 28.0:
            # ‡πÅ‡∏ö‡πà‡∏á: 6W ‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà
            six_w_cube = min(total_cube * 0.7, 20.0)
            jb_cube = total_cube - six_w_cube
            
            six_w_util = (six_w_cube / LIMITS['6W']['max_c']) * 100
            jb_util = (jb_cube / LIMITS['JB']['max_c']) * 100
            
            if six_w_util >= 75 and SPLIT_MIN <= jb_util <= SPLIT_MAX:
                return ('6W', True, {'split': ['6W', 'JB'], 'ratio': [six_w_cube/total_cube, jb_cube/total_cube]})
        
        # 4W + 4W (4W 5 + 4W 5 = 10 cube max) - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î 4W
        if max_priority == 1 and total_cube <= 10.0:
            four_w_util_half = (total_cube / 2 / LIMITS['4W']['max_c']) * 100
            if SPLIT_MIN <= four_w_util_half <= SPLIT_MAX:
                return ('4W', True, {'split': ['4W', '4W'], 'ratio': [0.5, 0.5]})
    
    # 4. 6W (‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î ‡πÅ‡∏ï‡πà cube ‡∏ï‡πâ‡∏≠‡∏á ‚â•100%)
    if max_priority >= 3:
        if cube_util_6w >= 100:
            return ('6W', False, None)
        elif cube_util_6w >= 80:
            # 6W ‡πÑ‡∏°‡πà‡πÄ‡∏ï‡πá‡∏° (80-99%) ‚Üí ‡∏¢‡∏±‡∏á‡∏û‡∏≠‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ
            return ('6W', False, None)
        else:
            # 6W ‡∏ß‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å (<80%) ‚Üí ‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô JB ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ
            if total_cube <= 8.0 and branch_ok_for_small and max_priority >= 2:
                return ('JB', False, None)
            # ‡∏ñ‡πâ‡∏≤ JB ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô 4W
            if total_cube <= 5.0 and branch_ok_for_small:
                return ('4W', False, None)
    
    # Default: ‡πÉ‡∏ä‡πâ max_allowed
    return (max_allowed, False, None)

def can_branch_use_vehicle(code, vehicle_type, branch_vehicles):
    """
    ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà = ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ
    - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å (‡πÄ‡∏ä‡πà‡∏ô 4W) = ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ)
    """
    if not branch_vehicles or code not in branch_vehicles:
        return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    if vehicle_type in vehicle_history:
        return True
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ (6W > JB > 4W)
    vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
    requested_size = vehicle_sizes.get(vehicle_type, 0)
    
    # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ
    max_used_size = max(vehicle_sizes.get(v, 0) for v in vehicle_history)
    
    # ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    # ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ)
    return requested_size <= max_used_size

def get_max_vehicle_for_branch_old(code, branch_vehicles):
    """[OLD] ‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ)"""
    if not branch_vehicles or code not in branch_vehicles:
        return '6W'  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 6W
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return '6W'
    
    vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
    max_vehicle = max(vehicle_history.keys(), key=lambda v: vehicle_sizes.get(v, 0))
    return max_vehicle

def get_most_used_vehicle_for_branch(code, branch_vehicles):
    """‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    if not branch_vehicles or code not in branch_vehicles:
        return None
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return None
    
    return max(vehicle_history, key=vehicle_history.get)

def is_similar_name(name1, name2):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© + ‡∏î‡∏π‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"""
    def extract_keywords(name):
        """‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤"""
        if pd.isna(name) or name is None:
            return set(), "", ""
        s = str(name).strip().upper()
        
        # ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà (‡πÑ‡∏ó‡∏¢ + ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
        keywords = set()
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏ö‡∏ö exact match
        important_words = [
            '‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£‡πå', 'FUTURE', '‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï', 'RANGSIT',
            '‡πÄ‡∏ã‡πá‡∏ô‡∏ó‡∏£‡∏±‡∏•', 'CENTRAL', '‡πÄ‡∏ó‡∏™‡πÇ‡∏Å‡πâ', 'TESCO', '‡πÇ‡∏•‡∏ï‡∏±‡∏™', 'LOTUS',
            '‡∏ö‡∏¥‡πä‡∏Å‡∏ã‡∏µ', 'BIGC', '‡πÅ‡∏°‡πá‡∏Ñ‡πÇ‡∏Ñ‡∏£', 'MAKRO', '‡πÇ‡∏Æ‡∏°‡πÇ‡∏õ‡∏£', 'HOMEPRO',
            '‡∏ã‡∏µ‡∏Ñ‡∏≠‡∏ô', 'SEACON', '‡πÄ‡∏°‡∏Å‡∏≤', 'MEGA', '‡∏û‡∏≤‡∏£‡∏≤‡πÑ‡∏î‡∏ã‡πå', 'PARADISE',
            '‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏≠‡∏•', 'TERMINAL', '‡∏™‡∏¢‡∏≤‡∏°‡∏û‡∏≤‡∏£‡∏≤‡∏Å‡∏≠‡∏ô', 'SIAM', 'PARAGON'
        ]
        
        for word in important_words:
            if word in s:
                keywords.add(word)
        
        # ‡∏•‡∏ö prefix/suffix ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
        prefixes = ['PTC-MRT-', 'FC PTF ', 'PTC-', 'PTC ', 'PUN-', 'PTF ', 
                   'MAXMART', 'CW', 'FC', 'NW', 'MI', 'PI']
        for prefix in prefixes:
            if s.startswith(prefix):
                s = s[len(prefix):].strip()
                break
        
        # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô (M, P, N) ‡∏ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        import re
        if re.match(r'^[MPN]\d', s):
            s = s[1:]
        
        # ‡πÅ‡∏¢‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        thai_chars = ''.join([c for c in s if '\u0e01' <= c <= '\u0e5b'])
        eng_chars = ''.join([c for c in s if c.isalpha() and c.isascii()])
        
        return keywords, thai_chars, eng_chars
    
    keywords1, thai1, eng1 = extract_keywords(name1)
    keywords2, thai2, eng2 = extract_keywords(name2)
    
    # üî• ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£‡πå+‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï)
    if keywords1 and keywords2:
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô >= 2 ‡∏Ñ‡∏≥ ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
        common_keywords = keywords1 & keywords2
        if len(common_keywords) >= 2:
            return True
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô 1 ‡∏Ñ‡∏≥ ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
        if len(common_keywords) >= 1:
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞
            specific_places = {'‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï', 'RANGSIT', '‡πÄ‡∏ã‡πá‡∏ô‡∏ó‡∏£‡∏±‡∏•', 'CENTRAL', '‡∏ã‡∏µ‡∏Ñ‡∏≠‡∏ô', 'SEACON'}
            if common_keywords & specific_places:
                # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏µ‡∏Å 1 ‡∏Ñ‡∏≥ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
                if len(common_keywords) >= 2 or (thai1 and thai2 and len(thai1) >= 4 and thai1[:4] in thai2):
                    return True
    
    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£
    if len(thai1) < 3 and len(eng1) < 3:
        return False
    if len(thai2) < 3 and len(eng2) < 3:
        return False
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    if thai1 and thai2:
        shorter_thai = min(thai1, thai2, key=len)
        longer_thai = max(thai1, thai2, key=len)
        if len(shorter_thai) >= 3 and shorter_thai in longer_thai:
            return True
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ 80%+
        if len(shorter_thai) >= 5:
            common = sum(1 for c in shorter_thai if c in longer_thai)
            if common / len(shorter_thai) >= 0.8:
                return True
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
    if eng1 and eng2:
        shorter_eng = min(eng1, eng2, key=len)
        longer_eng = max(eng1, eng2, key=len)
        if len(shorter_eng) >= 3 and shorter_eng in longer_eng:
            return True
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ 80%+
        if len(shorter_eng) >= 5:
            common = sum(1 for c in shorter_eng if c in longer_eng)
            if common / len(shorter_eng) >= 0.8:
                return True
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡πÄ‡∏ä‡πà‡∏ô Future = ‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£‡πå, Rangsit = ‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï)
    thai_eng_map = {
        'RANGSIT': '‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï',
        'FUTURE': '‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£',
        'PARK': '‡∏õ‡∏≤‡∏£‡∏Ñ',
        'TRIANGLE': '‡πÑ‡∏ï‡∏£‡πÅ‡∏≠‡∏á‡πÄ‡∏Å‡∏¥‡∏•',
    }
    
    for eng_word, thai_word in thai_eng_map.items():
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ù‡∏±‡πà‡∏á (‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏´‡∏£‡∏∑‡∏≠ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏´‡∏£‡∏∑‡∏≠ ‡πÑ‡∏ó‡∏¢-‡πÑ‡∏ó‡∏¢)
        has_eng_in_1 = eng_word in eng1
        has_eng_in_2 = eng_word in eng2
        has_thai_in_1 = thai_word in thai1
        has_thai_in_2 = thai_word in thai2
        
        # ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©) = ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
        if (has_eng_in_1 and has_eng_in_2) or (has_thai_in_1 and has_thai_in_2):
            return True
        # ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤ (‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡πÑ‡∏ó‡∏¢)
        if (has_eng_in_1 and has_thai_in_2) or (has_eng_in_2 and has_thai_in_1):
            return True
    
    return False

def haversine_distance(lat1, lon1, lat2, lon2):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡πÇ‡∏•‡∏Å (km)
    ‡πÉ‡∏ä‡πâ‡∏™‡∏π‡∏ï‡∏£ Haversine
    """
    from math import radians, sin, cos, sqrt, atan2
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏á‡∏®‡∏≤‡πÄ‡∏õ‡πá‡∏ô radians
    lat1_rad = radians(lat1)
    lon1_rad = radians(lon1)
    lat2_rad = radians(lat2)
    lon2_rad = radians(lon2)
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad
    
    # ‡∏™‡∏π‡∏ï‡∏£ Haversine
    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    
    # ‡∏£‡∏±‡∏®‡∏°‡∏µ‡πÇ‡∏•‡∏Å (km)
    R = 6371.0
    distance = R * c
    
    return distance

def get_region_type(province):
    """
    ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
    
    Returns:
        str: 'nearby' (‡πÉ‡∏Å‡∏•‡πâ - ‡πÉ‡∏ä‡πâ 4W/JB), 'far' (‡πÑ‡∏Å‡∏• - ‡πÉ‡∏ä‡πâ 6W), 
             'very_far' (‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å - ‡∏ï‡πâ‡∏≠‡∏á 6W ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô), 'unknown'
    """
    if pd.isna(province):
        return 'unknown'
    
    prov = str(province).strip()
    
    # üöõ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å‡πÜ (‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô + ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏•‡∏∂‡∏Å) ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    very_far_provinces = [
        # ‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô (‡πÑ‡∏Å‡∏•‡∏à‡∏≤‡∏Å DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ~500-700 ‡∏Å‡∏°.)
        '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô', '‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤',
        # ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏•‡∏∂‡∏Å (‡πÑ‡∏Å‡∏•‡∏à‡∏≤‡∏Å DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ~700-1000 ‡∏Å‡∏°.)
        '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏ï‡∏£‡∏±‡∏á', '‡∏™‡∏ï‡∏π‡∏•'
    ]
    
    for very_far in very_far_provinces:
        if very_far in prov:
            return 'very_far'
    
    # ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û + ‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏• + ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á = ‡πÉ‡∏Å‡∏•‡πâ ‚Üí ‡πÉ‡∏ä‡πâ 4W/JB
    nearby_provinces = [
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û',
        '‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£',
        '‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤',
        '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å'
    ]
    
    for nearby in nearby_provinces:
        if nearby in prov:
            return 'nearby'
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∑‡πà‡∏ô‡πÜ = ‡πÑ‡∏Å‡∏• ‚Üí ‡πÉ‡∏ä‡πâ 6W
    return 'far'

def is_nearby_province(prov1, prov2):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)"""
    if pd.isna(prov1) or pd.isna(prov2):
        return False
    
    if prov1 == prov2:
        return True
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ‡∏¢‡πà‡∏≠‡∏¢ (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
    province_groups = {
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û'],
        '‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•': ['‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£'],
        '‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤'],
        '‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ'],
        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': ['‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå', '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ'],
        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': ['‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ï‡∏£‡∏≤‡∏î', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß', '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': ['‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°', '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨', '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£', '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£', '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π', '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏•‡∏¢'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå', '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô', '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥', '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°', '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÉ‡∏ï‡πâ': ['‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä', '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå', '‡∏¢‡πÇ‡∏™‡∏ò‡∏£', '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©', '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå', '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç', '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ'],
        '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤', '‡∏•‡∏≥‡∏õ‡∏≤‡∏á', '‡∏•‡∏≥‡∏û‡∏π‡∏ô', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÅ‡∏û‡∏£‡πà', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô'],
        '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£', '‡∏ï‡∏≤‡∏Å', '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå', '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£', '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å', '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢', '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå', '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå'],
        '‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏î‡∏≤‡∏°‡∏±‡∏ô': ['‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏ï‡∏£‡∏±‡∏á', '‡∏û‡∏±‡∏á‡∏á‡∏≤', '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏£‡∏∞‡∏ô‡∏≠‡∏á', '‡∏™‡∏ï‡∏π‡∏•'],
        '‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡πà‡∏≤‡∏ß‡πÑ‡∏ó‡∏¢': ['‡∏ä‡∏∏‡∏°‡∏û‡∏£', '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™']
    }
    
    # ‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á 2 ‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    for group, provinces in province_groups.items():
        in_group_1 = any(p in str(prov1) for p in provinces)
        in_group_2 = any(p in str(prov2) for p in provinces)
        
        if in_group_1 and in_group_2:
            return True
    
    return False

def load_model():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
    if not os.path.exists(MODEL_PATH):
        return None
    
    try:
        with open(MODEL_PATH, 'rb') as f:
            model_data = pickle.load(f)
        return model_data
    except Exception as e:
        st.error(f"‚ùå Error loading model: {e}")
        return None

def create_pair_features(code1, code2, branch_info):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤"""
    import math
    
    info1 = branch_info[code1]
    info2 = branch_info[code2]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß
    weight_diff = abs(info1['avg_weight'] - info2['avg_weight'])
    cube_diff = abs(info1['avg_cube'] - info2['avg_cube'])
    weight_sum = info1['avg_weight'] + info2['avg_weight']
    cube_sum = info1['avg_cube'] + info2['avg_cube']
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    same_province = 1 if info1['province'] == info2['province'] else 0
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î
    distance_km = 0.0
    if info1['latitude'] != 0 and info2['latitude'] != 0:
        lat1, lon1 = math.radians(info1['latitude']), math.radians(info1['longitude'])
        lat2, lon2 = math.radians(info2['latitude']), math.radians(info2['longitude'])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
        c = 2 * math.asin(math.sqrt(a))
        distance_km = 6371 * c
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
    freq_product = info1['total_trips'] * info2['total_trips']
    freq_diff = abs(info1['total_trips'] - info2['total_trips'])
    
    # Ratio
    weight_ratio = (info1['avg_weight'] / info2['avg_weight']) if info2['avg_weight'] > 0 else 0
    cube_ratio = (info1['avg_cube'] / info2['avg_cube']) if info2['avg_cube'] > 0 else 0
    
    # ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ
    over_4w = 1 if (weight_sum > 2500 or cube_sum > 5.0) else 0
    over_jb = 1 if (weight_sum > 3500 or cube_sum > 8.0) else 0
    over_6w = 1 if (weight_sum > 5800 or cube_sum > 22.0) else 0
    
    return {
        'weight_sum': weight_sum,
        'cube_sum': cube_sum,
        'weight_diff': weight_diff,
        'cube_diff': cube_diff,
        'same_province': same_province,
        'distance_km': distance_km,
        'avg_weight_1': info1['avg_weight'],
        'avg_weight_2': info2['avg_weight'],
        'avg_cube_1': info1['avg_cube'],
        'avg_cube_2': info2['avg_cube'],
        'freq_product': freq_product,
        'freq_diff': freq_diff,
        'weight_ratio': weight_ratio,
        'cube_ratio': cube_ratio,
        'over_4w': over_4w,
        'over_jb': over_jb,
        'over_6w': over_6w
    }

def load_excel(file_content, sheet_name=None):
    """‡πÇ‡∏´‡∏•‡∏î Excel"""
    try:
        xls = pd.ExcelFile(io.BytesIO(file_content))
        
        target_sheet = None
        if sheet_name and sheet_name in xls.sheet_names:
            target_sheet = sheet_name
        else:
            for s in xls.sheet_names:
                if 'punthai' in s.lower() or '2.' in s.lower():
                    target_sheet = s
                    break
        
        if not target_sheet:
            target_sheet = xls.sheet_names[0]
        
        # ‡∏´‡∏≤ header row
        df_temp = pd.read_excel(xls, sheet_name=target_sheet, header=None)
        header_row = 0
        
        for i in range(min(10, len(df_temp))):
            row_values = df_temp.iloc[i].astype(str).str.upper()
            match_count = sum([
                'BRANCH' in ' '.join(row_values),
                'TRIP' in ' '.join(row_values),
                '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in ' '.join(df_temp.iloc[i].astype(str))
            ])
            if match_count >= 2:
                header_row = i
                break
        
        df = pd.read_excel(xls, sheet_name=target_sheet, header=header_row)
        df = df.loc[:, ~df.columns.duplicated()]
        
        return df
    except Exception as e:
        st.error(f"‚ùå Error: {e}")
        return None

def process_dataframe(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    if df is None:
        return None
    
    rename_map = {}
    
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 15 = ‡πÉ‡∏ä‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    # ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô: Sep, BU, ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤, ‡∏£‡∏´‡∏±‡∏™ WMS, ‡∏™‡∏≤‡∏Ç‡∏≤, Total Cube, Total Wgt, ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏¥‡πâ‡∏ô, Trip, Trip no, ...
    if len(df.columns) >= 8:
        col_list = list(df.columns)
        # ‡∏•‡∏≥‡∏î‡∏±‡∏ö 2 = ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤
        if len(col_list) > 2:
            rename_map[col_list[2]] = 'Code'
        # ‡∏•‡∏≥‡∏î‡∏±‡∏ö 4 = ‡∏™‡∏≤‡∏Ç‡∏≤/‡∏ä‡∏∑‡πà‡∏≠
        if len(col_list) > 4:
            rename_map[col_list[4]] = 'Name'
        # ‡∏•‡∏≥‡∏î‡∏±‡∏ö 5 = Total Cube
        if len(col_list) > 5:
            rename_map[col_list[5]] = 'Cube'
        # ‡∏•‡∏≥‡∏î‡∏±‡∏ö 6 = Total Wgt
        if len(col_list) > 6:
            rename_map[col_list[6]] = 'Weight'
        # ‡∏•‡∏≥‡∏î‡∏±‡∏ö 8 = Trip
        if len(col_list) > 8:
            rename_map[col_list[8]] = 'Trip'
        # ‡∏•‡∏≥‡∏î‡∏±‡∏ö 9 = Trip no
        if len(col_list) > 9:
            rename_map[col_list[9]] = 'TripNo'
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    for col in df.columns:
        if col in rename_map:
            continue
        col_clean = str(col).strip()
        col_upper = col_clean.upper().replace(' ', '').replace('_', '')
        
        if col_clean == 'BranchCode' or '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏£‡∏´‡∏±‡∏™ WMS' or 'BRANCH_CODE' in col_upper:
            rename_map[col] = 'Code'
        elif col_clean == 'Branch' or '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤' in col_clean or col_clean == '‡∏™‡∏≤‡∏Ç‡∏≤' or 'BRANCH' in col_upper:
            rename_map[col] = 'Name'
        elif 'TOTALWGT' in col_upper or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col_clean or 'WGT' in col_upper or 'WEIGHT' in col_upper:
            rename_map[col] = 'Weight'
        elif 'TOTALCUBE' in col_upper or '‡∏Ñ‡∏¥‡∏ß' in col_clean or 'CUBE' in col_upper:
            rename_map[col] = 'Cube'
        elif 'latitude' in col_clean.lower() or col_clean == '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î' or 'LAT' in col_upper:
            rename_map[col] = 'Latitude'
        elif 'longitude' in col_clean.lower() or col_clean == '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î' or 'LONG' in col_upper or 'LNG' in col_upper:
            rename_map[col] = 'Longitude'
        elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean or 'PROVINCE' in col_upper:
            rename_map[col] = 'Province'
        elif col_upper in ['TRIPNO', 'TRIP_NO'] or col_clean == 'Trip no':
            rename_map[col] = 'TripNo'
        elif col_upper == 'TRIP' or '‡∏ó‡∏£‡∏¥‡∏õ' in col_clean or '‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß' in col_clean:
            rename_map[col] = 'Trip'
        elif 'BOOKING' in col_upper:
            rename_map[col] = 'Booking'
    
    df = df.rename(columns=rename_map)
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥
    df = df.loc[:, ~df.columns.duplicated()]
    
    if 'Code' in df.columns:
        df['Code'] = df['Code'].apply(normalize)
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å (‡∏£‡∏´‡∏±‡∏™)
        df = df[~df['Code'].isin(EXCLUDE_BRANCHES)]
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ keyword ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        if 'Name' in df.columns:
            exclude_pattern = '|'.join(EXCLUDE_NAMES)
            df = df[~df['Name'].str.contains(exclude_pattern, case=False, na=False)]
    
    for col in ['Weight', 'Cube']:
        if col not in df.columns:
            df[col] = 0.0
        else:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å Master ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    if 'Province' not in df.columns or df['Province'].isna().all():
        if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns and 'Code' in df.columns:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏à‡∏≤‡∏Å Master
            province_map = {}
            for _, row in MASTER_DATA.iterrows():
                code = row.get('Plan Code', '')
                province = row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '')
                if code and province:
                    province_map[code] = province
            
            # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
            def find_province_by_name(code, name):
                # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å code ‡∏Å‡πà‡∏≠‡∏ô
                if code in province_map:
                    return province_map[code]
                
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
                if not name or pd.isna(name):
                    return None
                
                # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ (‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà prefix)
                keywords = str(name).replace('MAX MART-', '').replace('PUNTHAI-', '').replace('LUBE', '').strip()
                if not keywords:
                    return None
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ç‡∏≠‡∏á Master
                for _, master_row in MASTER_DATA.iterrows():
                    master_name = str(master_row.get('‡∏™‡∏≤‡∏Ç‡∏≤', ''))
                    # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô)
                    if keywords[:10] in master_name or master_name[:10] in keywords:
                        province = master_row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '')
                        if province:
                            return province
                
                return None
            
            # ‡πÉ‡∏™‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
            if 'Name' in df.columns:
                df['Province'] = df.apply(lambda row: find_province_by_name(row['Code'], row.get('Name', '')), axis=1)
            else:
                df['Province'] = df['Code'].map(province_map)
    
    return df.reset_index(drop=True)

def predict_trips(test_df, model_data, punthai_buffer=1.0, maxmart_buffer=1.10):
    """
    ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà - ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
    
    ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£:
    1. ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°: ‡∏†‡∏≤‡∏Ñ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí Route (‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å Master Dist.xlsx ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£)
    2. ‡∏à‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° Route ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏£‡∏ß‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÑ‡∏ß‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
    3. ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡πÉ‡∏Å‡∏•‡πâ (‡∏à‡∏≤‡∏Å DC)
    4. ‡∏ï‡∏±‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    5. ‡πÉ‡∏ä‡πâ BUFFER ‡∏ï‡∏≤‡∏° BU (‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤)
    
    Args:
        test_df: DataFrame ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
        model_data: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• (branch_vehicles, etc.)
        punthai_buffer: Buffer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Punthai (‡πÄ‡∏ä‡πà‡∏ô 1.0 = 100%)
        maxmart_buffer: Buffer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Maxmart/‡∏ú‡∏™‡∏° (‡πÄ‡∏ä‡πà‡∏ô 1.10 = 110%)
    """
    branch_vehicles = model_data.get('branch_vehicles', {})
    
    # ==========================================
    # Step 1: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Master Dist Lookup (Join_Key ‚Üí Sort_Code)
    # ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£: ‡πÉ‡∏ä‡πâ Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°
    # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á Sum_Code (Sort_Code) ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
    # ==========================================
    subdistrict_dist_lookup = {}  # {Join_Key: {sum_code, dist_from_dc, ...}}
    if MASTER_DIST_DATA and 'by_name' in MASTER_DIST_DATA:
        subdistrict_dist_lookup = MASTER_DIST_DATA['by_name']
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á location_map ‡∏à‡∏≤‡∏Å MASTER_DATA (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤)
    location_map = {}  # {code: {province, district, subdistrict, route, sum_code, ...}}
    
    if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
        for _, row in MASTER_DATA.iterrows():
            code = str(row.get('Plan Code', '')).strip().upper()
            if not code:
                continue
            
            province = str(row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '')).strip() if pd.notna(row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î')) else ''
            district = str(row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '')).strip() if pd.notna(row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠')) else ''
            subdistrict = str(row.get('‡∏ï‡∏≥‡∏ö‡∏•', '')).strip() if pd.notna(row.get('‡∏ï‡∏≥‡∏ö‡∏•')) else ''
            route = str(row.get('Reference', '')).strip() if pd.notna(row.get('Reference')) else ''
            lat = float(row.get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)) if pd.notna(row.get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î')) else 0
            lon = float(row.get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)) if pd.notna(row.get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î')) else 0
            
            # üîë ‡∏™‡∏£‡πâ‡∏≤‡∏á Join_Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Master Dist (VLOOKUP)
            prov_clean = clean_name(province)
            dist_clean = clean_name(district)
            subdist_clean = clean_name(subdistrict)
            join_key = f"{prov_clean}_{dist_clean}_{subdist_clean}"
            
            # ‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢ key ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á
            dist_data = subdistrict_dist_lookup.get(join_key, {})
            if not dist_data:
                # ‡∏•‡∏≠‡∏á normalize ‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                prov_normalized = normalize_province_name(province)
                alt_key = f"{prov_normalized}_{dist_clean}_{subdist_clean}"
                dist_data = subdistrict_dist_lookup.get(alt_key, {})
            
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Master Dist (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            if dist_data:
                sum_code = dist_data.get('sum_code', '')  # üéØ Sort_Code ‡∏´‡∏•‡∏±‡∏Å!
                dist_from_dc = dist_data.get('dist_from_dc_km', 9999)
                region_code = dist_data.get('region_code', '')
                prov_code = dist_data.get('prov_code', '')
                dist_code_val = dist_data.get('dist_code', '')
                subdist_code = dist_data.get('subdist_code', '')
            else:
                # Fallback: ‡∏™‡∏£‡πâ‡∏≤‡∏á sort_code ‡∏à‡∏≤‡∏Å region code ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å lat/lon
                region_code = get_region_code(province)
                sum_code = f"R99P999D9999S99999"  # Default ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏°‡πà‡∏û‡∏ö
                dist_from_dc = 9999
                if lat and lon:
                    dist_from_dc = haversine_distance(DC_WANG_NOI_LAT, DC_WANG_NOI_LON, lat, lon)
                prov_code = 'P999'
                dist_code_val = 'D9999'
                subdist_code = 'S99999'
            
            region_name = get_region_name(province)
            
            location_map[code] = {
                'province': province,
                'district': district,
                'subdistrict': subdistrict,
                'route': route,
                'lat': lat,
                'lon': lon,
                'join_key': join_key,  # üîë Join_Key ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ lookup
                'sum_code': sum_code,  # üéØ Sort_Code ‡∏´‡∏•‡∏±‡∏Å (‡∏à‡∏≤‡∏Å Master Dist)
                'distance_from_dc': dist_from_dc,
                'region_code': region_code,
                'prov_code': prov_code,
                'dist_code': dist_code_val,
                'subdist_code': subdist_code,
                'region_name': region_name
            }
    
    # ==========================================
    # Step 2: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤ (pd.merge ‡πÅ‡∏ö‡∏ö manual)
    # ==========================================
    df = test_df.copy()
    
    def get_location_info(code):
        code_upper = str(code).strip().upper()
        return location_map.get(code_upper, {
            'province': '', 'district': '', 'subdistrict': '', 'route': '',
            'lat': 0, 'lon': 0, 'join_key': '', 
            'sum_code': 'R99P999D9999S99999',  # Default sort_code
            'distance_from_dc': 9999,
            'region_code': 'R99', 'prov_code': 'P999', 'dist_code': 'D9999', 'subdist_code': 'S99999',
            'region_name': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
        })
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (‡∏£‡∏ß‡∏° sum_code ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sort)
    df['_sum_code'] = df['Code'].apply(lambda c: get_location_info(c)['sum_code'])  # üéØ Sort_Code!
    df['_join_key'] = df['Code'].apply(lambda c: get_location_info(c)['join_key'])
    df['_region_code'] = df['Code'].apply(lambda c: get_location_info(c)['region_code'])
    df['_region_name'] = df['Code'].apply(lambda c: get_location_info(c)['region_name'])
    df['_prov_code'] = df['Code'].apply(lambda c: get_location_info(c)['prov_code'])
    df['_dist_code'] = df['Code'].apply(lambda c: get_location_info(c)['dist_code'])
    df['_subdist_code'] = df['Code'].apply(lambda c: get_location_info(c)['subdist_code'])
    df['_province'] = df['Code'].apply(lambda c: get_location_info(c)['province'])
    df['_district'] = df['Code'].apply(lambda c: get_location_info(c)['district'])
    df['_subdistrict'] = df['Code'].apply(lambda c: get_location_info(c)['subdistrict'])
    df['_route'] = df['Code'].apply(lambda c: get_location_info(c)['route'])
    df['_distance_from_dc'] = df['Code'].apply(lambda c: get_location_info(c)['distance_from_dc'])
    
    # ==========================================
    # Step 3: ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏ö‡∏ö Hierarchical (Region > Province Max Dist > District Max Dist > Distance)
    # üéØ ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° Region Order ‡∏Å‡πà‡∏≠‡∏ô (‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡πÉ‡∏Å‡∏•‡πâ)
    # ==========================================
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏° Region Order ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sorting
    df['_region_order'] = df['_region_name'].map(REGION_ORDER).fillna(99)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Province Max Distance (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÑ‡∏´‡∏ô‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÑ‡∏Å‡∏•‡∏™‡∏∏‡∏î‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô)
    prov_max_dist = df.groupby('_province')['_distance_from_dc'].max().reset_index()
    prov_max_dist.columns = ['_province', '_prov_max_dist']
    df = df.merge(prov_max_dist, on='_province', how='left')
    df['_prov_max_dist'] = df['_prov_max_dist'].fillna(9999)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì District Max Distance (‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÑ‡∏´‡∏ô‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÑ‡∏Å‡∏•‡∏™‡∏∏‡∏î‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô)
    dist_max_dist = df.groupby(['_province', '_district'])['_distance_from_dc'].max().reset_index()
    dist_max_dist.columns = ['_province', '_district', '_dist_max_dist']
    df = df.merge(dist_max_dist, on=['_province', '_district'], how='left')
    df['_dist_max_dist'] = df['_dist_max_dist'].fillna(9999)
    
    # Sort: Region Order (Asc) ‚Üí Prov Max Dist (Desc) ‚Üí Dist Max Dist (Desc) ‚Üí Sum_Code ‚Üí Distance (Desc)
    df = df.sort_values(
        ['_region_order', '_prov_max_dist', '_dist_max_dist', '_sum_code', '_route', '_distance_from_dc'],
        ascending=[True, False, False, True, True, False]  # Region/Province/District ‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô
    ).reset_index(drop=True)
    
    # ==========================================
    # Step 4: ‡∏à‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° Route ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ‡∏£‡∏ß‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
    # ==========================================
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á grouping key ‡∏à‡∏≤‡∏Å route (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ï‡∏≥‡∏ö‡∏•+‡∏≠‡∏≥‡πÄ‡∏†‡∏≠+‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    def get_group_key(row):
        route = row['_route']
        if route and route.strip():
            return f"R_{route}"
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ route ‡πÉ‡∏ä‡πâ ‡∏£‡∏´‡∏±‡∏™‡∏ï‡∏≥‡∏ö‡∏• (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
        return f"L_{row['_subdist_code']}_{row['_dist_code']}_{row['_prov_code']}"
    
    df['_group_key'] = df.apply(get_group_key, axis=1)
    
    # ==========================================
    # Step 5: ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤ + Central Region Rule
    # ==========================================
    def get_max_vehicle_for_code(code):
        """‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
        max_vehicle = get_max_vehicle_for_branch(code)
        return max_vehicle
    
    def get_allowed_vehicles_for_region(region_name):
        """‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ (Central ‡∏´‡πâ‡∏≤‡∏° 6W)"""
        if region_name in CENTRAL_REGIONS:
            return CENTRAL_ALLOWED_VEHICLES  # ['4W', 'JB']
        return ['4W', 'JB', '6W']  # All vehicles
    
    df['_max_vehicle'] = df['Code'].apply(get_max_vehicle_for_code)
    df['_region_allowed_vehicles'] = df['_region_name'].apply(get_allowed_vehicles_for_region)
    
    # ==========================================
    # Step 6: DISTRICT CLUSTERING ALLOCATION (OPTIMIZED)
    # ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏ï‡∏≤‡∏° District Buckets ‡∏û‡∏£‡πâ‡∏≠‡∏° Split ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏ô
    # ==========================================
    trip_counter = 1
    df['Trip'] = 0
    
    vehicle_priority = {'4W': 1, 'JB': 2, '6W': 3}
    
    # üöÄ CACHE: Pre-compute branch constraints ‡πÅ‡∏•‡∏∞ BU type
    branch_max_vehicle_cache = {}
    branch_bu_cache = {}
    for _, row in df.iterrows():
        code = row['Code']
        branch_max_vehicle_cache[code] = row['_max_vehicle']
        bu = str(row.get('BU', '')).upper()
        branch_bu_cache[code] = bu in ['211', 'PUNTHAI']
    
    # üöÄ Pre-compute limits with buffer
    def get_max_limits(allowed_vehicles, is_punthai):
        """‡∏´‡∏≤ capacity ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
        buffer_mult = punthai_buffer if is_punthai else maxmart_buffer
        max_vehicle = '6W' if '6W' in allowed_vehicles else ('JB' if 'JB' in allowed_vehicles else '4W')
        limits_to_use = PUNTHAI_LIMITS if is_punthai else LIMITS
        lim = limits_to_use.get(max_vehicle, LIMITS['6W'])
        return {
            'max_w': lim.get('max_w', 6000) * buffer_mult,
            'max_c': lim.get('max_c', 20.0) * buffer_mult,
            'max_d': lim.get('max_drops', 12)
        }
    
    # Helper function: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (Optimized)
    def select_vehicle_for_load(weight, cube, drops, is_punthai, allowed_vehicles):
        """‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ (‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô Buffer)"""
        buffer_mult = punthai_buffer if is_punthai else maxmart_buffer
        limits_to_use = PUNTHAI_LIMITS if is_punthai else LIMITS
        
        for v in ['4W', 'JB', '6W']:
            if v not in allowed_vehicles:
                continue
            lim = limits_to_use[v]
            if (weight <= lim['max_w'] * buffer_mult and 
                cube <= lim['max_c'] * buffer_mult and 
                drops <= lim.get('max_drops', 12)):
                return v
        return None
    
    # Helper function: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Punthai ‡∏•‡πâ‡∏ß‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (Optimized - ‡πÉ‡∏ä‡πâ cache)
    def is_all_punthai_codes(codes):
        if not codes:
            return False
        return all(branch_bu_cache.get(c, False) for c in codes)
    
    # Helper function: ‡∏´‡∏≤ allowed vehicles ‡∏à‡∏≤‡∏Å codes (Optimized)
    def get_allowed_from_codes(codes, base_allowed):
        """‡∏´‡∏≤ allowed vehicles ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° branch constraints"""
        result = set(base_allowed)
        for code in codes:
            branch_max = branch_max_vehicle_cache.get(code, '6W')
            if branch_max == 'JB':
                result.discard('6W')
            elif branch_max == '4W':
                result.discard('6W')
                result.discard('JB')
        return list(result)
    
    # Current trip state
    current_trip = {
        'codes': [], 'weight': 0, 'cube': 0, 'drops': 0,
        'region': None, 'allowed_vehicles': ['4W', 'JB', '6W'],
        'district': None, 'is_punthai': False
    }
    
    overflow_queue = []  # Queue ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö stores ‡∏ó‡∏µ‡πà overflow
    
    def finalize_current_trip():
        """‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"""
        nonlocal trip_counter
        if current_trip['codes']:
            for c in current_trip['codes']:
                df.loc[df['Code'] == c, 'Trip'] = trip_counter
    
    def split_until_fits(allowed_vehicles, region):
        """‡πÅ‡∏¢‡∏Å stores ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å current_trip ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏≠‡∏î‡∏µ‡∏£‡∏ñ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô buffer) - OPTIMIZED"""
        nonlocal trip_counter, overflow_queue
        
        while True:
            # ‡πÉ‡∏ä‡πâ cached is_punthai
            is_punthai = current_trip['is_punthai']
            limits = get_max_limits(current_trip['allowed_vehicles'], is_punthai)
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if (current_trip['weight'] <= limits['max_w'] and 
                current_trip['cube'] <= limits['max_c'] and 
                current_trip['drops'] <= limits['max_d']):
                break
            
            if len(current_trip['codes']) <= 1:
                break
            
            # ‡∏ï‡∏±‡∏î store ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏≠‡∏≠‡∏Å
            overflow_code = current_trip['codes'].pop()
            overflow_weight = df.loc[df['Code'] == overflow_code, 'Weight'].iloc[0]
            overflow_cube = df.loc[df['Code'] == overflow_code, 'Cube'].iloc[0]
            current_trip['weight'] -= overflow_weight
            current_trip['cube'] -= overflow_cube
            current_trip['drops'] -= 1
            
            # Update is_punthai ‡πÅ‡∏•‡∏∞ allowed_vehicles
            current_trip['is_punthai'] = is_all_punthai_codes(current_trip['codes'])
            current_trip['allowed_vehicles'] = get_allowed_from_codes(current_trip['codes'], allowed_vehicles)
            
            overflow_queue.append({
                'code': overflow_code,
                'weight': overflow_weight,
                'cube': overflow_cube,
                'region': region,
                'allowed_vehicles': allowed_vehicles
            })
    
    def process_overflow_queue():
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• overflow queue - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö stores ‡∏ó‡∏µ‡πà‡∏•‡πâ‡∏ô - OPTIMIZED"""
        nonlocal trip_counter, current_trip, overflow_queue
        
        while overflow_queue:
            item = overflow_queue.pop(0)
            code = item['code']
            weight = item['weight']
            cube = item['cube']
            region = item['region']
            allowed_vehicles = item['allowed_vehicles']
            
            # ‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ current_trip
            if current_trip['codes']:
                test_codes = current_trip['codes'] + [code]
                test_weight = current_trip['weight'] + weight
                test_cube = current_trip['cube'] + cube
                test_drops = current_trip['drops'] + 1
                test_punthai = is_all_punthai_codes(test_codes)
                test_allowed = get_allowed_from_codes(test_codes, allowed_vehicles)
                
                vehicle = select_vehicle_for_load(test_weight, test_cube, test_drops, test_punthai, test_allowed)
                
                if vehicle:
                    # ‡∏û‡∏≠‡∏î‡∏µ! ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤
                    current_trip['codes'].append(code)
                    current_trip['weight'] = test_weight
                    current_trip['cube'] = test_cube
                    current_trip['drops'] = test_drops
                    current_trip['is_punthai'] = test_punthai
                    current_trip['allowed_vehicles'] = test_allowed
                    
                    # Double check
                    split_until_fits(allowed_vehicles, region)
                else:
                    # ‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏î‡∏µ ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏Å‡πà‡∏≤, ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà
                    finalize_current_trip()
                    trip_counter += 1
                    new_allowed = get_allowed_from_codes([code], allowed_vehicles)
                    current_trip = {
                        'codes': [code],
                        'weight': weight,
                        'cube': cube,
                        'drops': 1,
                        'region': region,
                        'allowed_vehicles': new_allowed,
                        'district': None,
                        'is_punthai': branch_bu_cache.get(code, False)
                    }
            else:
                # ‡∏ó‡∏£‡∏¥‡∏õ‡∏ß‡πà‡∏≤‡∏á
                new_allowed = get_allowed_from_codes([code], allowed_vehicles)
                current_trip = {
                    'codes': [code],
                    'weight': weight,
                    'cube': cube,
                    'drops': 1,
                    'region': region,
                    'allowed_vehicles': new_allowed,
                    'district': None,
                    'is_punthai': branch_bu_cache.get(code, False)
                }
    
    # ==========================================
    # GROUP BY DISTRICT BUCKETS - OPTIMIZED
    # ==========================================
    # Pre-group data for faster iteration
    district_groups = df.groupby(['_region_name', '_province', '_district'], sort=False)
    
    for (region, province, district), district_df in district_groups:
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• District (vectorized - no dict conversion)
        district_codes = district_df['Code'].tolist()
        district_weight = district_df['Weight'].sum()
        district_cube = district_df['Cube'].sum()
        district_drops = len(district_codes)
        
        # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
        allowed_vehicles = ['4W', 'JB', '6W']
        if region in CENTRAL_REGIONS:
            allowed_vehicles = CENTRAL_ALLOWED_VEHICLES.copy()
        
        # ==========================================
        # Rule 0: Region Change ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏Å‡πà‡∏≤ + process overflow
        # ==========================================
        if current_trip['region'] and current_trip['region'] != region:
            process_overflow_queue()
            finalize_current_trip()
            trip_counter += 1
            current_trip = {
                'codes': [], 'weight': 0, 'cube': 0, 'drops': 0,
                'region': None, 'allowed_vehicles': allowed_vehicles,
                'district': None, 'is_punthai': False
            }
        
        # ==========================================
        # Rule 1: ‡∏•‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏ó‡∏±‡πâ‡∏á District - OPTIMIZED
        # ==========================================
        if current_trip['codes']:
            test_codes = current_trip['codes'] + district_codes
            test_weight = current_trip['weight'] + district_weight
            test_cube = current_trip['cube'] + district_cube
            test_drops = current_trip['drops'] + district_drops
            test_punthai = is_all_punthai_codes(test_codes)
            test_allowed = get_allowed_from_codes(test_codes, allowed_vehicles)
            
            vehicle = select_vehicle_for_load(test_weight, test_cube, test_drops, test_punthai, test_allowed)
            
            if vehicle:
                # District ‡∏û‡∏≠‡∏î‡∏µ!
                current_trip['codes'].extend(district_codes)
                current_trip['weight'] = test_weight
                current_trip['cube'] = test_cube
                current_trip['drops'] = test_drops
                current_trip['allowed_vehicles'] = test_allowed
                current_trip['region'] = region
                current_trip['is_punthai'] = test_punthai
                
                # Double check
                split_until_fits(test_allowed, region)
            else:
                # District ‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏î‡∏µ ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏Å‡πà‡∏≤
                finalize_current_trip()
                trip_counter += 1
                
                new_allowed = get_allowed_from_codes(district_codes, allowed_vehicles)
                new_punthai = is_all_punthai_codes(district_codes)
                
                current_trip = {
                    'codes': district_codes.copy(),
                    'weight': district_weight,
                    'cube': district_cube,
                    'drops': district_drops,
                    'region': region,
                    'allowed_vehicles': new_allowed,
                    'district': district,
                    'is_punthai': new_punthai
                }
                
                # ==========================================
                # Rule 2: ‡∏ñ‡πâ‡∏≤ District ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏£‡∏ñ ‚Üí Split ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!
                # ==========================================
                split_until_fits(allowed_vehicles, region)
        else:
            # ‡∏ó‡∏£‡∏¥‡∏õ‡∏ß‡πà‡∏≤‡∏á - ‡∏´‡∏≤ allowed_vehicles ‡∏£‡∏ß‡∏° branch constraints (‡πÉ‡∏ä‡πâ cache)
            new_allowed = get_allowed_from_codes(district_codes, allowed_vehicles)
            new_punthai = is_all_punthai_codes(district_codes)
            
            current_trip = {
                'codes': district_codes.copy(),
                'weight': district_weight,
                'cube': district_cube,
                'drops': district_drops,
                'region': region,
                'allowed_vehicles': new_allowed,
                'district': district,
                'is_punthai': new_punthai
            }
            
            # ==========================================
            # Rule 2: ‡∏ñ‡πâ‡∏≤ District ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏£‡∏ñ ‚Üí Split ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!
            # ==========================================
            split_until_fits(new_allowed, region)
    
    # ==========================================
    # Final: Process remaining overflow ‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
    # ==========================================
    process_overflow_queue()
    finalize_current_trip()

    # ==========================================
    # Step 7: ‡∏™‡∏£‡πâ‡∏≤‡∏á Summary + Central Rule + Punthai Drop Limits
    # ==========================================
    summary_data = []
    
    for trip_num in sorted(df['Trip'].unique()):
        if trip_num == 0:
            continue
        
        trip_data = df[df['Trip'] == trip_num]
        total_w = trip_data['Weight'].sum()
        total_c = trip_data['Cube'].sum()
        trip_codes = trip_data['Code'].unique()
        trip_drops = len(trip_codes)
        
        # ‡∏´‡∏≤‡∏†‡∏≤‡∏Ñ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ (‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏Ñ‡πÅ‡∏£‡∏Å)
        trip_region = trip_data['_region_name'].iloc[0] if '_region_name' in trip_data.columns else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
        
        # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡∏£‡∏ß‡∏° Central Rule)
        max_vehicles = [get_max_vehicle_for_branch(c) for c in trip_codes]
        min_max_size = min(vehicle_priority.get(v, 3) for v in max_vehicles)
        max_allowed_vehicle = {1: '4W', 2: 'JB', 3: '6W'}.get(min_max_size, '6W')
        
        # üö´ Central Region Rule: ‡∏´‡πâ‡∏≤‡∏° 6W
        if trip_region in CENTRAL_REGIONS and max_allowed_vehicle == '6W':
            max_allowed_vehicle = 'JB'  # ‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô JB
        
        # ‡∏ï‡∏£‡∏ß‡∏à BU ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ
        is_punthai_only_trip = True
        for _, r in trip_data.iterrows():
            bu = str(r.get('BU', '')).upper()
            if bu not in ['211', 'PUNTHAI']:
                is_punthai_only_trip = False
                break
        
        buffer = punthai_buffer if is_punthai_only_trip else maxmart_buffer
        buffer_pct = int(buffer * 100)
        buffer_label = f"üÖøÔ∏è {buffer_pct}%" if is_punthai_only_trip else f"üÖº {buffer_pct}%"
        trip_type = 'punthai' if is_punthai_only_trip else 'maxmart'
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏û‡∏≠‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        suggested = max_allowed_vehicle
        source = "üìã ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤" if min_max_size < 3 else "ü§ñ ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"
        
        # üîí Punthai Drop Limit Check
        if is_punthai_only_trip:
            punthai_drop_limit = PUNTHAI_LIMITS.get(suggested, {}).get('max_drops', 999)
            if trip_drops > punthai_drop_limit:
                # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö drops
                if suggested == '4W' and trip_drops <= PUNTHAI_LIMITS['JB']['max_drops']:
                    suggested = 'JB'
                    source += " ‚Üí JB (Drop Limit)"
                elif suggested == 'JB' or trip_drops > PUNTHAI_LIMITS['JB']['max_drops']:
                    # ‡∏ñ‡πâ‡∏≤ Central ‡∏´‡πâ‡∏≤‡∏° 6W ‚Üí WARNING
                    if trip_region not in CENTRAL_REGIONS:
                        suggested = '6W'
                        source += " ‚Üí 6W (Drop Limit)"
                    else:
                        source += " ‚ö†Ô∏è Drops ‡πÄ‡∏Å‡∏¥‡∏ô!"
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì utilization
        max_util_threshold = buffer * 100  # 100% ‡∏´‡∏£‡∏∑‡∏≠ 110% ‡∏ï‡∏≤‡∏° BU
        if suggested in LIMITS:
            w_util = (total_w / LIMITS[suggested]['max_w']) * 100
            c_util = (total_c / LIMITS[suggested]['max_c']) * 100
            max_util = max(w_util, c_util)
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô threshold ‡∏ï‡∏≤‡∏° BU ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ
            if max_util > max_util_threshold:
                if suggested == '4W' and min_max_size >= 2:
                    jb_util = max((total_w / LIMITS['JB']['max_w']), (total_c / LIMITS['JB']['max_c'])) * 100
                    if jb_util <= max_util_threshold:
                        suggested = 'JB'
                        source += " ‚Üí JB"
                        w_util = (total_w / LIMITS['JB']['max_w']) * 100
                        c_util = (total_c / LIMITS['JB']['max_c']) * 100
                    elif min_max_size >= 3:
                        suggested = '6W'
                        source += " ‚Üí 6W"
                        w_util = (total_w / LIMITS['6W']['max_w']) * 100
                        c_util = (total_c / LIMITS['6W']['max_c']) * 100
                elif suggested == 'JB' and min_max_size >= 3:
                    suggested = '6W'
                    source += " ‚Üí 6W"
                    w_util = (total_w / LIMITS['6W']['max_w']) * 100
                    c_util = (total_c / LIMITS['6W']['max_c']) * 100
        else:
            w_util = c_util = 0
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏ß‡∏°
        total_distance = 0
        branch_coords = []
        for code in trip_codes:
            loc = location_map.get(str(code).upper(), {})
            if loc.get('lat') and loc.get('lon'):
                branch_coords.append((loc['lat'], loc['lon']))
        
        if branch_coords:
            # DC ‚Üí ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å
            total_distance += haversine_distance(DC_WANG_NOI_LAT, DC_WANG_NOI_LON, branch_coords[0][0], branch_coords[0][1])
            # ‡∏™‡∏≤‡∏Ç‡∏≤ ‚Üí ‡∏™‡∏≤‡∏Ç‡∏≤
            for i in range(len(branch_coords) - 1):
                total_distance += haversine_distance(branch_coords[i][0], branch_coords[i][1], branch_coords[i+1][0], branch_coords[i+1][1])
            # ‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‚Üí DC
            total_distance += haversine_distance(branch_coords[-1][0], branch_coords[-1][1], DC_WANG_NOI_LAT, DC_WANG_NOI_LON)
        
        summary_data.append({
            'Trip': trip_num,
            'Branches': len(trip_codes),
            'Weight': total_w,
            'Cube': total_c,
            'Truck': f"{suggested} {source}",
            'BU_Type': trip_type,
            'Buffer': buffer_label,
            'Weight_Use%': w_util,
            'Cube_Use%': c_util,
            'Total_Distance': round(total_distance, 1)
        })
    
    summary_df = pd.DataFrame(summary_data)
    
    # ==========================================
    # Step 8: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏™‡∏£‡∏¥‡∏°
    # ==========================================
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ñ
    trip_truck_map = {}
    for _, row in summary_df.iterrows():
        trip_truck_map[row['Trip']] = row['Truck']
    df['Truck'] = df['Trip'].map(trip_truck_map)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Region
    df['Region'] = df['_region_name']
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Province (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
    if 'Province' not in df.columns:
        df['Province'] = df['_province']
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC
    df['Distance_from_DC'] = df['_distance_from_dc'].round(1)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏ñ
    df['VehicleCheck'] = '‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ'
    
    # ==========================================
    # Step 9: ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏¥‡∏õ‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export)
    # ==========================================
    df = df.sort_values(['Trip', '_distance_from_dc'], ascending=[True, False]).reset_index(drop=True)
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
    cols_to_drop = ['_region_code', '_region_name', '_prov_code', '_dist_code', '_subdist_code', '_province', '_district', '_subdistrict', '_route', '_distance_from_dc', '_group_key', '_max_vehicle', '_region_order', '_prov_max_dist', '_dist_max_dist', '_region_allowed_vehicles']
    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')
    
    return df, summary_df
def main():
    st.set_page_config(
        page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß",
        page_icon="üöö",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # üîÑ Auto-refresh ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô (‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏ä)
    if AUTOREFRESH_AVAILABLE:
        now = datetime.now()
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ñ‡∏∂‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô (00:00:00)
        midnight = datetime.combine(now.date(), time(0, 0, 0))
        
        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô ‡πÄ‡∏≠‡∏≤‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        if now < midnight:
            next_midnight = midnight
        else:
            from datetime import timedelta
            next_midnight = midnight + timedelta(days=1)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
        seconds_until_midnight = int((next_midnight - now).total_seconds())
        
        # Refresh ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô
        if seconds_until_midnight > 0:
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 5 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô (‡∏´‡∏•‡∏±‡∏á 23:55)
            if seconds_until_midnight <= 300:  # 5 minutes
                st.info(f"üîÑ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞ Refresh ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÉ‡∏ô {seconds_until_midnight // 60} ‡∏ô‡∏≤‡∏ó‡∏µ")
                st_autorefresh(interval=seconds_until_midnight * 1000, key="midnight_refresh")
            else:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
                st_autorefresh(interval=3600000, limit=24, key="hourly_check")
    
    # Header
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("üöö ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß")
    with col2:
        st.image("https://raw.githubusercontent.com/twitter/twemoji/master/assets/svg/1f69a.svg", width=100)
    
    # Show Punthai learning stats
    if PUNTHAI_PATTERNS and 'stats' in PUNTHAI_PATTERNS and PUNTHAI_PATTERNS['stats']:
        stats = PUNTHAI_PATTERNS['stats']
        with st.expander("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Punthai Maxmart", expanded=False):
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤/‡∏ó‡∏£‡∏¥‡∏õ", f"{stats.get('avg_branches', 0):.1f}")
            with col_b:
                st.metric("‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß", f"{stats.get('same_province_pct', 0):.1f}%")
            with col_c:
                total_trips = stats.get('same_province', 0) + stats.get('mixed_province', 0)
                st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á", total_trips)
    
    st.markdown("---")
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_data = load_model()
    
    if not model_data:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.info("üí° ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: `python test_model.py`")
        st.stop()
    
    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    st.markdown("### üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå")
    uploaded_file = st.file_uploader(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel (.xlsx)", 
        type=['xlsx'],
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏•‡∏∞‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå"
    )
    
    if uploaded_file:
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session_state ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô export
        uploaded_file_content = uploaded_file.read()
        st.session_state['original_file_content'] = uploaded_file_content
        
        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
            df = load_excel(uploaded_file_content)
            df = process_dataframe(df)
            
            if df is not None and 'Code' in df.columns:
                st.success(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: **{len(df):,}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", f"{df['Code'].nunique():,}")
                with col2:
                    st.metric("‚öñÔ∏è ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏ß‡∏°", f"{df['Weight'].sum():,.0f} kg")
                with col3:
                    st.metric("üì¶ ‡∏Ñ‡∏¥‡∏ß‡∏£‡∏ß‡∏°", f"{df['Cube'].sum():.1f} m¬≥")
                with col4:
                    provinces = df['Province'].nunique() if 'Province' in df.columns else 0
                    st.metric("üó∫Ô∏è ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", f"{provinces}")
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                with st.expander("üîç ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"):
                    st.dataframe(df.head(10), use_container_width=True)
                
                # ==========================================
                # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Master (‡∏ó‡∏≥‡πÉ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ö‡πâ‡∏≤‡∏ô)
                # ==========================================
                if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á dict ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß
                    master_lookup = {}
                    for _, row in MASTER_DATA.iterrows():
                        code = str(row['Plan Code']).strip().upper()
                        master_lookup[code] = {
                            'province': row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''),
                            'district': row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                            'subdistrict': row.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                            'lat': row.get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0),
                            'lon': row.get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
                        }
                    
                    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î
                    filled_count = 0
                    for idx, row in df.iterrows():
                        code = str(row['Code']).strip().upper()
                        if code in master_lookup:
                            master_info = master_lookup[code]
                            # ‡πÄ‡∏ï‡∏¥‡∏° Province ‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
                            if 'Province' not in df.columns or pd.isna(df.loc[idx, 'Province']) or df.loc[idx, 'Province'] == '' or df.loc[idx, 'Province'] == 'UNKNOWN':
                                if master_info['province']:
                                    df.loc[idx, 'Province'] = master_info['province']
                                    filled_count += 1
                            # ‡πÄ‡∏ï‡∏¥‡∏° District ‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
                            if 'District' not in df.columns:
                                df['District'] = ''
                            if pd.isna(df.loc[idx, 'District']) or df.loc[idx, 'District'] == '':
                                if master_info['district']:
                                    df.loc[idx, 'District'] = master_info['district']
                            # ‡πÄ‡∏ï‡∏¥‡∏° Subdistrict ‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
                            if 'Subdistrict' not in df.columns:
                                df['Subdistrict'] = ''
                            if pd.isna(df.loc[idx, 'Subdistrict']) or df.loc[idx, 'Subdistrict'] == '':
                                if master_info['subdistrict']:
                                    df.loc[idx, 'Subdistrict'] = master_info['subdistrict']
                    
                    if filled_count > 0:
                        st.info(f"üìç ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Master ‡πÅ‡∏•‡πâ‡∏ß {filled_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà‡∏à‡∏≥‡∏ô‡∏ß‡∏ô)
                if 'Province' in df.columns:
                    missing_count = len(df[(df['Province'].isna()) | (df['Province'] == '') | (df['Province'] == 'UNKNOWN')])
                    if missing_count > 0:
                        st.warning(f"‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡∏°‡∏µ {missing_count} ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô Master")
                
                st.markdown("---")
                
                # ‡πÅ‡∏ó‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å
                tab1, tab2 = st.tabs([
                    "üì¶ ‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)", 
                    "üó∫Ô∏è ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ"
                ])
                    
                # ==========================================
                # ‡πÅ‡∏ó‡πá‡∏ö 1: ‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)
                # ==========================================
                with tab1:
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏° Region ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
                    if 'Region' not in df.columns and 'Province' in df.columns:
                        df['Region'] = df['Province'].apply(get_region_name)
                    
                    # ==========================================
                    # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
                    # ==========================================
                    st.markdown("#### ‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ")
                    
                    # ‡∏Å‡∏£‡∏≠‡∏Å Buffer ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                    col_buf1, col_buf2 = st.columns(2)
                    
                    with col_buf1:
                        punthai_buffer = st.number_input(
                            "üÖøÔ∏è Punthai Buffer %",
                            min_value=80,
                            max_value=120,
                            value=100,
                            step=5
                        )
                    
                    with col_buf2:
                        maxmart_buffer = st.number_input(
                            "üÖº Maxmart/‡∏ú‡∏™‡∏° Buffer %",
                            min_value=80,
                            max_value=150,
                            value=110,
                            step=5
                        )
                    
                    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô buffer value
                    punthai_buffer_value = punthai_buffer / 100.0
                    maxmart_buffer_value = maxmart_buffer / 100.0
                    
                    st.markdown("---")
                    
                    # ‡∏õ‡∏∏‡πà‡∏°‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
                    if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß", type="primary", use_container_width=True):
                        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                            # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡∏ï‡∏≥‡∏ö‡∏•/Route (‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô predict_trips)
                            df_to_process = df.copy()
                            
                            # ‡∏™‡πà‡∏á buffer ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° BU
                            result_df, summary = predict_trips(
                                df_to_process, 
                                model_data, 
                                punthai_buffer=punthai_buffer_value,
                                maxmart_buffer=maxmart_buffer_value
                            )
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ (Trip = 0)
                            unassigned_count = len(result_df[result_df['Trip'] == 0])
                            if unassigned_count > 0:
                                st.warning(f"‚ö†Ô∏è ‡∏°‡∏µ {unassigned_count} ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ (Trip = 0)")
                            
                            # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                            assigned_df = result_df[result_df['Trip'] > 0].copy()
                            
                            st.balloons()
                            st.success(f"‚úÖ **‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!** ‡∏£‡∏ß‡∏° **{len(summary)}** ‡∏ó‡∏£‡∏¥‡∏õ ({len(assigned_df)} ‡∏™‡∏≤‡∏Ç‡∏≤)")
                            
                            st.markdown("---")
                            
                            # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
                            st.markdown("### üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("üöö ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏£‡∏¥‡∏õ", len(summary))
                            with col2:
                                st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", len(assigned_df))
                            with col3:
                                avg_branches = len(assigned_df) / max(1, assigned_df['Trip'].nunique())
                                st.metric("üìä ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤/‡∏ó‡∏£‡∏¥‡∏õ", f"{avg_branches:.1f}")
                            with col4:
                                avg_util = summary['Cube_Use%'].mean() if len(summary) > 0 else 0
                                st.metric("üìà ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_util:.0f}%")
                            
                            st.markdown("---")
                            
                            # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ
                            st.markdown("### üöõ ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ")
                            st.dataframe(
                                summary.style.format({
                                    'Weight': '{:.2f}',
                                    'Cube': '{:.2f}',
                                    'Weight_Use%': '{:.1f}%',
                                    'Cube_Use%': '{:.1f}%',
                                    'Total_Distance': '{:.1f} km'
                                }).background_gradient(
                                    subset=['Weight_Use%', 'Cube_Use%'],
                                    cmap='RdYlGn',
                                    vmin=0,
                                    vmax=100
                                ),
                                use_container_width=True,
                                height=400
                            )
                            
                            # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ñ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
                            with st.expander("üìã ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)"):
                                # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                                display_cols = ['Trip', 'Code', 'Name']
                                if 'Province' in result_df.columns:
                                    display_cols.append('Province')
                                if 'Region' in result_df.columns:
                                    display_cols.append('Region')
                                display_cols.extend(['Max_Distance_in_Trip', 'Weight', 'Cube', 'Truck', 'VehicleCheck'])
                                
                                # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
                                display_cols = [col for col in display_cols if col in result_df.columns]
                                display_df = result_df[display_cols].copy()
                                
                                # ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
                                col_names = {'Trip': '‡∏ó‡∏£‡∏¥‡∏õ', 'Code': '‡∏£‡∏´‡∏±‡∏™', 'Name': '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', 'Province': '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 
                                           'Region': '‡∏†‡∏≤‡∏Ñ', 'Max_Distance_in_Trip': '‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á Max(km)', 
                                           'Weight': '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å(kg)', 'Cube': '‡∏Ñ‡∏¥‡∏ß(m¬≥)', 'Truck': '‡∏£‡∏ñ', 'VehicleCheck': '‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏ñ'}
                                display_df.columns = [col_names.get(c, c) for c in display_cols]
                                
                                # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á
                                st.dataframe(
                                    display_df.style.format({
                                        '‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á(km)': '{:.1f}',
                                        '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å(kg)': '{:.2f}',
                                        '‡∏Ñ‡∏¥‡∏ß(m¬≥)': '{:.2f}'
                                    }),
                                    use_container_width=True, 
                                    height=400
                                )
                            
                            # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô
                            warning_branches = result_df[result_df['VehicleCheck'].str.contains('‚ö†Ô∏è', na=False)]
                            if len(warning_branches) > 0:
                                with st.expander(f"‚ö†Ô∏è ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏Å‡∏ï‡∏¥ ({len(warning_branches)} ‡∏™‡∏≤‡∏Ç‡∏≤)"):
                                    st.warning("‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏õ‡∏Å‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏∑‡πà‡∏ô ‡πÅ‡∏ï‡πà‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ")
                                    display_cols_warn = ['Trip', 'Code', 'Name', 'Truck', 'VehicleCheck']
                                    display_warn_df = warning_branches[display_cols_warn].copy()
                                    display_warn_df.columns = ['‡∏ó‡∏£‡∏¥‡∏õ', '‡∏£‡∏´‡∏±‡∏™', '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î', '‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ']
                                    st.dataframe(display_warn_df, use_container_width=True)
                            
                            st.markdown("---")
                            
                            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö‡∏ä‡∏µ‡∏ï 2.Punthai ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏•‡∏±‡∏ö‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡πÇ‡∏ó‡∏ô‡∏™‡πâ‡∏°-‡∏Ç‡∏≤‡∏ß
                            from openpyxl import load_workbook
                            from openpyxl.styles import PatternFill, Font, Border, Side
                            
                            output = io.BytesIO()
                            
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á location_map ‡∏à‡∏≤‡∏Å MASTER_DATA
                            location_map = {}
                            if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
                                for _, row in MASTER_DATA.iterrows():
                                    code = str(row.get('Plan Code', '')).strip().upper()
                                    if code:
                                        location_map[code] = {
                                            '‡∏ï‡∏≥‡∏ö‡∏•': row.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                                            '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                                            '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î': row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''),
                                            'Route': row.get('Reference', '')
                                        }
                            
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Trip_No map
                            trip_no_map = {}
                            vehicle_counts = {'4W': 0, '4WJ': 0, '6W': 0}
                            
                            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á trip ‡∏ï‡∏≤‡∏° Zone Order + Province Max Dist + District Max Dist (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ)
                            ZONE_ORDER_EXPORT = {'NORTH': 1, 'NE': 2, 'SOUTH': 3, 'EAST': 4, 'WEST': 5, 'CENTRAL': 6}
                            trip_sort_keys = {}
                            
                            for trip_num in result_df['Trip'].unique():
                                if trip_num == 0:
                                    continue
                                trip_data = result_df[result_df['Trip'] == trip_num]
                                
                                # ‡∏´‡∏≤ Region Order
                                region = trip_data['Region'].iloc[0] if 'Region' in trip_data.columns else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                                region_order = ZONE_ORDER_EXPORT.get(region, 99)
                                
                                # ‡∏´‡∏≤ Province Max Distance ‡πÅ‡∏•‡∏∞ District Max Distance
                                prov_max_dist = 0
                                dist_max_dist = 0
                                
                                for code in trip_data['Code'].unique():
                                    loc = location_map.get(str(code).upper(), {})
                                    # ‡∏î‡∏∂‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å MASTER_DATA
                                    if not MASTER_DATA.empty:
                                        master_row = MASTER_DATA[MASTER_DATA['Plan Code'].astype(str).str.upper() == str(code).upper()]
                                        if len(master_row) > 0:
                                            dist_km = master_row.iloc[0].get('Distance from DC (km)', 0)
                                            if pd.notna(dist_km):
                                                prov_max_dist = max(prov_max_dist, float(dist_km))
                                                dist_max_dist = max(dist_max_dist, float(dist_km))
                                
                                # Sort key: Region Order (Asc), Prov Max Dist (Desc), Dist Max Dist (Desc)
                                # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏•‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ sort Desc
                                trip_sort_keys[trip_num] = (region_order, -prov_max_dist, -dist_max_dist)
                            
                            # Sort: Zone Order ‚Üí Province Max Dist (‡πÑ‡∏Å‡∏•‡∏Å‡πà‡∏≠‡∏ô) ‚Üí District Max Dist (‡πÑ‡∏Å‡∏•‡∏Å‡πà‡∏≠‡∏ô)
                            sorted_trips = sorted(
                                [t for t in result_df['Trip'].unique() if t != 0],
                                key=lambda t: trip_sort_keys.get(t, (99, 0, 0))
                            )
                            
                            for trip_num in sorted_trips:
                                trip_summary = summary[summary['Trip'] == trip_num]
                                if len(trip_summary) > 0:
                                    truck_info = trip_summary.iloc[0]['Truck']
                                    vehicle_type = truck_info.split()[0] if truck_info else '6W'
                                    # JB ‡πÉ‡∏ä‡πâ prefix 4WJ
                                    if vehicle_type == 'JB':
                                        vehicle_type = '4WJ'
                                    vehicle_counts[vehicle_type] = vehicle_counts.get(vehicle_type, 0) + 1
                                    trip_no = f"{vehicle_type}{vehicle_counts[vehicle_type]:03d}"
                                    trip_no_map[trip_num] = trip_no
                            
                            try:
                                # ‡πÇ‡∏´‡∏•‡∏î workbook ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
                                wb = load_workbook(io.BytesIO(st.session_state.get('original_file_content', b'')))
                                
                                # ‡∏´‡∏≤‡∏ä‡∏µ‡∏ï‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (2.Punthai)
                                target_sheet = None
                                for sheet_name in wb.sheetnames:
                                    if 'punthai' in sheet_name.lower() or '2.' in sheet_name.lower():
                                        target_sheet = sheet_name
                                        break
                                
                                if not target_sheet:
                                    target_sheet = '2.Punthai'
                                    if target_sheet not in wb.sheetnames:
                                        wb.create_sheet(target_sheet)
                                
                                ws = wb[target_sheet]
                                
                                # ‡∏´‡∏≤ header row
                                header_row = 1
                                for row_idx in range(1, min(5, ws.max_row + 1)):
                                    for col_idx in range(1, min(15, ws.max_column + 1)):
                                        cell_val = str(ws.cell(row=row_idx, column=col_idx).value or '')
                                        if '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in cell_val or 'Trip' in cell_val.upper():
                                            header_row = row_idx
                                            break
                                
                                # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
                                if ws.max_row > header_row:
                                    ws.delete_rows(header_row + 1, ws.max_row - header_row)
                                
                                # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô header ‡πÉ‡∏´‡∏°‡πà
                                new_headers = ['Sep.', 'BU', '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏£‡∏´‡∏±‡∏™ WMS', '‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'Route',
                                              'Total Cube', 'Total Wgt', 'Original QTY', 'Trip', 'Trip no']
                                for col_idx, header_val in enumerate(new_headers, 1):
                                    ws.cell(row=header_row, column=col_idx, value=header_val)
                                
                                # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡πÇ‡∏ó‡∏ô‡∏™‡πâ‡∏°-‡∏Ç‡∏≤‡∏ß (‡∏™‡∏•‡∏±‡∏ö 2 ‡∏™‡∏µ)
                                yellow_orange = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')
                                white_fill = PatternFill(start_color='FFFFFF', end_color='FFFFFF', fill_type='solid')
                                thin_border = Border(
                                    left=Side(style='thin'), right=Side(style='thin'),
                                    top=Side(style='thin'), bottom=Side(style='thin')
                                )
                                red_font = Font(color='FF0000', bold=True)
                                
                                # ‡∏´‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå
                                failed_trips = set()
                                vehicle_limits = {'4W': {'max_w': 2500, 'max_c': 5.0}, 'JB': {'max_w': 3500, 'max_c': 7.0}, '6W': {'max_w': 6000, 'max_c': 20.0}}
                                for t in result_df['Trip'].unique():
                                    if t == 0:
                                        continue
                                    trip_data = result_df[result_df['Trip'] == t]
                                    trip_cube = trip_data['Cube'].sum()
                                    trip_weight = trip_data['Weight'].sum()
                                    trip_no = trip_no_map.get(t, '6W001')
                                    veh_type = 'JB' if trip_no.startswith('4WJ') else ('4W' if trip_no.startswith('4W') else '6W')
                                    limits = vehicle_limits.get(veh_type, vehicle_limits['6W'])
                                    max_util = max((trip_cube / limits['max_c']) * 100, (trip_weight / limits['max_w']) * 100)
                                    if max_util > 105 or max_util < 50:
                                        failed_trips.add(t)
                                
                                # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                                current_trip = None
                                use_yellow = True
                                row_num = header_row + 1
                                sep_num = 1
                                
                                for trip_num in sorted_trips:
                                    trip_data = result_df[result_df['Trip'] == trip_num].copy()
                                    
                                    # Sort ‡∏ï‡∏≤‡∏° ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                                    trip_data['_sort_sub'] = trip_data['Code'].apply(lambda c: location_map.get(str(c).upper(), {}).get('‡∏ï‡∏≥‡∏ö‡∏•', ''))
                                    trip_data['_sort_dist'] = trip_data['Code'].apply(lambda c: location_map.get(str(c).upper(), {}).get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''))
                                    trip_data['_sort_prov'] = trip_data['Code'].apply(lambda c: location_map.get(str(c).upper(), {}).get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''))
                                    trip_data = trip_data.sort_values(['_sort_prov', '_sort_dist', '_sort_sub', 'Code'])
                                    
                                    trip_no = trip_no_map.get(trip_num, '')
                                    
                                    # ‡∏™‡∏•‡∏±‡∏ö‡∏™‡∏µ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
                                    if current_trip != trip_num:
                                        current_trip = trip_num
                                        use_yellow = not use_yellow
                                    
                                    fill = yellow_orange if use_yellow else white_fill
                                    
                                    for _, row in trip_data.iterrows():
                                        branch_code = row.get('Code', '')
                                        loc = location_map.get(str(branch_code).upper(), {})
                                        
                                        data = [
                                            sep_num,
                                            row.get('BU', 211),
                                            branch_code,
                                            branch_code,
                                            row.get('Name', ''),
                                            loc.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                                            loc.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                                            loc.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''),
                                            loc.get('Route', ''),
                                            round(row.get('Cube', 0), 2) if pd.notna(row.get('Cube')) else 0,
                                            round(row.get('Weight', 0), 2) if pd.notna(row.get('Weight')) else 0,
                                            row.get('OriginalQty', 0) if pd.notna(row.get('OriginalQty')) else 0,
                                            int(trip_num),
                                            trip_no,
                                        ]
                                        
                                        for col_idx, value in enumerate(data, 1):
                                            cell = ws.cell(row=row_num, column=col_idx, value=value)
                                            cell.fill = fill
                                            cell.border = thin_border
                                            if trip_num in failed_trips:
                                                cell.font = red_font
                                        
                                        row_num += 1
                                        sep_num += 1
                                
                                wb.save(output)
                                output.seek(0)
                                
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏î‡πâ: {e} - ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÅ‡∏ó‡∏ô")
                                # Fallback: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ xlsxwriter
                                output = io.BytesIO()
                                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                    export_df = result_df.copy()
                                    export_df['Trip_No'] = export_df['Trip'].map(lambda x: trip_no_map.get(x, ''))
                                    export_df.to_excel(writer, sheet_name='‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏£‡∏¥‡∏õ', index=False)
                                    summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏£‡∏¥‡∏õ', index=False)
                            
                            col1, col2, col3 = st.columns([1, 2, 1])
                            with col2:
                                st.download_button(
                                    label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Excel)",
                                    data=output.getvalue(),
                                    file_name=f"‡∏ú‡∏•‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    use_container_width=True
                                )
                
                # ==========================================
                # ‡πÅ‡∏ó‡πá‡∏ö 2: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ (‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)
                # ==========================================
                with tab2:
                    df_region = df.copy()
                    
                    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
                    branch_info = model_data.get('branch_info', {})
                    trip_pairs = model_data.get('trip_pairs', set())
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏Ñ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤ (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
                    region_groups = {
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ô': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≠‡∏Å': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•': ['‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤'],
                        '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': ['‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå', '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': ['‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ï‡∏£‡∏≤‡∏î', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß', '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': ['‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°', '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨', '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£', '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£', '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π', '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏•‡∏¢'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå', '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô', '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥', '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°', '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÉ‡∏ï‡πâ': ['‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä', '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå', '‡∏¢‡πÇ‡∏™‡∏ò‡∏£', '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©', '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå', '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç', '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠-‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤', '‡∏•‡∏≥‡∏õ‡∏≤‡∏á', '‡∏•‡∏≥‡∏û‡∏π‡∏ô', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÅ‡∏û‡∏£‡πà', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô'],
                        '‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠-‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£', '‡∏ï‡∏≤‡∏Å', '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå', '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£', '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å', '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢', '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå', '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå'],
                        '‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ-‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏î‡∏≤‡∏°‡∏±‡∏ô': ['‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏ï‡∏£‡∏±‡∏á', '‡∏û‡∏±‡∏á‡∏á‡∏≤', '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏£‡∏∞‡∏ô‡∏≠‡∏á', '‡∏™‡∏ï‡∏π‡∏•'],
                        '‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ-‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡πà‡∏≤‡∏ß‡πÑ‡∏ó‡∏¢': ['‡∏ä‡∏∏‡∏°‡∏û‡∏£', '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™']
                    }
                    
                    def get_region(province):
                        if pd.isna(province) or not province or str(province).strip() in ['', 'nan', 'UNKNOWN']:
                            return '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                        
                        # üö® Override: ‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤ ‚Üí ‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•)
                        if '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤' in str(province):
                            return '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å'
                        
                        for region, provinces in region_groups.items():
                            if any(p in str(province) for p in provinces):
                                return region
                        return '‡∏≠‡∏∑‡πà‡∏ô‡πÜ'
                    
                    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏†‡∏≤‡∏Ñ - ‡∏î‡∏∂‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å Master ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
                    if 'Province' not in df_region.columns or df_region['Province'].isna().any():
                        # ‡∏î‡∏∂‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å Master
                        if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
                            province_map = {}
                            for _, row in MASTER_DATA.iterrows():
                                code = row.get('Plan Code', '')
                                province = row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '')
                                if code and province:
                                    province_map[code] = province
                            
                            # ‡πÉ‡∏™‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
                            if 'Province' not in df_region.columns:
                                df_region['Province'] = df_region['Code'].map(province_map)
                            else:
                                # ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NaN
                                df_region['Province'] = df_region.apply(
                                    lambda row: province_map.get(row['Code'], row.get('Province', 'UNKNOWN')) 
                                    if pd.isna(row.get('Province')) else row['Province'],
                                    axis=1
                                )
                    
                    df_region['Region'] = df_region['Province'].apply(get_region)
                    
                    # ‡∏´‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤ (‡πÉ‡∏ä‡πâ Booking No. ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å)
                    def find_paired_branches(code, code_province, df_data):
                        paired = set()
                        
                        # ‡∏´‡∏≤ Booking No. ‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ
                        code_rows = df_data[df_data['Code'] == code]
                        if len(code_rows) == 0:
                            return paired
                        
                        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Booking ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                        if 'Booking' not in df_data.columns and 'Trip' not in df_data.columns:
                            return paired
                        
                        booking_col = 'Booking' if 'Booking' in df_data.columns else 'Trip'
                        code_bookings = set(code_rows[booking_col].dropna().astype(str))
                        
                        if not code_bookings:
                            return paired
                        
                        # ‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà Booking ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)
                        for booking in code_bookings:
                            if booking == 'nan' or not booking.strip():
                                continue
                            
                            same_booking = df_data[df_data[booking_col].astype(str) == booking]
                            for _, other_row in same_booking.iterrows():
                                other_code = other_row['Code']
                                
                                # ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: Booking ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô = ‡∏£‡∏ß‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏° (‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)
                                if other_code != code:
                                    paired.add(other_code)
                        
                        return paired
                    
                    all_codes_set = set(df_region['Code'].unique())
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏ö‡∏ö Union-Find (‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö: ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)
                    # Step 1: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master
                    initial_groups = {}
                    for code in all_codes_set:
                        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Master
                        location = {}
                        if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
                            master_row = MASTER_DATA[MASTER_DATA['Plan Code'] == code]
                            if len(master_row) > 0:
                                master_row = master_row.iloc[0]
                                location = {
                                    'subdistrict': master_row.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                                    'district': master_row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                                    'province': master_row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'UNKNOWN'),
                                    'lat': master_row.get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0),
                                    'lon': master_row.get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
                                }
                        
                        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Master ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
                        if not location or location.get('province', 'UNKNOWN') == 'UNKNOWN':
                            c_row = df_region[df_region['Code'] == code].iloc[0] if len(df_region[df_region['Code'] == code]) > 0 else None
                            if c_row is not None:
                                location = {
                                    'subdistrict': '',
                                    'district': '',
                                    'province': c_row.get('Province', 'UNKNOWN'),
                                    'lat': 0,
                                    'lon': 0
                                }
                        
                        if location:
                            initial_groups[(code,)] = {code: location}
                    
                    # ‡πÉ‡∏ä‡πâ initial_groups ‡πÅ‡∏ó‡∏ô booking_groups
                    booking_groups = initial_groups
                    
                    # Step 2: ‡∏£‡∏ß‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                    def groups_can_merge(locs1, locs2):
                        """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ 2 ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏£‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏´‡∏° (‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)"""
                        # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ï‡∏≥‡∏ö‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡∏ö‡∏•)
                        subdistricts1 = set(loc.get('subdistrict', '') for loc in locs1.values() if loc.get('subdistrict', ''))
                        subdistricts2 = set(loc.get('subdistrict', '') for loc in locs2.values() if loc.get('subdistrict', ''))
                        if subdistricts1 and subdistricts2 and (subdistricts1 & subdistricts2):
                            return True, '‡∏ï‡∏≥‡∏ö‡∏•'
                        
                        # 2. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
                        districts1 = {(loc.get('district', ''), loc.get('province', '')) for loc in locs1.values() if loc.get('district', '')}
                        districts2 = {(loc.get('district', ''), loc.get('province', '')) for loc in locs2.values() if loc.get('district', '')}
                        if districts1 and districts2:
                            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
                            for d1, p1 in districts1:
                                for d2, p2 in districts2:
                                    if d1 == d2 and p1 == p2 and p1:
                                        return True, '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠'
                        
                        # 3. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
                        provinces1 = set(loc.get('province', '') for loc in locs1.values() if loc.get('province', ''))
                        provinces2 = set(loc.get('province', '') for loc in locs2.values() if loc.get('province', ''))
                        if provinces1 & provinces2:
                            return True, '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'
                        
                        return False, None
                    
                    merged_groups = []
                    used_groups = set()
                    
                    for group1, locs1 in booking_groups.items():
                        if group1 in used_groups:
                            continue
                        
                        merged_codes = set(group1)
                        merged_locs = locs1.copy()
                        used_groups.add(group1)
                        
                        # ‡∏´‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
                        changed = True
                        while changed:
                            changed = False
                            for group2, locs2 in booking_groups.items():
                                if group2 in used_groups:
                                    continue
                                can_merge, level = groups_can_merge(merged_locs, locs2)
                                if can_merge:
                                    merged_codes |= set(group2)
                                    merged_locs.update(locs2)
                                    used_groups.add(group2)
                                    changed = True
                        
                        merged_groups.append({
                            'codes': merged_codes,
                            'locations': merged_locs
                        })
                    
                    # Step 3: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô groups format
                    groups = []
                    for mg in merged_groups:
                        rep_code = list(mg['codes'])[0]
                        rep_row = df_region[df_region['Code'] == rep_code].iloc[0]
                        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà UNKNOWN ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô NaN
                        provinces = set(
                            str(loc.get('province', '')).strip() 
                            for loc in mg['locations'].values() 
                            if loc.get('province') and str(loc.get('province', '')).strip() not in ['UNKNOWN', 'nan', '']
                        )
                        
                        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏•‡∏¢ ‡πÉ‡∏™‡πà "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
                        province_str = ', '.join(sorted(provinces)) if provinces else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                        
                        groups.append({
                            'codes': mg['codes'],
                            'region': rep_row.get('Region', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                            'province': province_str
                        })
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                    st.markdown("---")
                    st.markdown("### üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", df_region['Code'].nunique())
                    with col2:
                        st.metric("üóÇÔ∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°", len(groups))
                    with col3:
                        regions_count = df_region['Region'].nunique()
                        st.metric("üó∫Ô∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏Ñ", regions_count)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
                    st.markdown("---")
                    st.markdown("### üó∫Ô∏è ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ")
                    
                    region_summary = df_region.groupby('Region').agg({
                        'Code': 'nunique',
                        'Weight': 'sum',
                        'Cube': 'sum'
                    }).reset_index()
                    region_summary.columns = ['‡∏†‡∏≤‡∏Ñ', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏ß‡∏°', '‡∏Ñ‡∏¥‡∏ß‡∏£‡∏ß‡∏°']
                    st.dataframe(region_summary, use_container_width=True)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏Ñ
                    for region in sorted(df_region['Region'].unique()):
                        region_data = df_region[df_region['Region'] == region]
                        with st.expander(f"üìç {region} ({region_data['Code'].nunique()} ‡∏™‡∏≤‡∏Ç‡∏≤)"):
                            display_cols = ['Code', 'Name', 'Province', 'Weight', 'Cube']
                            display_cols = [c for c in display_cols if c in region_data.columns]
                            
                            region_display = region_data[display_cols].drop_duplicates('Code')
                            col_names = {'Code': '‡∏£‡∏´‡∏±‡∏™', 'Name': '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', 'Province': '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'Weight': '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å', 'Cube': '‡∏Ñ‡∏¥‡∏ß'}
                            region_display.columns = [col_names.get(c, c) for c in display_cols]
                            st.dataframe(region_display, use_container_width=True)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                    st.markdown("---")
                    st.markdown("### üîó ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)")
                    
                    paired_groups = [g for g in groups if len(g['codes']) > 1]
                    if paired_groups:
                        for i, group in enumerate(paired_groups, 1):
                            codes_list = list(group['codes'])
                            names = []
                            for c in codes_list:
                                name_row = df_region[df_region['Code'] == c]
                                if len(name_row) > 0 and 'Name' in name_row.columns:
                                    names.append(f"{c} ({name_row['Name'].iloc[0]})")
                                else:
                                    names.append(c)
                            
                            st.write(f"**‡∏Å‡∏•‡∏∏‡πà‡∏° {i}** - {group['region']}: {', '.join(names)}")
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ")
                    
                    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
                    st.markdown("---")
                    output_region = io.BytesIO()
                    with pd.ExcelWriter(output_region, engine='xlsxwriter') as writer:
                        df_region.to_excel(writer, sheet_name='‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î', index=False)
                        region_summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ', index=False)
                    
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        st.download_button(
                            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° (Excel)",
                            data=output_region.getvalue(),
                            file_name=f"‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )

if __name__ == "__main__":
    main()
