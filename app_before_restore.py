# ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets ‡∏î‡πâ‡∏ß‡∏¢ gspread
import gspread
from google.oauth2.service_account import Credentials

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î scope ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Google Sheets API
SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']

# URL ‡∏´‡∏£‡∏∑‡∏≠ ID ‡∏Ç‡∏≠‡∏á Google Sheet
SPREADSHEET_ID = '12DmIfECwVpsWfl8rl2r1A_LB4_5XMrmnmwlPUHKNU-o'
# ‡∏ä‡∏∑‡πà‡∏≠‡∏ä‡∏µ‡∏ï‡∏´‡∏£‡∏∑‡∏≠ gid (‡πÄ‡∏ä‡πà‡∏ô 'Sheet1' ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ worksheet_by_id)
WORKSHEET_GID = 876257177

# ‡πÇ‡∏´‡∏•‡∏î credentials (optional - graceful fallback)
gc = None
sh = None
SHEETS_AVAILABLE = False

try:
    creds = Credentials.from_service_account_file('credentials.json', scopes=SCOPES)
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(SPREADSHEET_ID)
    SHEETS_AVAILABLE = True
except FileNotFoundError:
    # credentials.json not found - will show setup message later
    pass
except Exception as e:
    # Other errors - will show message
    pass


# Streamlit Web App ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Google Sheets ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Excel
import streamlit as st
import gspread
from google.oauth2.service_account import Credentials
import pandas as pd
import os

# Import OR-Tools Vehicle Routing Optimization (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
try:
    from ortools_vrp import predict_trips_ortools
    ORTOOLS_AVAILABLE = True
except ImportError:
    ORTOOLS_AVAILABLE = False
    predict_trips_ortools = None

# Import Vehicle Logic (‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ, Buffer, Drop Limits)
try:
    from vehicle_logic import (
        load_vehicle_restrictions_from_excel,
        get_buffer_for_trip,
        get_punthai_drop_limit,
        check_branch_vehicle_compatibility,
        get_max_vehicle_for_branch,
        get_max_vehicle_for_trip,
        filter_vehicles_by_region,
        suggest_truck,
        calculate_utilization,
        is_punthai_only,
        is_central_region,
        PUNTHAI_BUFFER,
        MAXMART_BUFFER
    )
    VEHICLE_LOGIC_AVAILABLE = True
    
    # ‡πÇ‡∏´‡∏•‡∏î Vehicle Restrictions ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå
    VEHICLE_RESTRICTIONS = load_vehicle_restrictions_from_excel()
    if VEHICLE_RESTRICTIONS:
        print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î Vehicle Restrictions: {len(VEHICLE_RESTRICTIONS)} ‡∏™‡∏≤‡∏Ç‡∏≤")
except ImportError:
    VEHICLE_LOGIC_AVAILABLE = False
    VEHICLE_RESTRICTIONS = {}

st.title('üöö ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß - Route Optimizer')

# Show Google Sheets connection status
if SHEETS_AVAILABLE:
    st.success("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets ‡πÅ‡∏•‡πâ‡∏ß")
else:
    st.warning("‚ö†Ô∏è Google Sheets ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")
st.write('**‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤** ‚Üí **‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß‡πÅ‡∏ö‡∏ö Optimization** ‚Üí **‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå**')

import json
from datetime import datetime, time

def sync_branch_data_from_sheets():
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets ‡πÅ‡∏•‡∏∞ sync ‡∏Å‡∏±‡∏ö JSON file
    ‡πÉ‡∏ä‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤ (Code/Plan Code) ‡πÄ‡∏õ‡πá‡∏ô key ‡∏´‡∏•‡∏±‡∏Å
    
    Returns:
        DataFrame ‡∏´‡∏£‡∏∑‡∏≠ None ‡∏ñ‡πâ‡∏≤‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
    """
    global SHEETS_AVAILABLE, sh
    
    json_file = 'branch_data.json'
    
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å JSON
    existing_data = {}
    if os.path.exists(json_file):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô JSON: {e}")
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ Google Sheets ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
    if not SHEETS_AVAILABLE or sh is None:
        if existing_data:
            print(f"üì¶ ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å JSON ({len(existing_data)} ‡∏™‡∏≤‡∏Ç‡∏≤)")
            # ‡πÅ‡∏õ‡∏•‡∏á dict ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô DataFrame
            df = pd.DataFrame.from_dict(existing_data, orient='index')
            df.reset_index(drop=True, inplace=True)
            return df
        else:
            print("‚ÑπÔ∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô JSON ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets")
            print("üí° ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢: python create_sample_data.py")
            return None
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets
    try:
        print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets...")
        worksheet = None
        for ws in sh.worksheets():
            if ws.id == WORKSHEET_GID:
                worksheet = ws
                break
        
        if worksheet is None:
            print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet GID {WORKSHEET_GID}")
            return None
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        data = worksheet.get_all_values()
        
        if len(data) < 2:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Sheet")
            return None
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame
        df_new = pd.DataFrame(data[1:], columns=data[0])
        
        # ‡∏´‡∏≤ column ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤
        code_col = None
        for col in ['Code', 'Plan Code', '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏™‡∏≤‡∏Ç‡∏≤']:
            if col in df_new.columns:
                code_col = col
                break
        
        if code_col is None:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤")
            return None
        
        # ‡∏ô‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà
        new_count = 0
        updated_count = 0
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        dc_wangnoi = {
            '8nvDC011': {
                code_col: '8nvDC011',
                '‡∏™‡∏≤‡∏Ç‡∏≤': 'DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢',
                '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î': 'PROJECT-‡∏ö.‡∏û‡∏µ‡∏ó‡∏µ‡∏à‡∏µ ‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏ô‡∏≠‡∏¢‡∏µ ‡∏à‡∏≥‡∏Å‡∏±‡∏î (‡∏°‡∏´‡∏≤‡∏ä‡∏ô) (DC‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢)',
                '‡∏ï‡∏≥‡∏ö‡∏•': '‡∏û‡∏¢‡∏≠‡∏°',
                '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': '‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢',
                '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î': '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤',
                '‡∏•‡∏∞': 14.1793943,
                '‡∏•‡∏≠‡∏á': 100.6481489,
                'MaxTruckType': '6W'
            }
        }
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        if '8nvDC011' not in existing_data:
            existing_data['8nvDC011'] = dc_wangnoi['8nvDC011']
            new_count += 1
        
        # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        for idx, row in df_new.iterrows():
            code = str(row[code_col]).strip().upper()
            if not code or code == '':
                continue
            
            # ‡πÅ‡∏õ‡∏•‡∏á row ‡πÄ‡∏õ‡πá‡∏ô dict
            row_dict = row.to_dict()
            
            if code in existing_data:
                # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ - ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                if existing_data[code] != row_dict:
                    existing_data[code] = row_dict
                    updated_count += 1
                # ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÑ‡∏°‡πà‡∏ô‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô update
            else:
                # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà - ‡πÄ‡∏û‡∏¥‡πà‡∏°
                existing_data[code] = row_dict
                new_count += 1
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ Sync ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {new_count} ‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà, {updated_count} ‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï, ‡∏£‡∏ß‡∏° {len(existing_data)} ‡∏™‡∏≤‡∏Ç‡∏≤")
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô DataFrame
        df = pd.DataFrame.from_dict(existing_data, orient='index')
        df.reset_index(drop=True, inplace=True)
        
        return df
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î error ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
        if existing_data:
            print(f"üì¶ ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å JSON")
            df = pd.DataFrame.from_dict(existing_data, orient='index')
            return df
        return None


def load_sheet_data():
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets (deprecated - ‡πÉ‡∏ä‡πâ sync_branch_data_from_sheets ‡πÅ‡∏ó‡∏ô)"""
    global SHEETS_AVAILABLE
    
    if not SHEETS_AVAILABLE or gc is None or sh is None:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets - ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå credentials.json")
        st.info("""
        üìù **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Google Sheets Integration:**
        
        1. ‡πÑ‡∏õ‡∏ó‡∏µ‡πà [Google Cloud Console](https://console.cloud.google.com/)
        2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Service Account ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sheets API
        3. ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î JSON key file
        4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô `credentials.json` ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå app
        5. Restart Streamlit app
        
        **‡∏´‡∏£‡∏∑‡∏≠:** ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÅ‡∏ó‡∏ô (‡∏î‡∏π‡πÅ‡∏ó‡πá‡∏ö "üì¶ ‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß")
        """)
        return None
    
    try:
        SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']
        SPREADSHEET_ID = '12DmIfECwVpsWfl8rl2r1A_LB4_5XMrmnmwlPUHKNU-o'
        WORKSHEET_GID = 876257177
        
        worksheet = None
        for ws in sh.worksheets():
            if ws.id == WORKSHEET_GID:
                worksheet = ws
                break
        
        if worksheet is None:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Worksheet ‡∏ó‡∏µ‡πà‡∏°‡∏µ GID {WORKSHEET_GID}")
            return None
        
        data = worksheet.get_all_values()
        return data
    except Exception as e:
        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets: {e}")
        return None

# =============================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏° branch/zone
# =============================
def get_allowed_vehicle_for_branch(branch_code, zone, restrictions):
    allowed = restrictions.get(str(branch_code).strip(), ['4W', 'JB', '6W'])
    if zone == 'CENTRAL' and '6W' in allowed:
        allowed = [v for v in allowed if v != '6W']
    for v in ['6W', 'JB', '4W']:
        if v in allowed:
            return v
    return allowed[0]

# =============================
# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (comment ‡πÑ‡∏ß‡πâ)
# =============================
# restrictions = load_vehicle_restrictions('Dc/Auto planning (1).xlsx', 'Info')
# vehicle = get_allowed_vehicle_for_branch(branch_code, zone, restrictions)
"""
Logistics Planner 
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import glob
from datetime import datetime, time
import io
from math import radians, sin, cos, sqrt, atan2

# Auto-refresh component
try:
    from streamlit_autorefresh import st_autorefresh
    AUTOREFRESH_AVAILABLE = True
except ImportError:
    AUTOREFRESH_AVAILABLE = False
    st.warning("‚ö†Ô∏è ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á streamlit-autorefresh: pip install streamlit-autorefresh")

# ==========================================
# CONFIG
# ==========================================
MODEL_PATH = 'models/decision_tree_model.pkl'

# ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)
LIMITS = {
    '4W': {'max_w': 2500, 'max_c': 5.0, 'max_drops': 12},   # ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 5
    'JB': {'max_w': 3500, 'max_c': 7.0, 'max_drops': 12},   # ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 7
    '6W': {'max_w': 6000, 'max_c': 20.0, 'max_drops': 999}  # ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î, Cube ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡πá‡∏°, Weight ‚â§ 6000
}

# üîí ‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Punthai ‡∏•‡πâ‡∏ß‡∏ô (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 100%)
PUNTHAI_LIMITS = {
    '4W': {'max_w': 2500, 'max_c': 5.0, 'max_drops': 5},   # Punthai ‡∏•‡πâ‡∏ß‡∏ô 4W: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5 ‡∏™‡∏≤‡∏Ç‡∏≤
    'JB': {'max_w': 3500, 'max_c': 7.0, 'max_drops': 10},  # Punthai ‡∏•‡πâ‡∏ß‡∏ô JB: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 ‡∏™‡∏≤‡∏Ç‡∏≤
    '6W': {'max_w': 6000, 'max_c': 20.0, 'max_drops': 999}
}

# üéØ Minimum utilization ‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö balancing)
MIN_UTIL = {
    '4W': 80,   # 4W ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 70%
    'JB': 80,   # JB ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 80%
    '6W': 90    # 6W ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 90%
}

# Buffer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ (‡∏ï‡∏≤‡∏° BU)
BUFFER = 1.0  # Default buffer
PUNTHAI_BUFFER = 1.0  # üÖøÔ∏è Punthai ‡∏•‡πâ‡∏ß‡∏ô: ‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 100%
MAXMART_BUFFER = 1.10  # üÖº Maxmart/‡∏ú‡∏™‡∏°: ‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏î‡πâ 10%

# ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö 4W/JB ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô (6W ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î)
MAX_BRANCHES_PER_TRIP = 12  # ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 12 ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πà‡∏≠‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 4W/JB (6W ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î)

# Performance Config
MAX_DETOUR_KM = 12  # ‡∏•‡∏î‡∏à‡∏≤‡∏Å 15km ‡πÄ‡∏õ‡πá‡∏ô 12km ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô
MAX_MERGE_ITERATIONS = 25  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏¥‡∏õ (‡∏•‡∏î‡∏à‡∏≤‡∏Å 50 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)

# ==========================================
# REGION ORDER CONFIG (Far-to-Near Sorting)
# ==========================================
# ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î: ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ ‚Üí ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô ‚Üí ‡πÉ‡∏ï‡πâ ‚Üí ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å ‚Üí ‡∏Å‡∏•‡∏≤‡∏á
REGION_ORDER = {
    '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': 1, 'NORTH': 1,
    '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô': 2, 'NE': 2,
    '‡πÉ‡∏ï‡πâ': 3, 'SOUTH': 3,
    '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': 4, 'EAST': 4,
    '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': 5, 'WEST': 5,
    '‡∏Å‡∏•‡∏≤‡∏á': 6, 'CENTRAL': 6,
    '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏': 99
}

# ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á: ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ 6W (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 4W, JB)
CENTRAL_REGIONS = ['‡∏Å‡∏•‡∏≤‡∏á', 'CENTRAL']
CENTRAL_ALLOWED_VEHICLES = ['4W', 'JB']  # NO 6W in Central

# ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡πà‡∏á (‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å)
EXCLUDE_BRANCHES = ['DC011', 'PTDC', 'PTG DISTRIBUTION CENTER']

# ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏î‡∏≠‡∏≠‡∏Å (‡πÉ‡∏ä‡πâ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠)
EXCLUDE_NAMES = ['Distribution Center', 'PTG Distribution', '‡∏ö.‡∏û‡∏µ‡∏ó‡∏µ‡∏à‡∏µ ‡πÄ‡∏≠‡πá‡∏ô‡πÄ‡∏ô‡∏≠‡∏¢‡∏µ']

# ‡∏û‡∏¥‡∏Å‡∏±‡∏î DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ (‡∏à‡∏∏‡∏î‡∏Å‡∏•‡∏≤‡∏á)
DC_WANG_NOI_LAT = 14.179394
DC_WANG_NOI_LON = 100.648149

# ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏ñ 6W (‡∏Å‡∏°.)
DISTANCE_REQUIRE_6W = 100  # ‡∏ñ‡πâ‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC ‡πÄ‡∏Å‡∏¥‡∏ô 100 ‡∏Å‡∏°. ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W

# ==========================================
# ZONE/REGION CONFIG - ‡∏£‡∏´‡∏±‡∏™‡∏†‡∏≤‡∏Ñ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
# ==========================================
# ‡∏£‡∏´‡∏±‡∏™‡∏†‡∏≤‡∏Ñ: 1=‡∏Å‡∏•‡∏≤‡∏á, 2=‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å, 3=‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å, 4=‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, 5=‡∏≠‡∏µ‡∏™‡∏≤‡∏ô, 6=‡πÉ‡∏ï‡πâ
REGION_CODE = {
    # ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á (‡∏£‡∏´‡∏±‡∏™ 1)
    '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£': '10', '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø': '10',
    '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ': '11',
    '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ': '12',
    '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤': '13', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤': '13',
    '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ': '14',
    '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ': '15',
    '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ': '16',
    '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á': '17',
    '‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó': '18',
    '‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°': '19',
    '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£': '1A',
    '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£': '1B',
    '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°': '1C',
    
    # ‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å (‡∏£‡∏´‡∏±‡∏™ 2)
    '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ': '20',
    '‡∏£‡∏∞‡∏¢‡∏≠‡∏á': '21',
    '‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ': '22',
    '‡∏ï‡∏£‡∏≤‡∏î': '23',
    '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤': '24',
    '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ': '25',
    '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß': '26',
    '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å': '27',
    
    # ‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å (‡∏£‡∏´‡∏±‡∏™ 3)
    '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ': '30',
    '‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ': '31',
    '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ': '32',
    '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ': '33',
    '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå': '34',
    
    # ‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠ (‡∏£‡∏´‡∏±‡∏™ 4) - ‡πÑ‡∏Å‡∏• ‡πÉ‡∏ä‡πâ 6W ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
    '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå': '40',
    '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ': '41',
    '‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£': '42',
    '‡∏ï‡∏≤‡∏Å': '43',
    '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢': '44',
    '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å': '45',
    '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£': '46',
    '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå': '47',
    '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå': '48',
    '‡πÅ‡∏û‡∏£‡πà': '49',
    '‡∏ô‡πà‡∏≤‡∏ô': '4A',
    '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤': '4B',
    '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢': '4C',
    '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà': '4D',
    '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô': '4E',
    '‡∏•‡∏≥‡∏û‡∏π‡∏ô': '4F',
    '‡∏•‡∏≥‡∏õ‡∏≤‡∏á': '4G',
    
    # ‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å‡πÄ‡∏â‡∏µ‡∏¢‡∏á‡πÄ‡∏´‡∏ô‡∏∑‡∏≠/‡∏≠‡∏µ‡∏™‡∏≤‡∏ô (‡∏£‡∏´‡∏±‡∏™ 5)
    '‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤': '50', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä': '50',
    '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå': '51',
    '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå': '52',
    '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©': '53',
    '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ': '54',
    '‡∏¢‡πÇ‡∏™‡∏ò‡∏£': '55',
    '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥': '56',
    '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç': '57',
    '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π': '58',
    '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô': '59',
    '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ': '5A',
    '‡πÄ‡∏•‡∏¢': '5B',
    '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢': '5C',
    '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°': '5D',
    '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î': '5E',
    '‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå': '5F',
    '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£': '5G',
    '‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°': '5H',
    '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£': '5I',
    '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨': '5J',
    
    # ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ (‡∏£‡∏´‡∏±‡∏™ 6) - ‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å ‡πÉ‡∏ä‡πâ 6W
    '‡∏ä‡∏∏‡∏°‡∏û‡∏£': '60',
    '‡∏£‡∏∞‡∏ô‡∏≠‡∏á': '61',
    '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ': '62',
    '‡∏û‡∏±‡∏á‡∏á‡∏≤': '63',
    '‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà': '64',
    '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï': '65',
    '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä': '66',
    '‡∏ï‡∏£‡∏±‡∏á': '67',
    '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á': '68',
    '‡∏™‡∏á‡∏Ç‡∏•‡∏≤': '69',
    '‡∏™‡∏ï‡∏π‡∏•': '6A',
    '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ': '6B',
    '‡∏¢‡∏∞‡∏•‡∏≤': '6C',
    '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™': '6D',
}

# ‡∏†‡∏≤‡∏Ñ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (‡πÑ‡∏Å‡∏•‡∏à‡∏≤‡∏Å DC)
REGIONS_REQUIRE_6W = ['4', '5', '6']  # ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô, ‡πÉ‡∏ï‡πâ

# ‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏Ñ
REGION_NAMES = {
    '1': '‡∏Å‡∏•‡∏≤‡∏á',
    '2': '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å',
    '3': '‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å',
    '4': '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠',
    '5': '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô',
    '6': '‡πÉ‡∏ï‡πâ',
    '9': '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
}

# ==========================================
# HELPER: ZONE/REGION FUNCTIONS
# ==========================================
def get_region_code(province):
    """‡∏î‡∏∂‡∏á‡∏£‡∏´‡∏±‡∏™‡∏†‡∏≤‡∏Ñ/‡πÇ‡∏ã‡∏ô‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î"""
    if not province or str(province).strip() == '' or str(province) == 'nan':
        return '99'  # ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏
    province = str(province).strip()
    return REGION_CODE.get(province, '99')

def get_region_name(province):
    """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏†‡∏≤‡∏Ñ‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î"""
    code = get_region_code(province)
    if code == '99':
        return '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
    region_prefix = code[0]
    return REGION_NAMES.get(region_prefix, '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏')

def get_recommended_vehicle_by_region(province, distance_from_dc=None):
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ/‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á"""
    code = get_region_code(province)
    region_prefix = code[0] if code != '99' else '9'
    
    # ‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô, ‡πÉ‡∏ï‡πâ ‚Üí ‡πÉ‡∏ä‡πâ 6W
    if region_prefix in REGIONS_REQUIRE_6W:
        return '6W'
    
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡∏¥‡∏ô threshold ‚Üí ‡πÉ‡∏ä‡πâ 6W
    if distance_from_dc and distance_from_dc > DISTANCE_REQUIRE_6W:
        return '6W'
    
    # ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á, ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å, ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å ‚Üí ‡πÉ‡∏ä‡πâ 4W/JB ‡πÑ‡∏î‡πâ
    return 'JB'  # default ‡πÄ‡∏õ‡πá‡∏ô JB

def sort_branches_by_region_route(branches_df, master_data=None):
    """
    ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí Route
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î
    """
    if branches_df.empty:
        return branches_df
    
    df = branches_df.copy()
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sort
    df['_region_code'] = df['Province'].apply(get_region_code) if 'Province' in df.columns else '99'
    df['_province'] = df['Province'].fillna('') if 'Province' in df.columns else ''
    df['_district'] = df['District'].fillna('') if 'District' in df.columns else ''
    df['_subdistrict'] = df['Subdistrict'].fillna('') if 'Subdistrict' in df.columns else ''
    
    # ‡πÅ‡∏¢‡∏Å Route number
    if 'Route' in df.columns:
        df['_route_num'] = df['Route'].apply(lambda x: int(str(x).replace('CD', '')) if pd.notna(x) and str(x).startswith('CD') else 99999)
    else:
        df['_route_num'] = 99999
    
    # Sort
    df = df.sort_values(by=['_region_code', '_province', '_district', '_subdistrict', '_route_num'])
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß
    df = df.drop(columns=['_region_code', '_province', '_district', '_subdistrict', '_route_num'])
    
    return df.reset_index(drop=True)

def check_trip_route_spread(trip_df):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏°‡∏µ Route ‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡πÑ‡∏´‡∏°
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (route_range, is_spread, provinces)
    """
    if trip_df.empty or 'Route' not in trip_df.columns:
        return 0, False, []
    
    routes = trip_df['Route'].dropna().unique()
    route_nums = []
    for r in routes:
        if pd.notna(r) and str(r).startswith('CD'):
            try:
                route_nums.append(int(str(r).replace('CD', '')))
            except:
                pass
    
    if len(route_nums) < 2:
        return 0, False, trip_df['Province'].dropna().unique().tolist() if 'Province' in trip_df.columns else []
    
    route_range = max(route_nums) - min(route_nums)
    is_spread = route_range > 4000  # ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 4000 ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢
    
    provinces = trip_df['Province'].dropna().unique().tolist() if 'Province' in trip_df.columns else []
    
    return route_range, is_spread, provinces

def validate_trip_vehicle(trip_df, assigned_vehicle):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏Ñ/‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (is_valid, recommended_vehicle, reason)
    """
    if trip_df.empty:
        return True, assigned_vehicle, ''
    
    provinces = trip_df['Province'].dropna().unique() if 'Province' in trip_df.columns else []
    
    # ‡∏´‡∏≤‡∏†‡∏≤‡∏Ñ‡∏ó‡∏µ‡πà‡πÑ‡∏Å‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
    farthest_region = '1'  # default ‡∏Å‡∏•‡∏≤‡∏á
    for prov in provinces:
        code = get_region_code(prov)
        region = code[0] if code != '99' else '1'
        if region > farthest_region:
            farthest_region = region
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
    if farthest_region in REGIONS_REQUIRE_6W:
        # ‡∏†‡∏≤‡∏Ñ‡πÑ‡∏Å‡∏• ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ 6W
        if assigned_vehicle in ['4W', 'JB']:
            return False, '6W', f'‡∏†‡∏≤‡∏Ñ{REGION_NAMES.get(farthest_region, "‡πÑ‡∏Å‡∏•")} ‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ 6W'
    
    return True, assigned_vehicle, ''

# ==========================================
# LOAD MASTER DATA
# ==========================================
@st.cache_data(ttl=7200)  # Cache 2 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)
def load_master_data():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á
    ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: 1. JSON (sync ‡∏à‡∏≤‡∏Å Sheets), 2. Excel files
    """
    # 1. ‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å JSON ‡∏ó‡∏µ‡πà sync ‡∏à‡∏≤‡∏Å Google Sheets
    json_file = 'branch_data.json'
    if os.path.exists(json_file):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                branch_data = json.load(f)
            
            if branch_data:
                print(f"üì¶ ‡πÇ‡∏´‡∏•‡∏î Master ‡∏à‡∏≤‡∏Å JSON: {len(branch_data)} ‡∏™‡∏≤‡∏Ç‡∏≤")
                df_master = pd.DataFrame.from_dict(branch_data, orient='index')
                df_master.reset_index(drop=True, inplace=True)
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î column ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
                required_cols = ['Plan Code', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î']
                
                # Mapping column names
                column_mapping = {}
                for col in df_master.columns:
                    col_clean = str(col).strip()
                    if 'plan code' in col_clean.lower() or '‡∏£‡∏´‡∏±‡∏™' in col_clean or col_clean.upper() == 'CODE':
                        column_mapping[col] = 'Plan Code'
                    elif '‡∏ï‡∏≥‡∏ö‡∏•' in col_clean or 'subdistrict' in col_clean.lower():
                        column_mapping[col] = '‡∏ï‡∏≥‡∏ö‡∏•'
                    elif '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠' in col_clean or 'district' in col_clean.lower():
                        column_mapping[col] = '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠'
                    elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean or 'province' in col_clean.lower():
                        column_mapping[col] = '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'
                    elif '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î' in col_clean or 'latitude' in col_clean.lower() or col_clean.upper() == 'LAT':
                        column_mapping[col] = '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î'
                    elif '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î' in col_clean or '‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏à‡∏π‡∏î' in col_clean or 'longitude' in col_clean.lower() or col_clean.upper() in ['LON', 'LONG', 'LNG']:
                        column_mapping[col] = '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î'
                
                if column_mapping:
                    df_master = df_master.rename(columns=column_mapping)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á Plan Code ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ (‡πÉ‡∏ä‡πâ Code ‡πÅ‡∏ó‡∏ô)
                if 'Plan Code' not in df_master.columns:
                    if 'Code' in df_master.columns:
                        df_master['Plan Code'] = df_master['Code']
                    elif '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in df_master.columns:
                        df_master['Plan Code'] = df_master['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤']
                
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Plan Code
                if 'Plan Code' in df_master.columns:
                    df_master['Plan Code'] = df_master['Plan Code'].astype(str).str.strip().str.upper()
                    df_master = df_master[df_master['Plan Code'] != '']
                
                # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ
                available_cols = [col for col in required_cols if col in df_master.columns]
                if available_cols:
                    return df_master[available_cols]
                
                return df_master
                
        except Exception as e:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î JSON: {e}")
    
    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ JSON ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå Excel (Fallback)
    try:
        usecols = ['Plan Code', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î']
        possible_files = ['Dc/‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á.xlsx', 'Dc/Master ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á.xlsx']
        df_master = pd.DataFrame()
        for file_path in possible_files:
            try:
                df_master = pd.read_excel(file_path, usecols=usecols)
                print(f"üì¶ ‡πÇ‡∏´‡∏•‡∏î Master ‡∏à‡∏≤‡∏Å Excel: {file_path}")
                break
            except:
                continue
        if df_master.empty:
            return pd.DataFrame()
        
        # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Plan Code (vectorized)
        if 'Plan Code' in df_master.columns:
            df_master['Plan Code'] = df_master['Plan Code'].astype(str).str.strip().str.upper()
        
        df_master = df_master[df_master['Plan Code'] != '']
        return df_master
    except FileNotFoundError:
        return pd.DataFrame()
    except Exception as e:
        try:
            st.warning(f"‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Master: {e} (‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏ó‡∏ô)")
        except:
            pass
        return pd.DataFrame()

# ‡πÇ‡∏´‡∏•‡∏î Master Data
MASTER_DATA = load_master_data()

# ==========================================
# CLEAN NAME FUNCTION (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥ Join_Key)
# ==========================================
def clean_name(text):
    """
    ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠: ‡∏•‡∏ö prefix ‡∏à./‡∏≠./‡∏ï. ‡πÅ‡∏•‡∏∞ trim whitespace
    ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Join_Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Master Data
    """
    if pd.isna(text) or text is None:
        return ''
    text = str(text)
    # ‡∏•‡∏ö prefix ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    text = text.replace('‡∏à. ', '').replace('‡∏à.', '')
    text = text.replace('‡∏≠. ', '').replace('‡∏≠.', '')
    text = text.replace('‡∏ï. ', '').replace('‡∏ï.', '')
    # ‡∏•‡∏ö prefix ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    text = text.replace('Tambon ', '').replace('Amphoe ', '').replace('Changwat ', '')
    return text.strip()

def normalize_province_name(province):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô)
    """
    if pd.isna(province) or province is None:
        return ''
    province = clean_name(province)
    # Mapping ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
    province_mapping = {
        '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤': '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤',
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏Ø': '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£',
        '‡∏Å‡∏ó‡∏°': '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£',
        '‡∏Å‡∏ó‡∏°.': '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£',
        '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä': '‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤',
    }
    return province_mapping.get(province, province)

def load_master_dist_data():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Master Dist.xlsx ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:
    1. ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏≥‡∏ö‡∏•
    2. Sum_Code (Sort_Code) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå
    
    ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£: ‡πÉ‡∏ä‡πâ Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á Sum_Code ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Sort
    """
    try:
        file_path = 'Dc/Master Dist.xlsx'
        df = pd.read_excel(file_path)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á lookup dict - ‡∏™‡∏≠‡∏á key: Sum_Code ‡πÅ‡∏•‡∏∞ Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•)
        dist_lookup = {}   # key = Sum_Code
        name_lookup = {}   # key = Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•)
        
        for _, row in df.iterrows():
            sum_code = str(row.get('Sum_Code', '')).strip()
            
            # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏û‡∏¥‡πà‡∏° sum_code (Sort_Code) ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢!
            data = {
                'sum_code': sum_code,  # üîë ‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Sort!
                'region': row.get('Region', ''),
                'region_code': row.get('Region_Code', ''),
                'province': row.get('Province', ''),
                'prov_code': row.get('Prov_Code', ''),
                'district': row.get('District', ''),
                'dist_code': row.get('Dist_Code', ''),
                'subdistrict': row.get('Subdistrict', ''),
                'subdist_code': row.get('Subdist_Code', ''),
                'dist_from_dc_km': float(row.get('Dist_from_DC_km', 9999)) if pd.notna(row.get('Dist_from_DC_km')) else 9999,
                'prov_dist_km': float(row.get('Prov_Dist_km', 0)) if pd.notna(row.get('Prov_Dist_km')) else 0,
                'dist_subdist_km': float(row.get('Dist_Subdist_km', 0)) if pd.notna(row.get('Dist_Subdist_km')) else 0,
            }
            
            # Key 1: Sum_Code (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö lookup ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)
            if sum_code:
                dist_lookup[sum_code] = data
            
            # Key 2: Join_Key (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î_‡∏≠‡∏≥‡πÄ‡∏†‡∏≠_‡∏ï‡∏≥‡∏ö‡∏•) - ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏Ç‡∏≠‡∏á Lookup!
            prov_raw = str(row.get('Province', ''))
            dist_raw = str(row.get('District', ''))
            subdist_raw = str(row.get('Subdistrict', ''))
            
            # Clean name ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Join
            prov_clean = clean_name(prov_raw)
            dist_clean = clean_name(dist_raw)
            subdist_clean = clean_name(subdist_raw)
            
            # Join_Key ‡πÅ‡∏ö‡∏ö clean (‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô)
            join_key = f"{prov_clean}_{dist_clean}_{subdist_clean}"
            if join_key and join_key != '__':
                name_lookup[join_key] = data
            
            # Join_Key ‡πÅ‡∏ö‡∏ö normalized province (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô)
            prov_normalized = normalize_province_name(prov_raw)
            if prov_normalized != prov_clean:
                alt_key = f"{prov_normalized}_{dist_clean}_{subdist_clean}"
                if alt_key and alt_key != '__':
                    name_lookup[alt_key] = data
            
            # Join_Key ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ prefix (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ prefix)
            raw_key = f"{prov_raw.strip()}_{dist_raw.strip()}_{subdist_raw.strip()}"
            if raw_key and raw_key != '__' and raw_key not in name_lookup:
                name_lookup[raw_key] = data
        
        return {'by_code': dist_lookup, 'by_name': name_lookup}
    except Exception as e:
        return {'by_code': {}, 'by_name': {}}

# ‡πÇ‡∏´‡∏•‡∏î Master Dist Data
MASTER_DIST_DATA = load_master_dist_data()

# ==========================================
# PUNTHAI/MAXMART BUFFER FUNCTIONS
# ==========================================
def is_punthai_only(trip_data):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô Punthai ‡∏•‡πâ‡∏ß‡∏ô, Maxmart ‡∏•‡πâ‡∏ß‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏™‡∏°
    
    Returns:
        'punthai_only': ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô Punthai (BU = 211 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ PUNTHAI)
        'maxmart_only': ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô Maxmart (BU = 200 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ MAXMART)
        'mixed': ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á Punthai ‡πÅ‡∏•‡∏∞ Maxmart
        'other': ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• BU
    """
    if trip_data is None or len(trip_data) == 0:
        return 'other'
    
    punthai_count = 0
    maxmart_count = 0
    total_count = len(trip_data)
    
    for _, row in trip_data.iterrows():
        bu = row.get('BU', None)
        name = str(row.get('Name', '')).upper()
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ Punthai: BU = 211 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ PUNTHAI
        if bu == 211 or bu == '211' or 'PUNTHAI' in name or 'PUN-' in name:
            punthai_count += 1
        # ‡πÄ‡∏ä‡πá‡∏Ñ Maxmart: BU = 200 ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ MAXMART/MAX MART
        elif bu == 200 or bu == '200' or 'MAXMART' in name or 'MAX MART' in name:
            maxmart_count += 1
    
    if punthai_count == total_count:
        return 'punthai_only'
    elif maxmart_count == total_count:
        return 'maxmart_only'
    elif punthai_count > 0 or maxmart_count > 0:
        return 'mixed'
    else:
        return 'other'

def get_buffer_for_trip(trip_data):
    """
    ‡∏î‡∏∂‡∏á Buffer ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ï‡∏≤‡∏° BU ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ
    
    Rules:
    - Punthai ‡∏•‡πâ‡∏ß‡∏ô: BUFFER = 1.0 (‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏Å‡∏¥‡∏ô 100%)
    - Maxmart ‡∏•‡πâ‡∏ß‡∏ô/‡∏ú‡∏™‡∏°: BUFFER = 1.10 (‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏î‡πâ 10%)
    
    Returns:
        float: buffer multiplier (1.0 ‡∏´‡∏£‡∏∑‡∏≠ 1.10)
    """
    trip_type = is_punthai_only(trip_data)
    
    if trip_type == 'punthai_only':
        return PUNTHAI_BUFFER  
    elif trip_type in ['maxmart_only', 'mixed']:
        return MAXMART_BUFFER  
    else:
        return BUFFER  

def get_punthai_drop_limit(trip_data, vehicle_type):
    """
    ‡∏î‡∏∂‡∏á‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Drop ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Punthai ‡∏•‡πâ‡∏ß‡∏ô
    
    Rules:
    - Punthai ‡∏•‡πâ‡∏ß‡∏ô + 4W: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5 ‡∏™‡∏≤‡∏Ç‡∏≤
    - Punthai ‡∏•‡πâ‡∏ß‡∏ô + JB: ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 7 drop
    - ‡∏≠‡∏∑‡πà‡∏ô‡πÜ: ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î (999)
    
    Returns:
        int: max drops allowed
    """
    trip_type = is_punthai_only(trip_data)
    
    if trip_type == 'punthai_only':
        return PUNTHAI_LIMITS.get(vehicle_type, {}).get('max_drops', 999)
    else:
        return 999  # ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î

@st.cache_data(ttl=3600)  # Cache 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
def load_booking_history_restrictions():
    """‡πÇ‡∏´‡∏•‡∏î‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡∏à‡∏≤‡∏Å Booking History - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á 3,053 booking (Optimized)"""
    try:
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Booking History (‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö)
        possible_files = [
            'Dc/‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏™‡πà‡∏á DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢(1).xlsx',
            'Dc/‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏á‡∏≤‡∏ô‡∏à‡∏±‡∏î‡∏™‡πà‡∏á DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢.xlsx',
            'branch_vehicle_restrictions_from_booking.xlsx'
        ]
        
        file_path = None
        for path in possible_files:
            if os.path.exists(path):
                file_path = path
                break
        
        if not file_path:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ (fallback)
            return load_learned_restrictions_fallback()
        
        df = pd.read_excel(file_path)
        
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ
        vehicle_mapping = {
            '4 ‡∏•‡πâ‡∏≠ ‡∏à‡∏±‡∏°‡πÇ‡∏ö‡πâ ‡∏ï‡∏π‡πâ‡∏ó‡∏∂‡∏ö': 'JB',
            '6 ‡∏•‡πâ‡∏≠ ‡∏ï‡∏π‡πâ‡∏ó‡∏∂‡∏ö': '6W',
            '4 ‡∏•‡πâ‡∏≠ ‡∏ï‡∏π‡πâ‡∏ó‡∏∂‡∏ö': '4W'
        }
        df['Vehicle_Type'] = df['‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ'].map(vehicle_mapping)
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏™‡∏≤‡∏Ç‡∏≤-‡∏£‡∏ñ (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Booking No)
        branch_vehicle_history = {}
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏™‡∏≤‡∏Ç‡∏≤
        for branch_code in df['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤'].dropna().unique():
            branch_data = df[df['‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤'] == branch_code]
            vehicle_types = branch_data['Vehicle_Type'].dropna().unique()
            if len(vehicle_types) > 0:
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ
                branch_vehicle_history[branch_code] = list(branch_data['Vehicle_Type'].dropna())
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á restrictions
        branch_restrictions = {}
        vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
        
        for branch_code, vehicle_list in branch_vehicle_history.items():
            vehicles_used = set(vehicle_list)
            vehicle_counts = pd.Series(vehicle_list).value_counts().to_dict()
            
            if len(vehicles_used) == 1:
                # STRICT - ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
                vehicle = list(vehicles_used)[0]
                branch_restrictions[str(branch_code)] = {
                    'max_vehicle': vehicle,
                    'allowed': [vehicle],
                    'total_bookings': len(vehicle_list),
                    'restriction_type': 'STRICT'
                }
            else:
                # FLEXIBLE - ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
                max_vehicle = max(vehicles_used, key=lambda v: vehicle_sizes.get(v, 0))
                branch_restrictions[str(branch_code)] = {
                    'max_vehicle': max_vehicle,
                    'allowed': list(vehicles_used),
                    'total_bookings': len(vehicle_list),
                    'restriction_type': 'FLEXIBLE'
                }
        
        stats = {
            'total_branches': len(branch_restrictions),
            'strict': len([b for b, r in branch_restrictions.items() if r['restriction_type'] == 'STRICT']),
            'flexible': len([b for b, r in branch_restrictions.items() if r['restriction_type'] == 'FLEXIBLE']),
            'total_bookings': len(df)
        }
        
        return {
            'branch_restrictions': branch_restrictions,
            'stats': stats
        }
    except Exception as e:
        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏î error ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ó‡∏ô
        return load_learned_restrictions_fallback()

def load_learned_restrictions_fallback():
    """
    ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å Booking History (backup)
    ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ
    
    ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå 3,053 bookings, 2,790 ‡∏™‡∏≤‡∏Ç‡∏≤:
    - JB: ‡∏£‡∏ñ‡∏Å‡∏•‡∏≤‡∏á (‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 54.7%)
    - 6W: ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà (30.1%)
    - 4W: ‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å (0.2%)
    
    ‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• default ‡πÄ‡∏õ‡πá‡∏ô JB (‡∏£‡∏ñ‡∏Å‡∏•‡∏≤‡∏á ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà)
    """
    return {
        'branch_restrictions': {},
        'stats': {
            'total_branches': 0,
            'strict': 0,
            'flexible': 0,
            'total_bookings': 0,
            'fallback': True,
            'message': '‡πÉ‡∏ä‡πâ Punthai ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å (‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Booking History)'
        }
    }

@st.cache_data(ttl=3600)  # Cache 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
def load_punthai_reference():
    """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Punthai Maxmart ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ (Location patterns - Optimized)"""
    try:
        file_path = 'Dc/‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô Punthai Maxmart ‡∏£‡∏≠‡∏ö‡∏™‡∏±‡πà‡∏á 24‡∏´‡∏¢‡∏¥‡∏ö 25‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2568 To.‡πÄ‡∏ü‡∏¥(1) - ‡∏™‡∏≥‡πÄ‡∏ô‡∏≤.xlsx'
        df = pd.read_excel(file_path, sheet_name='2.Punthai', header=1)
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ Trip ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà DC/Distribution Center
        df_clean = df[df['Trip'].notna()].copy()
        df_clean = df_clean[~df_clean['BranchCode'].isin(['DC011', 'PTDC', 'PTG Distribution Center'])].copy()
        
        # Extract vehicle type from Trip no (‡πÄ‡∏ä‡πà‡∏ô 4W009 ‚Üí 4W)
        df_clean['Vehicle_Type'] = df_clean['Trip no'].apply(
            lambda x: str(x)[:2] if pd.notna(x) else 'Unknown'
        )
        
        # Merge ‡∏Å‡∏±‡∏ö Master ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡∏ö‡∏•/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        try:
            df_master = pd.read_excel('Dc/Master ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á.xlsx')
            df_clean = df_clean.merge(
                df_master[['Plan Code', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î']],
                left_on='BranchCode',
                right_on='Plan Code',
                how='left'
            )
        except:
            pass
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡∏à‡∏≤‡∏Å Punthai (‡πÅ‡∏ú‡∏ô) - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Booking
        punthai_restrictions = {}
        vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
        
        for branch_code in df_clean['BranchCode'].unique():
            branch_data = df_clean[df_clean['BranchCode'] == branch_code]
            vehicles_used = set(branch_data['Vehicle_Type'].dropna().tolist())
            vehicles_used = {v for v in vehicles_used if v in ['4W', 'JB', '6W']}
            
            if vehicles_used:
                if len(vehicles_used) == 1:
                    vehicle = list(vehicles_used)[0]
                    punthai_restrictions[str(branch_code)] = {
                        'max_vehicle': vehicle,
                        'allowed': [vehicle],
                        'source': 'PUNTHAI'
                    }
                else:
                    max_vehicle = max(vehicles_used, key=lambda v: vehicle_sizes.get(v, 0))
                    punthai_restrictions[str(branch_code)] = {
                        'max_vehicle': max_vehicle,
                        'allowed': list(vehicles_used),
                        'source': 'PUNTHAI'
                    }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á dictionary: Trip ‚Üí ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (location patterns)
        trip_patterns = {}
        location_stats = {
            'same_province': 0,
            'mixed_province': 0,
            'avg_branches': 0
        }
        
        for trip_num in df_clean['Trip'].unique():
            trip_data = df_clean[df_clean['Trip'] == trip_num]
            
            # Get location info
            provinces = set(trip_data['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'].dropna().tolist()) if '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in trip_data.columns else set()
            
            # Count same vs mixed province
            if len(provinces) == 1:
                location_stats['same_province'] += 1
            elif len(provinces) > 1:
                location_stats['mixed_province'] += 1
            
            trip_patterns[int(trip_num)] = {
                'branches': len(trip_data),
                'codes': trip_data['BranchCode'].tolist(),
                'weight': trip_data['TOTALWGT'].sum() if 'TOTALWGT' in trip_data.columns else 0,
                'cube': trip_data['TOTALCUBE'].sum() if 'TOTALCUBE' in trip_data.columns else 0,
                'provinces': list(provinces),
                'same_province': len(provinces) == 1
            }
        
        # Calculate stats
        if trip_patterns:
            location_stats['avg_branches'] = sum(t['branches'] for t in trip_patterns.values()) / len(trip_patterns)
            total = location_stats['same_province'] + location_stats['mixed_province']
            location_stats['same_province_pct'] = (location_stats['same_province'] / total * 100) if total > 0 else 0
        
        return {
            'patterns': trip_patterns, 
            'stats': location_stats,
            'punthai_restrictions': punthai_restrictions
        }
    except:
        return {'patterns': {}, 'stats': {}, 'punthai_restrictions': {}}

# ‡πÇ‡∏´‡∏•‡∏î Booking History (‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ)
BOOKING_RESTRICTIONS = load_booking_history_restrictions()

# ‡πÇ‡∏´‡∏•‡∏î Punthai Reference (location patterns)
PUNTHAI_PATTERNS = load_punthai_reference()

# ==========================================
# HELPER FUNCTIONS
# ==========================================
def normalize(val):
    """‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"""
    return str(val).strip().upper().replace(" ", "").replace(".0", "")

def calculate_distance(lat1, lon1, lat2, lon2):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏≠‡∏á‡∏à‡∏∏‡∏î (‡∏Å‡∏°.) - Haversine formula"""
    if lat1 == 0 or lon1 == 0 or lat2 == 0 or lon2 == 0:
        return 0
    import math
    lat1_rad, lon1_rad = math.radians(lat1), math.radians(lon1)
    lat2_rad, lon2_rad = math.radians(lat2), math.radians(lon2)
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad
    a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2)**2
    c = 2 * math.asin(math.sqrt(a))
    return 6371 * c

def calculate_distance_from_dc(lat, lon):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ (‡∏Å‡∏°.)"""
    return calculate_distance(DC_WANG_NOI_LAT, DC_WANG_NOI_LON, lat, lon)

def calculate_bearing(lat1, lon1, lat2, lon2):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (bearing) ‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î 1 ‡πÑ‡∏õ‡∏à‡∏∏‡∏î 2
    Returns: ‡∏°‡∏∏‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏á‡∏®‡∏≤ (0-360) ‡πÇ‡∏î‡∏¢ 0 = ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠, 90 = ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å, 180 = ‡πÉ‡∏ï‡πâ, 270 = ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å
    """
    if lat1 == 0 or lon1 == 0 or lat2 == 0 or lon2 == 0:
        return None
    import math
    lat1_rad = math.radians(lat1)
    lat2_rad = math.radians(lat2)
    dlon_rad = math.radians(lon2 - lon1)
    
    x = math.sin(dlon_rad) * math.cos(lat2_rad)
    y = math.cos(lat1_rad) * math.sin(lat2_rad) - math.sin(lat1_rad) * math.cos(lat2_rad) * math.cos(dlon_rad)
    
    bearing_rad = math.atan2(x, y)
    bearing_deg = math.degrees(bearing_rad)
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô 0-360
    return (bearing_deg + 360) % 360

def is_opposite_direction(bearing1, bearing2, threshold=120):
    """
    ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≠‡∏á‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    Args:
        bearing1, bearing2: ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏á‡∏®‡∏≤ (0-360)
        threshold: ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏° (‡∏≠‡∏á‡∏®‡∏≤)
    Returns:
        True ‡∏ñ‡πâ‡∏≤‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏±‡∏ô
    """
    if bearing1 is None or bearing2 is None:
        return False
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏°‡∏∏‡∏°
    diff = abs(bearing1 - bearing2)
    if diff > 180:
        diff = 360 - diff
    
    # ‡∏ñ‡πâ‡∏≤‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ threshold ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏°
    return diff >= threshold

def check_branch_vehicle_compatibility(branch_code, vehicle_type):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏° (‡∏£‡∏ß‡∏° Booking + Punthai)"""
    branch_code_str = str(branch_code).strip()
    
    # 1. ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Booking History ‡∏Å‡πà‡∏≠‡∏ô (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)
    booking_restrictions = BOOKING_RESTRICTIONS.get('branch_restrictions', {})
    if branch_code_str in booking_restrictions:
        allowed = booking_restrictions[branch_code_str].get('allowed', [])
        return vehicle_type in allowed
    
    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Punthai (‡πÅ‡∏ú‡∏ô)
    punthai_restrictions = PUNTHAI_PATTERNS.get('punthai_restrictions', {})
    if branch_code_str in punthai_restrictions:
        allowed = punthai_restrictions[branch_code_str].get('allowed', [])
        return vehicle_type in allowed
    
    # 3. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• = ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô
    return True

def get_max_vehicle_for_branch(branch_code):
    """‡∏î‡∏∂‡∏á‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡∏ô‡∏µ‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (‡∏£‡∏ß‡∏° Booking History + Punthai)"""
    branch_code_str = str(branch_code).strip()
    
    # 1. ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Booking History ‡∏Å‡πà‡∏≠‡∏ô (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏™‡∏π‡∏á)
    booking_restrictions = BOOKING_RESTRICTIONS.get('branch_restrictions', {})
    if branch_code_str in booking_restrictions:
        return booking_restrictions[branch_code_str].get('max_vehicle', '6W')
    
    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å Punthai (‡πÅ‡∏ú‡∏ô - ‡∏™‡∏≥‡∏£‡∏≠‡∏á)
    punthai_restrictions = PUNTHAI_PATTERNS.get('punthai_restrictions', {})
    if branch_code_str in punthai_restrictions:
        return punthai_restrictions[branch_code_str].get('max_vehicle', '6W')
    
    # 3. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á = ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏î‡πâ
    return '6W'

def get_max_vehicle_for_trip(trip_codes):
    """
    ‡∏´‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏¥‡∏õ‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ)
    
    Args:
        trip_codes: set ‡∏Ç‡∏≠‡∏á branch codes ‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
    
    Returns:
        str: '4W', 'JB', ‡∏´‡∏£‡∏∑‡∏≠ '6W'
    """
    vehicle_priority = {'4W': 1, 'JB': 2, '6W': 3}
    max_allowed = '6W'  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤
    min_priority = 3  # ‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î
    
    for code in trip_codes:
        branch_max = get_max_vehicle_for_branch(code)
        priority = vehicle_priority.get(branch_max, 3)
        
        # üîí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î) ‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
        if priority < min_priority:
            min_priority = priority
            max_allowed = branch_max
    
    return max_allowed

def get_required_vehicle_by_distance(branch_code):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC"""
    # ‡∏î‡∏∂‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏≤‡∏Å Master
    if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
        master_row = MASTER_DATA[MASTER_DATA['Plan Code'] == branch_code]
        if len(master_row) > 0:
            lat = master_row.iloc[0].get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
            lon = master_row.iloc[0].get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
            distance = calculate_distance_from_dc(lat, lon)
            
            # ‡∏ñ‡πâ‡∏≤‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC ‡πÄ‡∏Å‡∏¥‡∏ô‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W
            if distance > DISTANCE_REQUIRE_6W:
                return '6W', distance
    
    return None, 0

def can_fit_truck(total_weight, total_cube, truck_type):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡πÉ‡∏™‡πà‡∏£‡∏ñ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    limits = LIMITS[truck_type]
    max_w = limits['max_w'] * BUFFER
    max_c = limits['max_c'] * BUFFER
    return total_weight <= max_w and total_cube <= max_c

def suggest_truck(total_weight, total_cube, max_allowed='6W', trip_codes=None):
    """
    ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÇ‡∏î‡∏¢‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà:
    1. ‡πÉ‡∏™‡πà‡∏Ç‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏û‡∏≠‡∏î‡∏µ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î 105%)
    2. ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÉ‡∏Å‡∏•‡πâ 100% ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: 90-100%)
    3. ‡πÄ‡∏Ñ‡∏≤‡∏£‡∏û‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà 4W = ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 4W ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô)
    """
    vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
    max_size = vehicle_sizes.get(max_allowed, 3)
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°
    branch_max_vehicle = '4W'  # üîí ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà 4W (‡πÄ‡∏•‡πá‡∏Å‡∏™‡∏∏‡∏î) ‡πÅ‡∏•‡πâ‡∏ß‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
    if trip_codes is not None and len(trip_codes) > 0:
        for code in trip_codes:
            branch_max = get_max_vehicle_for_branch(code)
            # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ
            if vehicle_sizes.get(branch_max, 3) < vehicle_sizes.get(branch_max_vehicle, 3):
                branch_max_vehicle = branch_max
        
        # ‡∏à‡∏≥‡∏Å‡∏±‡∏î max_allowed ‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤
        if vehicle_sizes.get(branch_max_vehicle, 3) < max_size:
            max_allowed = branch_max_vehicle
            max_size = vehicle_sizes.get(max_allowed, 3)
    
    best_truck = None
    best_utilization = 0
    best_distance_from_100 = 999  # ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å 100%
    
    for truck in ['4W', 'JB', '6W']:
        truck_size = vehicle_sizes.get(truck, 0)
        # ‡∏ñ‡πâ‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ
        if truck_size > max_size:
            continue
        if can_fit_truck(total_weight, total_cube, truck):
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì % ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ
            limits = LIMITS[truck]
            w_util = (total_weight / limits['max_w']) * 100
            c_util = (total_cube / limits['max_c']) * 100
            utilization = max(w_util, c_util)
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å 100%
            distance_from_100 = abs(100 - utilization)
            
            # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ 100% ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (90-105% ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢)
            # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤
            if best_truck is None:
                best_truck = truck
                best_utilization = utilization
                best_distance_from_100 = distance_from_100
            else:
                # ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 90-105% ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ 100% ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
                if 90 <= utilization <= 105:
                    if distance_from_100 < best_distance_from_100 or best_utilization < 90:
                        best_truck = truck
                        best_utilization = utilization
                        best_distance_from_100 = distance_from_100
                # ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤
                elif utilization > best_utilization:
                    best_truck = truck
                    best_utilization = utilization
                    best_distance_from_100 = distance_from_100
    
    if best_truck:
        return best_truck
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
    return max_allowed if max_allowed in LIMITS else '6W+'

def calculate_optimal_vehicle_split(total_weight, total_cube, max_allowed='6W', branch_count=0):
    """
    üöõ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
    
    ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç:
    - 4W: ‚â§12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 5
    - JB: ‚â§12 ‡∏à‡∏∏‡∏î, Cube ‚â§ 8  
    - 6W: ‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î, Cube ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡πá‡∏° ‚â•100%
    
    ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å:
    1. 4W (‡∏ñ‡πâ‡∏≤ cube ‚â§ 5)
    2. JB (‡∏ñ‡πâ‡∏≤ cube ‚â§ 8)
    3. JB + 4W (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    4. JB + JB (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    5. 6W + JB (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    6. 4W + 4W (‡πÅ‡∏¢‡∏Å 2 ‡∏Ñ‡∏±‡∏ô, 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô)
    7. 6W (cube ‡∏ï‡πâ‡∏≠‡∏á ‚â•100%)
    
    Returns: (vehicle_type, split_needed, split_config)
    """
    vehicle_priority = {'4W': 1, 'JB': 2, '6W': 3}
    max_priority = vehicle_priority.get(max_allowed, 3)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì utilization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏ñ (‡πÉ‡∏ä‡πâ Cube ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å)
    cube_util_4w = (total_cube / LIMITS['4W']['max_c']) * 100  # max 5 cube
    cube_util_jb = (total_cube / LIMITS['JB']['max_c']) * 100  # max 8 cube
    cube_util_6w = (total_cube / LIMITS['6W']['max_c']) * 100  # max 20 cube
    
    weight_util_4w = (total_weight / LIMITS['4W']['max_w']) * 100
    weight_util_jb = (total_weight / LIMITS['JB']['max_w']) * 100
    weight_util_6w = (total_weight / LIMITS['6W']['max_w']) * 100
    
    # üéØ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢: Utilization 75%-95% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å, 95%-105% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    SPLIT_MIN = 75   # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å
    SPLIT_MAX = 95   # ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å
    SINGLE_MIN = 95  # ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    SINGLE_MAX = 105 # ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤ (4W/JB ‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 12 ‡∏à‡∏∏‡∏î)
    branch_ok_for_small = branch_count <= 12 or branch_count == 0
    
    # 1. ‡∏•‡∏≠‡∏á 4W ‡∏Å‡πà‡∏≠‡∏ô (‡∏ñ‡πâ‡∏≤ cube ‚â§ 5 ‡πÅ‡∏•‡∏∞ ‚â§12 ‡∏à‡∏∏‡∏î)
    if max_priority >= 1 and total_cube <= 5.0 and branch_ok_for_small:
        if cube_util_4w <= 105 and weight_util_4w <= 105:
            return ('4W', False, None)
    
    # 2. ‡∏•‡∏≠‡∏á JB (‡∏ñ‡πâ‡∏≤ cube ‚â§ 8 ‡πÅ‡∏•‡∏∞ ‚â§12 ‡∏à‡∏∏‡∏î)
    if max_priority >= 2 and total_cube <= 8.0 and branch_ok_for_small:
        if cube_util_jb <= 105 and weight_util_jb <= 105:
            return ('JB', False, None)
    
    # 3. ‡∏ñ‡πâ‡∏≤‡∏£‡∏ñ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏°‡πà‡∏û‡∏≠ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏¢‡∏Å (cube > 8 ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏∏‡∏î > 12)
    need_split = total_cube > 8.0 or not branch_ok_for_small
    
    if need_split:
        # üîÑ ‡∏•‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö - ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ 75%-95% ‡∏ï‡πà‡∏≠‡∏Ñ‡∏±‡∏ô
        
        # JB + 4W (JB 8 cube + 4W 5 cube = 13 cube max)
        if max_priority >= 2 and total_cube <= 13.0:
            # ‡πÅ‡∏ö‡πà‡∏á: JB ‡∏£‡∏±‡∏ö cube ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤, 4W ‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
            jb_cube = min(total_cube * 0.6, 8.0)  # JB ‡∏£‡∏±‡∏ö 60% ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 8
            four_w_cube = total_cube - jb_cube
            
            jb_util = (jb_cube / LIMITS['JB']['max_c']) * 100
            four_w_util = (four_w_cube / LIMITS['4W']['max_c']) * 100
            
            if SPLIT_MIN <= jb_util <= SPLIT_MAX and SPLIT_MIN <= four_w_util <= SPLIT_MAX:
                return ('JB', True, {'split': ['JB', '4W'], 'ratio': [jb_cube/total_cube, four_w_cube/total_cube]})
        
        # JB + JB (JB 8 + JB 8 = 16 cube max)
        if max_priority >= 2 and total_cube <= 16.0:
            jb_util_half = (total_cube / 2 / LIMITS['JB']['max_c']) * 100
            if SPLIT_MIN <= jb_util_half <= SPLIT_MAX:
                return ('JB', True, {'split': ['JB', 'JB'], 'ratio': [0.5, 0.5]})
        
        # 6W + JB (6W 20 + JB 8 = 28 cube max)
        if max_priority >= 3 and total_cube <= 28.0:
            # ‡πÅ‡∏ö‡πà‡∏á: 6W ‡∏£‡∏±‡∏ö‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà
            six_w_cube = min(total_cube * 0.7, 20.0)
            jb_cube = total_cube - six_w_cube
            
            six_w_util = (six_w_cube / LIMITS['6W']['max_c']) * 100
            jb_util = (jb_cube / LIMITS['JB']['max_c']) * 100
            
            if six_w_util >= 75 and SPLIT_MIN <= jb_util <= SPLIT_MAX:
                return ('6W', True, {'split': ['6W', 'JB'], 'ratio': [six_w_cube/total_cube, jb_cube/total_cube]})
        
        # 4W + 4W (4W 5 + 4W 5 = 10 cube max) - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î 4W
        if max_priority == 1 and total_cube <= 10.0:
            four_w_util_half = (total_cube / 2 / LIMITS['4W']['max_c']) * 100
            if SPLIT_MIN <= four_w_util_half <= SPLIT_MAX:
                return ('4W', True, {'split': ['4W', '4W'], 'ratio': [0.5, 0.5]})
    
    # 4. 6W (‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏∏‡∏î ‡πÅ‡∏ï‡πà cube ‡∏ï‡πâ‡∏≠‡∏á ‚â•100%)
    if max_priority >= 3:
        if cube_util_6w >= 100:
            return ('6W', False, None)
        elif cube_util_6w >= 80:
            # 6W ‡πÑ‡∏°‡πà‡πÄ‡∏ï‡πá‡∏° (80-99%) ‚Üí ‡∏¢‡∏±‡∏á‡∏û‡∏≠‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ
            return ('6W', False, None)
        else:
            # 6W ‡∏ß‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å (<80%) ‚Üí ‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô JB ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ
            if total_cube <= 8.0 and branch_ok_for_small and max_priority >= 2:
                return ('JB', False, None)
            # ‡∏ñ‡πâ‡∏≤ JB ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô 4W
            if total_cube <= 5.0 and branch_ok_for_small:
                return ('4W', False, None)
    
    # Default: ‡πÉ‡∏ä‡πâ max_allowed
    return (max_allowed, False, None)

def can_branch_use_vehicle(code, vehicle_type, branch_vehicles):
    """
    ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà = ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ
    - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡πÅ‡∏Ñ‡πà‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å (‡πÄ‡∏ä‡πà‡∏ô 4W) = ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ)
    """
    if not branch_vehicles or code not in branch_vehicles:
        return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏ñ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ô‡∏µ‡πâ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    if vehicle_type in vehicle_history:
        return True
    
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ (6W > JB > 4W)
    vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
    requested_size = vehicle_sizes.get(vehicle_type, 0)
    
    # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ
    max_used_size = max(vehicle_sizes.get(v, 0) for v in vehicle_history)
    
    # ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏•‡πá‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
    # ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ)
    return requested_size <= max_used_size

def get_max_vehicle_for_branch_old(code, branch_vehicles):
    """[OLD] ‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ (‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏µ‡πâ)"""
    if not branch_vehicles or code not in branch_vehicles:
        return '6W'  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥ = ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ñ‡∏∂‡∏á 6W
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return '6W'
    
    vehicle_sizes = {'4W': 1, 'JB': 2, '6W': 3}
    max_vehicle = max(vehicle_history.keys(), key=lambda v: vehicle_sizes.get(v, 0))
    return max_vehicle

def get_most_used_vehicle_for_branch(code, branch_vehicles):
    """‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ä‡πâ‡∏ö‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î"""
    if not branch_vehicles or code not in branch_vehicles:
        return None
    
    vehicle_history = branch_vehicles[code]
    if not vehicle_history:
        return None
    
    return max(vehicle_history, key=vehicle_history.get)

def is_similar_name(name1, name2):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© + ‡∏î‡∏π‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"""
    def extract_keywords(name):
        """‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤"""
        if pd.isna(name) or name is None:
            return set(), "", ""
        s = str(name).strip().upper()
        
        # ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà (‡πÑ‡∏ó‡∏¢ + ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
        keywords = set()
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏ö‡∏ö exact match
        important_words = [
            '‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£‡πå', 'FUTURE', '‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï', 'RANGSIT',
            '‡πÄ‡∏ã‡πá‡∏ô‡∏ó‡∏£‡∏±‡∏•', 'CENTRAL', '‡πÄ‡∏ó‡∏™‡πÇ‡∏Å‡πâ', 'TESCO', '‡πÇ‡∏•‡∏ï‡∏±‡∏™', 'LOTUS',
            '‡∏ö‡∏¥‡πä‡∏Å‡∏ã‡∏µ', 'BIGC', '‡πÅ‡∏°‡πá‡∏Ñ‡πÇ‡∏Ñ‡∏£', 'MAKRO', '‡πÇ‡∏Æ‡∏°‡πÇ‡∏õ‡∏£', 'HOMEPRO',
            '‡∏ã‡∏µ‡∏Ñ‡∏≠‡∏ô', 'SEACON', '‡πÄ‡∏°‡∏Å‡∏≤', 'MEGA', '‡∏û‡∏≤‡∏£‡∏≤‡πÑ‡∏î‡∏ã‡πå', 'PARADISE',
            '‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏≠‡∏•', 'TERMINAL', '‡∏™‡∏¢‡∏≤‡∏°‡∏û‡∏≤‡∏£‡∏≤‡∏Å‡∏≠‡∏ô', 'SIAM', 'PARAGON'
        ]
        
        for word in important_words:
            if word in s:
                keywords.add(word)
        
        # ‡∏•‡∏ö prefix/suffix ‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢
        prefixes = ['PTC-MRT-', 'FC PTF ', 'PTC-', 'PTC ', 'PUN-', 'PTF ', 
                   'MAXMART', 'CW', 'FC', 'NW', 'MI', 'PI']
        for prefix in prefixes:
            if s.startswith(prefix):
                s = s[len(prefix):].strip()
                break
        
        # ‡∏•‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ï‡πâ‡∏ô (M, P, N) ‡∏ñ‡πâ‡∏≤‡∏ï‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        import re
        if re.match(r'^[MPN]\d', s):
            s = s[1:]
        
        # ‡πÅ‡∏¢‡∏Å‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
        thai_chars = ''.join([c for c in s if '\u0e01' <= c <= '\u0e5b'])
        eng_chars = ''.join([c for c in s if c.isalpha() and c.isascii()])
        
        return keywords, thai_chars, eng_chars
    
        # fallback: ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤ ‡πÉ‡∏´‡πâ‡πÄ‡∏î‡∏≤‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏´‡∏•‡∏±‡∏á + ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏£‡∏´‡∏±‡∏™/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        parts = address.split()
        # ‡∏Ç‡πâ‡∏≤‡∏°‡∏£‡∏´‡∏±‡∏™ plus code ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        idx = 0
        if parts and ('+' in parts[0] or re.match(r'^[A-Z0-9]{4,}', parts[0])):
            idx = 1
        # ‡∏´‡∏≤‡∏ï‡∏≥‡∏ö‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏£‡∏´‡∏±‡∏™/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î/‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
        for i in range(idx, len(parts)):
            if not re.match(r'^(‡∏≠‡∏≥‡πÄ‡∏†‡∏≠|‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î|\d{5}|[A-Z0-9]{4,}|‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢)$', parts[i]):
                tambon = parts[i]
                break
    keywords1, thai1, eng1 = extract_keywords(name1) if 'name1' in locals() else (set(), '', '')
    keywords2, thai2, eng2 = extract_keywords(name2) if 'name2' in locals() else (set(), '', '')

    # üî• ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡πà‡∏≠‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£‡πå+‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï)
    if keywords1 and keywords2:
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô >= 2 ‡∏Ñ‡∏≥ ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
        common_keywords = keywords1 & keywords2
        if len(common_keywords) >= 2:
            return True
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ô 1 ‡∏Ñ‡∏≥ ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
        if len(common_keywords) >= 1:
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏â‡∏û‡∏≤‡∏∞
            specific_places = {'‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï', 'RANGSIT', '‡πÄ‡∏ã‡πá‡∏ô‡∏ó‡∏£‡∏±‡∏•', 'CENTRAL', '‡∏ã‡∏µ‡∏Ñ‡∏≠‡∏ô', 'SEACON'}
            if common_keywords & specific_places:
                # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏µ‡∏Å 1 ‡∏Ñ‡∏≥ ‡∏´‡∏£‡∏∑‡∏≠ ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
                if len(common_keywords) >= 2 or (thai1 and thai2 and len(thai1) >= 4 and thai1[:4] in thai2):
                    return True

    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£
    if len(thai1) < 3 and len(eng1) < 3:
        return False
    if len(thai2) < 3 and len(eng2) < 3:
        return False

    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    if thai1 and thai2:
        shorter_thai = min(thai1, thai2, key=len)
        longer_thai = max(thai1, thai2, key=len)
        if len(shorter_thai) >= 3 and shorter_thai in longer_thai:
            return True
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ 80%+
        if len(shorter_thai) >= 5:
            common = sum(1 for c in shorter_thai if c in longer_thai)
            if common / len(shorter_thai) >= 0.8:
                return True

    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
    if eng1 and eng2:
        shorter_eng = min(eng1, eng2, key=len)
        longer_eng = max(eng1, eng2, key=len)
        if len(shorter_eng) >= 3 and shorter_eng in longer_eng:
            return True
        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ 80%+
        if len(shorter_eng) >= 5:
            common = sum(1 for c in shorter_eng if c in longer_eng)
            if common / len(shorter_eng) >= 0.8:
                return True

    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (‡πÄ‡∏ä‡πà‡∏ô Future = ‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£‡πå, Rangsit = ‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï)
    thai_eng_map = {
        'RANGSIT': '‡∏£‡∏±‡∏á‡∏™‡∏¥‡∏ï',
        'FUTURE': '‡∏ü‡∏¥‡∏ß‡πÄ‡∏à‡∏≠‡∏£',
        'PARK': '‡∏õ‡∏≤‡∏£‡∏Ñ',
        'TRIANGLE': '‡πÑ‡∏ï‡∏£‡πÅ‡∏≠‡∏á‡πÄ‡∏Å‡∏¥‡∏•',
    }

    for eng_word, thai_word in thai_eng_map.items():
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏ù‡∏±‡πà‡∏á (‡πÑ‡∏ó‡∏¢-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏´‡∏£‡∏∑‡∏≠ ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡∏´‡∏£‡∏∑‡∏≠ ‡πÑ‡∏ó‡∏¢-‡πÑ‡∏ó‡∏¢)
        has_eng_in_1 = eng_word in eng1
        has_eng_in_2 = eng_word in eng2
        has_thai_in_1 = thai_word in thai1
        has_thai_in_2 = thai_word in thai2
        # ‡∏ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÑ‡∏ó‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©) = ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô
        if (has_eng_in_1 and has_eng_in_2) or (has_thai_in_1 and has_thai_in_2):
            return True
        # ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≤‡∏°‡∏†‡∏≤‡∏©‡∏≤ (‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©-‡πÑ‡∏ó‡∏¢)
        if (has_eng_in_1 and has_thai_in_2) or (has_eng_in_2 and has_thai_in_1):
            return True
    
    return False

def haversine_distance(lat1, lon1, lat2, lon2):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡πÇ‡∏•‡∏Å (km)
    ‡πÉ‡∏ä‡πâ‡∏™‡∏π‡∏ï‡∏£ Haversine
    """
    from math import radians, sin, cos, sqrt, atan2
    
    # ‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏á‡∏®‡∏≤‡πÄ‡∏õ‡πá‡∏ô radians
    lat1_rad = radians(lat1)
    lon1_rad = radians(lon1)
    lat2_rad = radians(lat2)
    lon2_rad = radians(lon2)
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î
    dlat = lat2_rad - lat1_rad
    dlon = lon2_rad - lon1_rad
    
    # ‡∏™‡∏π‡∏ï‡∏£ Haversine
    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1-a))
    
    # ‡∏£‡∏±‡∏®‡∏°‡∏µ‡πÇ‡∏•‡∏Å (km)
    R = 6371.0
    distance = R * c
    
    return distance

def get_region_type(province):
    """
    ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
    
    Returns:
        str: 'nearby' (‡πÉ‡∏Å‡∏•‡πâ - ‡πÉ‡∏ä‡πâ 4W/JB), 'far' (‡πÑ‡∏Å‡∏• - ‡πÉ‡∏ä‡πâ 6W), 
             'very_far' (‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å - ‡∏ï‡πâ‡∏≠‡∏á 6W ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô), 'unknown'
    """
    if pd.isna(province):
        return 'unknown'
    
    prov = str(province).strip()
    
    # üöõ ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å‡πÜ (‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô + ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏•‡∏∂‡∏Å) ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ 6W ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    very_far_provinces = [
        # ‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô (‡πÑ‡∏Å‡∏•‡∏à‡∏≤‡∏Å DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ~500-700 ‡∏Å‡∏°.)
        '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô', '‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤',
        # ‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ‡∏•‡∏∂‡∏Å (‡πÑ‡∏Å‡∏•‡∏à‡∏≤‡∏Å DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ~700-1000 ‡∏Å‡∏°.)
        '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏ï‡∏£‡∏±‡∏á', '‡∏™‡∏ï‡∏π‡∏•'
    ]
    
    for very_far in very_far_provinces:
        if very_far in prov:
            return 'very_far'
    
    # ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û + ‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏• + ‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á = ‡πÉ‡∏Å‡∏•‡πâ ‚Üí ‡πÉ‡∏ä‡πâ 4W/JB
    nearby_provinces = [
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û',
        '‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£',
        '‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤',
        '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å'
    ]
    
    for nearby in nearby_provinces:
        if nearby in prov:
            return 'nearby'
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏∑‡πà‡∏ô‡πÜ = ‡πÑ‡∏Å‡∏• ‚Üí ‡πÉ‡∏ä‡πâ 6W
    return 'far'

def is_nearby_province(prov1, prov2):
    """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)"""
    if pd.isna(prov1) or pd.isna(prov2):
        return False
    
    if prov1 == prov2:
        return True
    
    # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ‡∏¢‡πà‡∏≠‡∏¢ (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
    province_groups = {
        '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û'],
        '‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•': ['‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£'],
        '‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤'],
        '‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ'],
        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': ['‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå', '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ'],
        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': ['‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ï‡∏£‡∏≤‡∏î', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß', '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': ['‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°', '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨', '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£', '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£', '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π', '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏•‡∏¢'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå', '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô', '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥', '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°', '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î'],
        '‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÉ‡∏ï‡πâ': ['‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä', '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå', '‡∏¢‡πÇ‡∏™‡∏ò‡∏£', '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©', '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå', '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç', '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ'],
        '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤', '‡∏•‡∏≥‡∏õ‡∏≤‡∏á', '‡∏•‡∏≥‡∏û‡∏π‡∏ô', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÅ‡∏û‡∏£‡πà', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô'],
        '‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£', '‡∏ï‡∏≤‡∏Å', '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå', '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£', '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å', '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢', '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå', '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå'],
        '‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏î‡∏≤‡∏°‡∏±‡∏ô': ['‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏ï‡∏£‡∏±‡∏á', '‡∏û‡∏±‡∏á‡∏á‡∏≤', '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏£‡∏∞‡∏ô‡∏≠‡∏á', '‡∏™‡∏ï‡∏π‡∏•'],
        '‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡πà‡∏≤‡∏ß‡πÑ‡∏ó‡∏¢': ['‡∏ä‡∏∏‡∏°‡∏û‡∏£', '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™']
    }
    
    # ‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á 2 ‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    for group, provinces in province_groups.items():
        in_group_1 = any(p in str(prov1) for p in provinces)
        in_group_2 = any(p in str(prov2) for p in provinces)
        
        if in_group_1 and in_group_2:
            return True
    
    return False

def load_model():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡πÑ‡∏ß‡πâ"""
    if not os.path.exists(MODEL_PATH):
        return None
    
    try:
        with open(MODEL_PATH, 'rb') as f:
            model_data = pickle.load(f)
        return model_data
    except Exception as e:
        st.error(f"‚ùå Error loading model: {e}")
        return None

def create_pair_features(code1, code2, branch_info):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏™‡∏≤‡∏Ç‡∏≤"""
    import math
    
    info1 = branch_info[code1]
    info2 = branch_info[code2]
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÅ‡∏•‡∏∞‡∏Ñ‡∏¥‡∏ß
    weight_diff = abs(info1['avg_weight'] - info2['avg_weight'])
    cube_diff = abs(info1['avg_cube'] - info2['avg_cube'])
    weight_sum = info1['avg_weight'] + info2['avg_weight']
    cube_sum = info1['avg_cube'] + info2['avg_cube']
    
    # ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    same_province = 1 if info1['province'] == info2['province'] else 0
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î
    distance_km = 0.0
    if info1['latitude'] != 0 and info2['latitude'] != 0:
        lat1, lon1 = math.radians(info1['latitude']), math.radians(info1['longitude'])
        lat2, lon2 = math.radians(info2['latitude']), math.radians(info2['longitude'])
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2
        c = 2 * math.asin(math.sqrt(a))
        distance_km = 6371 * c
    
    # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà
    freq_product = info1['total_trips'] * info2['total_trips']
    freq_diff = abs(info1['total_trips'] - info2['total_trips'])
    
    # Ratio
    weight_ratio = (info1['avg_weight'] / info2['avg_weight']) if info2['avg_weight'] > 0 else 0
    cube_ratio = (info1['avg_cube'] / info2['avg_cube']) if info2['avg_cube'] > 0 else 0
    
    # ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ
    over_4w = 1 if (weight_sum > 2500 or cube_sum > 5.0) else 0
    over_jb = 1 if (weight_sum > 3500 or cube_sum > 8.0) else 0
    over_6w = 1 if (weight_sum > 5800 or cube_sum > 22.0) else 0
    
    return {
        'weight_sum': weight_sum,
        'cube_sum': cube_sum,
        'weight_diff': weight_diff,
        'cube_diff': cube_diff,
        'same_province': same_province,
        'distance_km': distance_km,
        'avg_weight_1': info1['avg_weight'],
        'avg_weight_2': info2['avg_weight'],
        'avg_cube_1': info1['avg_cube'],
        'avg_cube_2': info2['avg_cube'],
        'freq_product': freq_product,
        'freq_diff': freq_diff,
        'weight_ratio': weight_ratio,
        'cube_ratio': cube_ratio,
        'over_4w': over_4w,
        'over_jb': over_jb,
        'over_6w': over_6w
    }

def load_excel(file_content, sheet_name=None):
    """‡πÇ‡∏´‡∏•‡∏î Excel"""
    try:
        xls = pd.ExcelFile(io.BytesIO(file_content))
        
        target_sheet = None
        if sheet_name and sheet_name in xls.sheet_names:
            target_sheet = sheet_name
        else:
            for s in xls.sheet_names:
                if 'punthai' in s.lower() or '2.' in s.lower():
                    target_sheet = s
                    break
        
        if not target_sheet:
            target_sheet = xls.sheet_names[0]
        
        # ‡∏´‡∏≤ header row
        df_temp = pd.read_excel(xls, sheet_name=target_sheet, header=None)
        header_row = 0
        
        for i in range(min(10, len(df_temp))):
            row_values = df_temp.iloc[i].astype(str).str.upper()
            match_count = sum([
                'BRANCH' in ' '.join(row_values),
                'TRIP' in ' '.join(row_values),
                '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in ' '.join(df_temp.iloc[i].astype(str))
            ])
            if match_count >= 2:
                header_row = i
                break
        
        df = pd.read_excel(xls, sheet_name=target_sheet, header=header_row)
        df = df.loc[:, ~df.columns.duplicated()]
        
        return df
    except Exception as e:
        st.error(f"‚ùå Error: {e}")
        return None

def process_dataframe(df):
    """‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets"""
    if df is None or df.empty:
        return None
    
    rename_map = {}
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Google Sheets)
    for col in df.columns:
        col_clean = str(col).strip()
        col_upper = col_clean.upper().replace(' ', '').replace('_', '')
        
        # ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤
        if any(keyword in col_clean.lower() for keyword in ['plan code', 'branch code', '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏£‡∏´‡∏±‡∏™ wms', 'code']):
            if 'Code' not in rename_map.values():  # ‡πÄ‡∏≠‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
                rename_map[col] = 'Code'
        
        # ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
        elif any(keyword in col_clean.lower() for keyword in ['branch name', '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏™‡∏≤‡∏Ç‡∏≤', 'branch']) and 'code' not in col_clean.lower():
            if 'Name' not in rename_map.values():
                rename_map[col] = 'Name'
        
        # ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
        elif any(keyword in col_upper for keyword in ['TOTALWGT', 'WEIGHT', 'WGT']) or '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å' in col_clean:
            if 'Weight' not in rename_map.values():
                rename_map[col] = 'Weight'
        
        # ‡∏Ñ‡∏¥‡∏ß/‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ï‡∏£
        elif any(keyword in col_upper for keyword in ['TOTALCUBE', 'CUBE', 'VOLUME']) or '‡∏Ñ‡∏¥‡∏ß' in col_clean or '‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ï‡∏£' in col_clean:
            if 'Cube' not in rename_map.values():
                rename_map[col] = 'Cube'
        
        # ‡∏û‡∏¥‡∏Å‡∏±‡∏î
        elif 'latitude' in col_clean.lower() or col_clean == '‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î' or col_upper == 'LAT':
            rename_map[col] = 'Latitude'
        elif 'longitude' in col_clean.lower() or '‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î' in col_clean or '‡∏•‡∏≠‡∏á‡∏à‡∏¥‡∏à‡∏π‡∏î' in col_clean or col_upper in ['LON', 'LONG', 'LNG']:
            rename_map[col] = 'Longitude'
        
        # ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà
        elif '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î' in col_clean or 'province' in col_clean.lower():
            if 'Province' not in rename_map.values():
                rename_map[col] = 'Province'
        elif '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠' in col_clean or 'district' in col_clean.lower() and 'sub' not in col_clean.lower():
            if 'District' not in rename_map.values():
                rename_map[col] = 'District'
        elif '‡∏ï‡∏≥‡∏ö‡∏•' in col_clean or 'subdistrict' in col_clean.lower() or 'sub district' in col_clean.lower():
            if 'Subdistrict' not in rename_map.values():
                rename_map[col] = 'Subdistrict'
        
        # ‡∏ó‡∏£‡∏¥‡∏õ
        elif col_upper in ['TRIPNO', 'TRIP_NO'] or col_clean == 'Trip no':
            rename_map[col] = 'TripNo'
        elif col_upper == 'TRIP' or '‡∏ó‡∏£‡∏¥‡∏õ' in col_clean or '‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß' in col_clean:
            rename_map[col] = 'Trip'
        elif 'BOOKING' in col_upper:
            rename_map[col] = 'Booking'
    
    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏•‡∏≥‡∏î‡∏±‡∏ö (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå Auto Plan)
    if 'Code' not in rename_map.values() and len(df.columns) >= 8:
        col_list = list(df.columns)
        if len(col_list) > 2 and col_list[2] not in rename_map:
            rename_map[col_list[2]] = 'Code'
        if len(col_list) > 4 and col_list[4] not in rename_map:
            rename_map[col_list[4]] = 'Name'
        if len(col_list) > 5 and col_list[5] not in rename_map:
            rename_map[col_list[5]] = 'Cube'
        if len(col_list) > 6 and col_list[6] not in rename_map:
            rename_map[col_list[6]] = 'Weight'
    
    # ‡πÉ‡∏ä‡πâ mapping
    df = df.rename(columns=rename_map)
    
    # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥
    df = df.loc[:, ~df.columns.duplicated()]
    
    # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Code
    if 'Code' in df.columns:
        df['Code'] = df['Code'].apply(normalize)
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏Å
        df = df[~df['Code'].isin(EXCLUDE_BRANCHES)]
        
        # ‡∏ï‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏µ keyword ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        if 'Name' in df.columns:
            exclude_pattern = '|'.join(EXCLUDE_NAMES)
            df = df[~df['Name'].str.contains(exclude_pattern, case=False, na=False)]
    
    # ‡πÅ‡∏õ‡∏•‡∏á Weight ‡πÅ‡∏•‡∏∞ Cube ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    for col in ['Weight', 'Cube']:
        if col not in df.columns:
            df[col] = 0.0
        else:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0.0)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å Master ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
    if 'Province' not in df.columns or df['Province'].isna().all():
        if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns and 'Code' in df.columns:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏à‡∏≤‡∏Å Master
            province_map = {}
            for _, row in MASTER_DATA.iterrows():
                code = row.get('Plan Code', '')
                province = row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '')
                if code and province:
                    province_map[code] = province
            
            # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
            def find_province_by_name(code, name):
                # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏à‡∏≤‡∏Å code ‡∏Å‡πà‡∏≠‡∏ô
                if code in province_map:
                    return province_map[code]
                
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤
                if not name or pd.isna(name):
                    return None
                
                # ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ (‡πÄ‡∏≠‡∏≤‡∏Ñ‡∏≥‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà prefix)
                keywords = str(name).replace('MAX MART-', '').replace('PUNTHAI-', '').replace('LUBE', '').strip()
                if not keywords:
                    return None
                
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤‡∏Ç‡∏≠‡∏á Master
                for _, master_row in MASTER_DATA.iterrows():
                    master_name = str(master_row.get('‡∏™‡∏≤‡∏Ç‡∏≤', ''))
                    # ‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô (‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô)
                    if keywords[:10] in master_name or master_name[:10] in keywords:
                        province = master_row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '')
                        if province:
                            return province
                
                return None
            
            # ‡πÉ‡∏™‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
            if 'Name' in df.columns:
                df['Province'] = df.apply(lambda row: find_province_by_name(row['Code'], row.get('Name', '')), axis=1)
            else:
                df['Province'] = df['Code'].map(province_map)
    
    return df.reset_index(drop=True)

# ============================================================================
# üéØ MAIN APPLICATION
# ============================================================================

def main():
    st.set_page_config(
        page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß",
        page_icon="üöö",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # üîÑ Sync ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ß‡πá‡∏ö (‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á error ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ)
    try:
        synced_df = sync_branch_data_from_sheets()
        if synced_df is not None and not synced_df.empty:
            st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(synced_df)} ‡∏™‡∏≤‡∏Ç‡∏≤", icon="üìä")
    except Exception as e:
        # ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á error ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ credentials
        pass
    
    # ==========================================
    # Step 6: DISTRICT CLUSTERING ALLOCATION (OPTIMIZED)
    # üî• ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ‡∏Å‡πà‡∏≠‡∏ô (4W ‚Üí JB ‚Üí 6W)
    # ==========================================
    trip_counter = 1
    df['Trip'] = 0
    
    # üöÄ CACHE: Pre-compute branch constraints ‡πÅ‡∏•‡∏∞ BU type
    branch_max_vehicle_cache = {}
    branch_bu_cache = {}
    branch_priority_cache = {}  # ‡πÄ‡∏û‡∏¥‡πà‡∏°: cache ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö priority ‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ
    vehicle_priority = {'4W': 1, 'JB': 2, '6W': 3}
    
    for _, row in df.iterrows():
        code = row['Code']
        max_vehicle = row.get('_max_vehicle', '6W')
        branch_max_vehicle_cache[code] = max_vehicle
        bu = str(row.get('BU', '')).upper()
        branch_bu_cache[code] = bu in ['211', 'PUNTHAI']
        # ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏£‡∏ñ (4W, JB) ‡∏à‡∏∞‡∏°‡∏µ priority ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤
        branch_priority_cache[code] = vehicle_priority.get(max_vehicle, 3)
    
    # üöÄ Pre-compute limits with buffer (CACHED VERSION)
    limits_cache = {}  # Cache: (max_vehicle, is_punthai) -> limits
    
    def get_max_limits(allowed_vehicles, is_punthai):
        """‡∏´‡∏≤ capacity ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ (with caching)"""
        buffer_mult = punthai_buffer if is_punthai else maxmart_buffer
        max_vehicle = '6W' if '6W' in allowed_vehicles else ('JB' if 'JB' in allowed_vehicles else '4W')
        
        # Check cache first
        cache_key = (max_vehicle, is_punthai)
        if cache_key in limits_cache:
            return limits_cache[cache_key]
        
        limits_to_use = PUNTHAI_LIMITS if is_punthai else LIMITS
        lim = limits_to_use.get(max_vehicle, LIMITS['6W'])
        result = {
            'max_w': lim.get('max_w', 6000) * buffer_mult,
            'max_c': lim.get('max_c', 20.0) * buffer_mult,
            'max_d': lim.get('max_drops', 12)
        }
        
        # Store in cache
        limits_cache[cache_key] = result
        return result
    
    # Helper function: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (Optimized - v2)
    def select_vehicle_for_load(weight, cube, drops, is_punthai, allowed_vehicles, global_limiting_factor):
        """
        ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ (‡∏ï‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô Buffer)
        üî• ‡πÉ‡∏ä‡πâ global_limiting_factor ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö
        üöÄ Optimized: ‡πÉ‡∏ä‡πâ cache ‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
        
        Parameters:
            global_limiting_factor: 'weight' ‡∏´‡∏£‡∏∑‡∏≠ 'cube' ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        
        Returns: (vehicle, limiting_factor)
            vehicle: ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏£‡∏ñ ('4W', 'JB', '6W')
            limiting_factor: ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö global_limiting_factor ‡πÄ‡∏™‡∏°‡∏≠
        """
        buffer_mult = punthai_buffer if is_punthai else maxmart_buffer
        limits_to_use = PUNTHAI_LIMITS if is_punthai else LIMITS
        
        # Pre-compute limits for all vehicles (‡∏ó‡∏≥‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
        for v in ['4W', 'JB', '6W']:
            if v not in allowed_vehicles:
                continue
            lim = limits_to_use[v]
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏ó‡∏±‡πâ‡∏á 3 ‡∏°‡∏¥‡∏ï‡∏¥ (inline calculation)
            if (weight <= lim['max_w'] * buffer_mult and 
                cube <= lim['max_c'] * buffer_mult and 
                drops <= lim.get('max_drops', 12)):
                # üéØ ‡πÉ‡∏ä‡πâ global_limiting_factor ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß
                return v, global_limiting_factor
        
        return None, None
    
    # üî• NEW: Helper function - ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    def meets_minimum_standard(weight, cube, drops, allowed_vehicles, limiting_factor=None):
        """
        ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏°‡∏µ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å/‡∏Ñ‡∏¥‡∏ß‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        üî• ‡∏ñ‡πâ‡∏≤‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å ‚Üí ‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
        üî• ‡∏ñ‡πâ‡∏≤‡∏ï‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏¥‡∏ß ‚Üí ‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏¥‡∏ß
        
        ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô:
        - Weight: ‚â• 70% ‡∏Ç‡∏≠‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î
        - Cube: ‚â• 70% ‡∏Ç‡∏≠‡∏á‡∏Ç‡∏µ‡∏î‡∏à‡∏≥‡∏Å‡∏±‡∏î  
        """
        if not allowed_vehicles:
            return True
        
        # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
        min_vehicle = '4W' if '4W' in allowed_vehicles else ('JB' if 'JB' in allowed_vehicles else '6W')
        lim = LIMITS[min_vehicle]
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ limiting_factor ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÄ‡∏≠‡∏á (‡∏à‡∏≤‡∏Å weight ‡∏Å‡∏±‡∏ö cube)
        if limiting_factor is None:
            weight_pct = (weight / lim['max_w']) * 100 if lim['max_w'] > 0 else 0
            cube_pct = (cube / lim['max_c']) * 100 if lim['max_c'] > 0 else 0
            
            if weight_pct >= cube_pct:
                limiting_factor = 'weight'
            else:
                limiting_factor = 'cube'
        
        # üéØ ‡∏ß‡∏±‡∏î‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ï‡∏≤‡∏° limiting_factor ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô!
        if limiting_factor == 'weight':
            min_weight = lim['max_w'] * 0.70  # ‚â• 70%
            return weight >= min_weight
        elif limiting_factor == 'cube':
            min_cube = lim['max_c'] * 0.70  # ‚â• 70%
            return cube >= min_cube
        
        # Fallback (‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡∏¥‡∏î)
        return True
    
    # Helper function: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Punthai ‡∏•‡πâ‡∏ß‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (Optimized - ‡πÉ‡∏ä‡πâ cache)
    def is_all_punthai_codes(codes):
        if not codes:
            return False
        return all(branch_bu_cache.get(c, False) for c in codes)
    
    # Helper function: ‡∏´‡∏≤ allowed vehicles ‡∏à‡∏≤‡∏Å codes (Optimized)
    def get_allowed_from_codes(codes, base_allowed):
        """‡∏´‡∏≤ allowed vehicles ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° branch constraints"""
        result = set(base_allowed)
        for code in codes:
            branch_max = branch_max_vehicle_cache.get(code, '6W')
            if branch_max == 'JB':
                result.discard('6W')
            elif branch_max == '4W':
                result.discard('6W')
                result.discard('JB')
        return list(result)
    
    # üî• NEW: Helper function - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì centroid ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á
    def calculate_trip_centroid(codes):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î lat/lon"""
        if not codes:
            return None, None
        trip_branches = df[df['Code'].isin(codes)]
        valid_coords = trip_branches[(trip_branches['_lat'] != 0) & (trip_branches['_lon'] != 0)]
        if valid_coords.empty:
            return None, None
        return valid_coords['_lat'].mean(), valid_coords['_lon'].mean()
    
    # üî• NEW: Helper function - ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏£‡∏¥‡∏õ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (+ ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á)
    def is_branch_near_trip(branch_code, trip_codes, max_distance_km=80):
        """
        ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        Args:
            branch_code: ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏ä‡πá‡∏Ñ
            trip_codes: ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            max_distance_km: ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ (‡∏Å‡∏°.)
        Returns:
            True ‡∏ñ‡πâ‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏û‡∏≠‡πÅ‡∏•‡∏∞‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°, False ‡∏ñ‡πâ‡∏≤‡πÑ‡∏Å‡∏•‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏°
        """
        if not trip_codes:
            return True  # ‡∏ó‡∏£‡∏¥‡∏õ‡∏ß‡πà‡∏≤‡∏á ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
        
        # ‡∏´‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°
        branch_data = df[df['Code'] == branch_code]
        if branch_data.empty:
            return True
        
        branch_lat = branch_data['_lat'].iloc[0]
        branch_lon = branch_data['_lon'].iloc[0]
        branch_province = branch_data['_province'].iloc[0]
        
        if branch_lat == 0 or branch_lon == 0:
            return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡∏±‡∏î ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì centroid ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ
        trip_lat, trip_lon = calculate_trip_centroid(trip_codes)
        if trip_lat is None or trip_lon is None:
            return True  # ‡∏ó‡∏£‡∏¥‡∏õ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏û‡∏¥‡∏Å‡∏±‡∏î ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô
        
        # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        distance = haversine_distance(trip_lat, trip_lon, branch_lat, branch_lon)
        if distance > max_distance_km:
            return False  # ‡πÑ‡∏Å‡∏•‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
        
        # 2. üî• ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏°)
        # ‡∏´‡∏≤‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ (‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏™‡∏≤‡∏Ç‡∏≤‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
        trip_provinces = df[df['Code'].isin(trip_codes)]['_province'].value_counts()
        if trip_provinces.empty:
            return True
        
        main_province = trip_provinces.index[0]
        
        # ‡∏ñ‡πâ‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å ‚Üí OK
        if branch_province == main_province:
            return True
        
        # ‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‚Üí ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á
        # ‡∏´‡∏≤ centroid ‡∏Ç‡∏≠‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å
        main_prov_branches = df[(df['Code'].isin(trip_codes)) & (df['_province'] == main_province)]
        valid_main = main_prov_branches[(main_prov_branches['_lat'] != 0) & (main_prov_branches['_lon'] != 0)]
        
        if valid_main.empty:
            return True
        
        main_prov_lat = valid_main['_lat'].mean()
        main_prov_lon = valid_main['_lon'].mean()
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
        trip_bearings = []
        for code in trip_codes:
            code_data = df[df['Code'] == code]
            if code_data.empty:
                continue
            code_lat = code_data['_lat'].iloc[0]
            code_lon = code_data['_lon'].iloc[0]
            if code_lat != 0 and code_lon != 0:
                bearing = calculate_bearing(main_prov_lat, main_prov_lon, code_lat, code_lon)
                if bearing is not None:
                    trip_bearings.append(bearing)
        
        if not trip_bearings:
            return True  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô
        
        # ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ
        avg_bearing = sum(trip_bearings) / len(trip_bearings)
        
        # ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏±‡∏Å
        new_bearing = calculate_bearing(main_prov_lat, main_prov_lon, branch_lat, branch_lon)
        if new_bearing is None:
            return True
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if is_opposite_direction(avg_bearing, new_bearing, threshold=100):
            return False  # ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏° ‡πÑ‡∏°‡πà‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏¥‡∏õ
        
        return True  # ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á
    
    # Current trip state
    current_trip = {
        'codes': [], 'weight': 0, 'cube': 0, 'drops': 0,
        'region': None, 'allowed_vehicles': ['4W', 'JB', '6W'],
        'province': None,  # üî• ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        'district': None, 'is_punthai': False,
        'limiting_factor': None  # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£ (weight/cube/drops)
    }
    
    overflow_queue = []  # Queue ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö stores ‡∏ó‡∏µ‡πà overflow
    
    def finalize_current_trip():
        """‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"""
        nonlocal trip_counter
        if current_trip['codes']:
            for c in current_trip['codes']:
                df.loc[df['Code'] == c, 'Trip'] = trip_counter
    
    def split_until_fits(allowed_vehicles, region):
        """‡πÅ‡∏¢‡∏Å stores ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å current_trip ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏û‡∏≠‡∏î‡∏µ‡∏£‡∏ñ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô buffer) - OPTIMIZED"""
        nonlocal trip_counter, overflow_queue
        
        while True:
            # ‡πÉ‡∏ä‡πâ cached is_punthai
            is_punthai = current_trip['is_punthai']
            limits = get_max_limits(current_trip['allowed_vehicles'], is_punthai)
            
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if (current_trip['weight'] <= limits['max_w'] and 
                current_trip['cube'] <= limits['max_c'] and 
                current_trip['drops'] <= limits['max_d']):
                break
            
            if len(current_trip['codes']) <= 1:
                break
            
            # ‡∏ï‡∏±‡∏î store ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏≠‡∏≠‡∏Å
            overflow_code = current_trip['codes'].pop()
            overflow_weight = df.loc[df['Code'] == overflow_code, 'Weight'].iloc[0]
            overflow_cube = df.loc[df['Code'] == overflow_code, 'Cube'].iloc[0]
            current_trip['weight'] -= overflow_weight
            current_trip['cube'] -= overflow_cube
            current_trip['drops'] -= 1
            
            # Update is_punthai ‡πÅ‡∏•‡∏∞ allowed_vehicles
            current_trip['is_punthai'] = is_all_punthai_codes(current_trip['codes'])
            current_trip['allowed_vehicles'] = get_allowed_from_codes(current_trip['codes'], allowed_vehicles)
            
            overflow_queue.append({
                'code': overflow_code,
                'weight': overflow_weight,
                'cube': overflow_cube,
                'region': region,
                'allowed_vehicles': allowed_vehicles
            })
    
    def process_overflow_queue():
        """‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• overflow queue - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö stores ‡∏ó‡∏µ‡πà‡∏•‡πâ‡∏ô - OPTIMIZED v2"""
        nonlocal trip_counter, current_trip, overflow_queue
        
        while overflow_queue:
            item = overflow_queue.pop(0)
            code = item['code']
            weight = item['weight']
            cube = item['cube']
            region = item['region']
            allowed_vehicles = item['allowed_vehicles']
            
            # üöÄ Skip if already assigned (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô double assignment)
            if df.loc[df['Code'] == code, 'Trip'].iloc[0] != 0:
                continue
            
            # ‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤ current_trip
            if current_trip['codes']:
                test_codes = current_trip['codes'] + [code]
                test_weight = current_trip['weight'] + weight
                test_cube = current_trip['cube'] + cube
                test_drops = current_trip['drops'] + 1
                test_punthai = is_all_punthai_codes(test_codes)
                test_allowed = get_allowed_from_codes(test_codes, allowed_vehicles)
                
                vehicle, limiting_factor = select_vehicle_for_load(test_weight, test_cube, test_drops, test_punthai, test_allowed, GLOBAL_LIMITING_FACTOR)
                
                if vehicle:
                    # ‡∏û‡∏≠‡∏î‡∏µ! ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤
                    current_trip['codes'].append(code)
                    current_trip['weight'] = test_weight
                    current_trip['cube'] = test_cube
                    current_trip['drops'] = test_drops
                    current_trip['is_punthai'] = test_punthai
                    current_trip['allowed_vehicles'] = test_allowed
                    current_trip['limiting_factor'] = limiting_factor  # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£
                    
                    # Double check
                    split_until_fits(allowed_vehicles, region)
                else:
                    # ‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏î‡∏µ ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏Å‡πà‡∏≤, ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà
                    finalize_current_trip()
                    trip_counter += 1
                    new_allowed = get_allowed_from_codes([code], allowed_vehicles)
                    current_trip = {
                        'codes': [code],
                        'weight': weight,
                        'cube': cube,
                        'drops': 1,
                        'region': region,
                        'allowed_vehicles': new_allowed,
                        'district': None,
                        'is_punthai': branch_bu_cache.get(code, False)
                    }
            else:
                # ‡∏ó‡∏£‡∏¥‡∏õ‡∏ß‡πà‡∏≤‡∏á
                new_allowed = get_allowed_from_codes([code], allowed_vehicles)
                current_trip = {
                    'codes': [code],
                    'weight': weight,
                    'cube': cube,
                    'drops': 1,
                    'region': region,
                    'allowed_vehicles': new_allowed,
                    'district': None,
                    'is_punthai': branch_bu_cache.get(code, False)
                }
    
    # ==========================================
    # GROUP BY DISTRICT BUCKETS - OPTIMIZED WITH PROXIMITY GROUPING
    # üî• ‡πÉ‡∏ä‡πâ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á (lat/lon) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏¥‡∏õ
    # ==========================================
    # Pre-group data for faster iteration
    district_groups = df.groupby(['_region_name', '_province', '_district'], sort=False)
    
    # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    prev_province = None
    
    for (region, province, district), district_df in district_groups:
        # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• District (vectorized - no dict conversion)
        district_codes = district_df['Code'].tolist()
        district_weight = district_df['Weight'].sum()
        district_cube = district_df['Cube'].sum()
        district_drops = len(district_codes)
        
        # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
        allowed_vehicles = ['4W', 'JB', '6W']
        if region in CENTRAL_REGIONS:
            allowed_vehicles = CENTRAL_ALLOWED_VEHICLES.copy()
        
        # ==========================================
        # üî• Rule 0 (UPDATED): Province-Complete Mode - ‡∏à‡∏±‡∏î‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô
        # ‡πÑ‡∏°‡πà‡πÅ‡∏¢‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏±‡∏ô - ‡∏ï‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        # ==========================================
        should_close_trip = False
        
        if current_trip['region'] and current_trip['region'] != region:
            # 1. ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏Ñ ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô
            should_close_trip = True
        elif prev_province and prev_province != province:
            # 2. üî• ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡πÑ‡∏°‡πà‡∏ú‡∏™‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)
            should_close_trip = True
        
        if should_close_trip:
            process_overflow_queue()
            
            # üî• ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ (‡πÉ‡∏ä‡πâ limiting_factor ‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á)
            if current_trip['codes']:
                if not meets_minimum_standard(current_trip['weight'], current_trip['cube'], 
                                              current_trip['drops'], current_trip['allowed_vehicles'],
                                              current_trip['limiting_factor']):
                    # ‡∏ó‡∏£‡∏¥‡∏õ‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ - ‡∏•‡∏≠‡∏á‡∏£‡∏ß‡∏°‡∏ï‡πà‡∏≠‡∏Å‡πà‡∏≠‡∏ô (‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏Ñ)
                    if current_trip['region'] == region:
                        should_close_trip = False
            
            if should_close_trip:
                finalize_current_trip()
                trip_counter += 1
                current_trip = {
                    'codes': [], 'weight': 0, 'cube': 0, 'drops': 0,
                    'region': None, 'allowed_vehicles': allowed_vehicles,
                    'district': None, 'province': None,
                    'is_punthai': False, 'limiting_factor': None
                }
        
        # ==========================================
        # Rule 1: ‡∏•‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏ó‡∏±‡πâ‡∏á District - OPTIMIZED WITH PROXIMITY CHECK
        # üî• ‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏¥‡∏õ
        # ==========================================
        if current_trip['codes']:
            # üî• ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏ô‡∏µ‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏ó‡∏£‡∏¥‡∏õ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            # ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô
            sample_branch = district_codes[0]
            is_near = is_branch_near_trip(sample_branch, current_trip['codes'], max_distance_km=80)
            
            if not is_near:
                # ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏ô‡∏µ‡πâ‡πÑ‡∏Å‡∏•‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏Å‡πà‡∏≤ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡∏°‡πà
                finalize_current_trip()
                trip_counter += 1
                
                new_allowed = get_allowed_from_codes(district_codes, allowed_vehicles)
                new_punthai = is_all_punthai_codes(district_codes)
                
                current_trip = {
                    'codes': district_codes.copy(),
                    'weight': district_weight,
                    'cube': district_cube,
                    'drops': district_drops,
                    'region': region,
                    'allowed_vehicles': new_allowed,
                    'province': province,
                    'district': district,
                    'is_punthai': new_punthai
                }
                
                split_until_fits(allowed_vehicles, region)
            else:
                # ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏ô‡∏µ‡πâ‡πÉ‡∏Å‡∏•‡πâ‡∏û‡∏≠ ‚Üí ‡∏•‡∏≠‡∏á‡∏£‡∏ß‡∏°‡∏ó‡∏£‡∏¥‡∏õ
                test_codes = current_trip['codes'] + district_codes
                test_weight = current_trip['weight'] + district_weight
                test_cube = current_trip['cube'] + district_cube
                test_drops = current_trip['drops'] + district_drops
                test_punthai = is_all_punthai_codes(test_codes)
                test_allowed = get_allowed_from_codes(test_codes, allowed_vehicles)
                
                vehicle, limiting_factor = select_vehicle_for_load(test_weight, test_cube, test_drops, test_punthai, test_allowed, GLOBAL_LIMITING_FACTOR)
                
                if vehicle:
                    # District ‡∏û‡∏≠‡∏î‡∏µ!
                    current_trip['codes'].extend(district_codes)
                    current_trip['weight'] = test_weight
                    current_trip['cube'] = test_cube
                    current_trip['drops'] = test_drops
                    current_trip['allowed_vehicles'] = test_allowed
                    current_trip['region'] = region
                    current_trip['province'] = province  # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                    current_trip['district'] = district
                    current_trip['is_punthai'] = test_punthai
                    current_trip['limiting_factor'] = limiting_factor  # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£
                    
                    # Double check
                    split_until_fits(test_allowed, region)
                else:
                    # District ‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏î‡∏µ ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏Å‡πà‡∏≤
                    finalize_current_trip()
                    trip_counter += 1
                    
                    new_allowed = get_allowed_from_codes(district_codes, allowed_vehicles)
                    new_punthai = is_all_punthai_codes(district_codes)
                    
                    current_trip = {
                        'codes': district_codes.copy(),
                        'weight': district_weight,
                        'cube': district_cube,
                        'drops': district_drops,
                        'region': region,
                        'allowed_vehicles': new_allowed,
                        'province': province,  # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                        'district': district,
                        'is_punthai': new_punthai
                    }
                    
                    # ==========================================
                    # Rule 2: ‡∏ñ‡πâ‡∏≤ District ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏£‡∏ñ ‚Üí Split ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!
                    # ==========================================
                    split_until_fits(allowed_vehicles, region)
        else:
            # ‡∏ó‡∏£‡∏¥‡∏õ‡∏ß‡πà‡∏≤‡∏á - ‡∏´‡∏≤ allowed_vehicles ‡∏£‡∏ß‡∏° branch constraints (‡πÉ‡∏ä‡πâ cache)
            new_allowed = get_allowed_from_codes(district_codes, allowed_vehicles)
            new_punthai = is_all_punthai_codes(district_codes)
            
            current_trip = {
                'codes': district_codes.copy(),
                'weight': district_weight,
                'cube': district_cube,
                'drops': district_drops,
                'region': region,
                'allowed_vehicles': new_allowed,
                'province': province,  # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                'district': district,
                'is_punthai': new_punthai
            }
            
            # ==========================================
            # Rule 2: ‡∏ñ‡πâ‡∏≤ District ‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏£‡∏ñ ‚Üí Split ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!
            # ==========================================
            split_until_fits(new_allowed, region)
        
        # üî• ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
        prev_province = province
    
    # ==========================================
    # Final: Process remaining overflow ‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏£‡∏≠‡∏ö 1)
    # ==========================================
    process_overflow_queue()
    finalize_current_trip()

    # ==========================================
    # üî• PHASE 2: CLEANUP MODE - ‡∏£‡∏ß‡∏°‡πÄ‡∏®‡∏©‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    # ‡∏£‡∏ß‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏£‡∏¥‡∏õ (Trip = 0)
    # ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏≥‡∏ö‡∏•/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡∏Ç‡πâ‡∏≤‡∏°‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
    # ==========================================
    remaining_df = df[df['Trip'] == 0].copy()
    
    if not remaining_df.empty:
        # Log cleanup phase
        print(f"üîÑ Cleanup Phase: {remaining_df['_province'].nunique()} provinces, {len(remaining_df)} branches remaining")
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ ‚Üí ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á (‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡πÉ‡∏Å‡∏•‡πâ) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô
        remaining_df = remaining_df.sort_values(
            ['_vehicle_priority', '_region_order', '_distance_from_dc'],
            ascending=[True, True, False]
        )
        
        # Reset current trip
        current_trip = {
            'codes': [], 'weight': 0, 'cube': 0, 'drops': 0,
            'region': None, 'allowed_vehicles': ['4W', 'JB', '6W'],
            'province': None, 'district': None, 'is_punthai': False
        }
        
        prev_region = None
        
        for idx, row in remaining_df.iterrows():
            code = row['Code']
            weight = row['Weight']
            cube = row['Cube']
            region = row['_region_name']
            
            # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
            allowed_vehicles = ['4W', 'JB', '6W']
            if region in CENTRAL_REGIONS:
                allowed_vehicles = CENTRAL_ALLOWED_VEHICLES.copy()
            
            # üî• ‡∏ï‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏Ñ (cleanup mode ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ú‡∏™‡∏°‡∏Ç‡πâ‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ)
            if prev_region and prev_region != region:
                finalize_current_trip()
                trip_counter += 1
                current_trip = {
                    'codes': [], 'weight': 0, 'cube': 0, 'drops': 0,
                    'region': None, 'allowed_vehicles': allowed_vehicles,
                    'province': None, 'district': None, 'is_punthai': False
                }
            
            # ‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            if current_trip['codes']:
                test_codes = current_trip['codes'] + [code]
                test_weight = current_trip['weight'] + weight
                test_cube = current_trip['cube'] + cube
                test_drops = current_trip['drops'] + 1
                test_punthai = is_all_punthai_codes(test_codes)
                test_allowed = get_allowed_from_codes(test_codes, allowed_vehicles)
                
                vehicle, limiting_factor = select_vehicle_for_load(test_weight, test_cube, test_drops, test_punthai, test_allowed, GLOBAL_LIMITING_FACTOR)
                
                if vehicle:
                    # ‡∏û‡∏≠‡∏î‡∏µ! ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤
                    current_trip['codes'].append(code)
                    current_trip['weight'] = test_weight
                    current_trip['cube'] = test_cube
                    current_trip['drops'] = test_drops
                    current_trip['region'] = region
                    current_trip['is_punthai'] = test_punthai
                    current_trip['allowed_vehicles'] = test_allowed
                    current_trip['limiting_factor'] = limiting_factor  # üî• ‡πÄ‡∏Å‡πá‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏±‡∏î‡∏î‡πâ‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£
                else:
                    # ‡πÑ‡∏°‡πà‡∏û‡∏≠‡∏î‡∏µ ‚Üí ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏Å‡πà‡∏≤, ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏´‡∏°‡πà
                    finalize_current_trip()
                    trip_counter += 1
                    new_allowed = get_allowed_from_codes([code], allowed_vehicles)
                    current_trip = {
                        'codes': [code],
                        'weight': weight,
                        'cube': cube,
                        'drops': 1,
                        'region': region,
                        'allowed_vehicles': new_allowed,
                        'province': None,
                        'district': None,
                        'is_punthai': branch_bu_cache.get(code, False)
                    }
            else:
                # ‡∏ó‡∏£‡∏¥‡∏õ‡∏ß‡πà‡∏≤‡∏á
                new_allowed = get_allowed_from_codes([code], allowed_vehicles)
                current_trip = {
                    'codes': [code],
                    'weight': weight,
                    'cube': cube,
                    'drops': 1,
                    'region': region,
                    'allowed_vehicles': new_allowed,
                    'province': None,
                    'district': None,
                    'is_punthai': branch_bu_cache.get(code, False)
                }
            
            prev_region = region
        
        # ‡∏õ‡∏¥‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        finalize_current_trip()

    # ==========================================
    # Step 7: ‡∏™‡∏£‡πâ‡∏≤‡∏á Summary + Central Rule + Punthai Drop Limits
    # ==========================================
    summary_data = []
    
    for trip_num in sorted(df['Trip'].unique()):
        if trip_num == 0:
            continue
        
        trip_data = df[df['Trip'] == trip_num]
        total_w = trip_data['Weight'].sum()
        total_c = trip_data['Cube'].sum()
        trip_codes = trip_data['Code'].unique()
        trip_drops = len(trip_codes)
        
        # ‡∏´‡∏≤‡∏†‡∏≤‡∏Ñ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ (‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏Ñ‡πÅ‡∏£‡∏Å)
        trip_region = trip_data['_region_name'].iloc[0] if '_region_name' in trip_data.columns else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
        
        # ‡∏´‡∏≤‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (‡∏£‡∏ß‡∏° Central Rule)
        max_vehicles = [get_max_vehicle_for_branch(c) for c in trip_codes]
        min_max_size = min(vehicle_priority.get(v, 3) for v in max_vehicles)
        max_allowed_vehicle = {1: '4W', 2: 'JB', 3: '6W'}.get(min_max_size, '6W')
        
        # üö´ Central Region Rule: ‡∏´‡πâ‡∏≤‡∏° 6W
        if trip_region in CENTRAL_REGIONS and max_allowed_vehicle == '6W':
            max_allowed_vehicle = 'JB'  # ‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô JB
        
        # ‡∏ï‡∏£‡∏ß‡∏à BU ‡∏Ç‡∏≠‡∏á‡∏ó‡∏£‡∏¥‡∏õ
        is_punthai_only_trip = True
        for _, r in trip_data.iterrows():
            bu = str(r.get('BU', '')).upper()
            if bu not in ['211', 'PUNTHAI']:
                is_punthai_only_trip = False
                break
        
        buffer = punthai_buffer if is_punthai_only_trip else maxmart_buffer
        buffer_pct = int(buffer * 100)
        buffer_label = f"üÖøÔ∏è {buffer_pct}%" if is_punthai_only_trip else f"üÖº {buffer_pct}%"
        trip_type = 'punthai' if is_punthai_only_trip else 'maxmart'
        
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏û‡∏≠‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        suggested = max_allowed_vehicle
        source = "üìã ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏™‡∏≤‡∏Ç‡∏≤" if min_max_size < 3 else "ü§ñ ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥"
        
        # üîí Punthai Drop Limit Check
        if is_punthai_only_trip:
            punthai_drop_limit = PUNTHAI_LIMITS.get(suggested, {}).get('max_drops', 999)
            if trip_drops > punthai_drop_limit:
                # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö drops
                if suggested == '4W' and trip_drops <= PUNTHAI_LIMITS['JB']['max_drops']:
                    suggested = 'JB'
                    source += " ‚Üí JB (Drop Limit)"
                elif suggested == 'JB' or trip_drops > PUNTHAI_LIMITS['JB']['max_drops']:
                    # ‡∏ñ‡πâ‡∏≤ Central ‡∏´‡πâ‡∏≤‡∏° 6W ‚Üí WARNING
                    if trip_region not in CENTRAL_REGIONS:
                        suggested = '6W'
                        source += " ‚Üí 6W (Drop Limit)"
                    else:
                        source += " ‚ö†Ô∏è Drops ‡πÄ‡∏Å‡∏¥‡∏ô!"
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì utilization
        max_util_threshold = buffer * 100  # 100% ‡∏´‡∏£‡∏∑‡∏≠ 110% ‡∏ï‡∏≤‡∏° BU
        if suggested in LIMITS:
            w_util = (total_w / LIMITS[suggested]['max_w']) * 100
            c_util = (total_c / LIMITS[suggested]['max_c']) * 100
            max_util = max(w_util, c_util)
            
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô threshold ‡∏ï‡∏≤‡∏° BU ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏£‡∏ñ
            if max_util > max_util_threshold:
                if suggested == '4W' and min_max_size >= 2:
                    jb_util = max((total_w / LIMITS['JB']['max_w']), (total_c / LIMITS['JB']['max_c'])) * 100
                    if jb_util <= max_util_threshold:
                        suggested = 'JB'
                        source += " ‚Üí JB"
                        w_util = (total_w / LIMITS['JB']['max_w']) * 100
                        c_util = (total_c / LIMITS['JB']['max_c']) * 100
                    elif min_max_size >= 3:
                        suggested = '6W'
                        source += " ‚Üí 6W"
                        w_util = (total_w / LIMITS['6W']['max_w']) * 100
                        c_util = (total_c / LIMITS['6W']['max_c']) * 100
                elif suggested == 'JB' and min_max_size >= 3:
                    suggested = '6W'
                    source += " ‚Üí 6W"
                    w_util = (total_w / LIMITS['6W']['max_w']) * 100
                    c_util = (total_c / LIMITS['6W']['max_c']) * 100
        else:
            w_util = c_util = 0
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏£‡∏ß‡∏°
        total_distance = 0
        branch_coords = []
        for code in trip_codes:
            loc = location_map.get(str(code).upper(), {})
            if loc.get('lat') and loc.get('lon'):
                branch_coords.append((loc['lat'], loc['lon']))
        
        if branch_coords:
            # DC ‚Üí ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å
            total_distance += haversine_distance(DC_WANG_NOI_LAT, DC_WANG_NOI_LON, branch_coords[0][0], branch_coords[0][1])
            # ‡∏™‡∏≤‡∏Ç‡∏≤ ‚Üí ‡∏™‡∏≤‡∏Ç‡∏≤
            for i in range(len(branch_coords) - 1):
                total_distance += haversine_distance(branch_coords[i][0], branch_coords[i][1], branch_coords[i+1][0], branch_coords[i+1][1])
            # ‡∏™‡∏≤‡∏Ç‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ ‚Üí DC
            total_distance += haversine_distance(branch_coords[-1][0], branch_coords[-1][1], DC_WANG_NOI_LAT, DC_WANG_NOI_LON)
        
        summary_data.append({
            'Trip': trip_num,
            'Branches': len(trip_codes),
            'Weight': total_w,
            'Cube': total_c,
            'Truck': f"{suggested} {source}",
            'BU_Type': trip_type,
            'Buffer': buffer_label,
            'Weight_Use%': w_util,
            'Cube_Use%': c_util,
            'Total_Distance': round(total_distance, 1)
        })
    
    summary_df = pd.DataFrame(summary_data)
    
    # ==========================================
    # Step 8: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏™‡∏£‡∏¥‡∏°
    # ==========================================
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ñ
    trip_truck_map = {}
    for _, row in summary_df.iterrows():
        trip_truck_map[row['Trip']] = row['Truck']
    df['Truck'] = df['Trip'].map(trip_truck_map)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Region
    df['Region'] = df['_region_name']
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Province (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ)
    if 'Province' not in df.columns:
        df['Province'] = df['_province']
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å DC
    df['Distance_from_DC'] = df['_distance_from_dc'].round(1)
    
    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ä‡πá‡∏Ñ‡∏£‡∏ñ
    df['VehicleCheck'] = '‚úÖ ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ'
    
    # ==========================================
    # Step 9: ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ó‡∏£‡∏¥‡∏õ‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ó‡∏£‡∏¥‡∏õ‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö export)
    
    return df.reset_index(drop=True)

# ============================================================================
# üéØ MAIN APPLICATION
# ============================================================================

def main():
    st.set_page_config(
        page_title="‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß",
        page_icon="üöö",
        layout="wide",
        initial_sidebar_state="collapsed"
    )
    
    # üîÑ Sync ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ß‡πá‡∏ö (‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á error ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ)
    try:
        synced_df = sync_branch_data_from_sheets()
        if synced_df is not None and not synced_df.empty:
            st.success(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(synced_df)} ‡∏™‡∏≤‡∏Ç‡∏≤", icon="üìä")
    except Exception as e:
        # ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á error ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ credentials
        pass
    
    # üîÑ Auto-refresh ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô (‡∏•‡πâ‡∏≤‡∏á‡πÅ‡∏Ñ‡∏ä)
    if AUTOREFRESH_AVAILABLE:
        now = datetime.now()
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ñ‡∏∂‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô (00:00:00)
        midnight = datetime.combine(now.date(), time(0, 0, 0))
        
        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô ‡πÄ‡∏≠‡∏≤‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        if now < midnight:
            next_midnight = midnight
        else:
            from datetime import timedelta
            next_midnight = midnight + timedelta(days=1)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠ (‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ)
        seconds_until_midnight = int((next_midnight - now).total_seconds())
        
        # Refresh ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô
        if seconds_until_midnight > 0:
            # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 5 ‡∏ô‡∏≤‡∏ó‡∏µ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏Ñ‡∏∑‡∏ô (‡∏´‡∏•‡∏±‡∏á 23:55)
            if seconds_until_midnight <= 300:  # 5 minutes
                st.info(f"üîÑ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞ Refresh ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÉ‡∏ô {seconds_until_midnight // 60} ‡∏ô‡∏≤‡∏ó‡∏µ")
                st_autorefresh(interval=seconds_until_midnight * 1000, key="midnight_refresh")
            else:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á
                st_autorefresh(interval=3600000, limit=24, key="hourly_check")
    
    # Header
    col1, col2 = st.columns([3, 1])
    with col2:
        st.markdown("###  ")  # Spacing
        if st.button("üîÑ Refresh"):
            st.rerun()
    
    # Sidebar - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Master Data
    st.sidebar.header("‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤")
    
    with st.sidebar.expander("üìä ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master (‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤)", expanded=False):
        st.markdown("""
        üîÑ **‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Master Data ‡πÉ‡∏´‡∏°‡πà**
        - ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï branch_data.json
        - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: Plan Code, ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î, ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠, ‡∏ï‡∏≥‡∏ö‡∏•, Route, Distance, Lat, Lon
        """)
        
        # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Master
        master_file = st.file_uploader(
            "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î Master Data (Excel)",
            type=["xlsx", "xls"],
            help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î",
            key="master_uploader"
        )
        
        if master_file:
            if st.button("‚¨ÜÔ∏è ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Master Data", type="primary"):
                try:
                    with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
                        # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel
                        df_master = pd.read_excel(master_file)
                        
                        # ‡∏´‡∏≤‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Code
                        code_col = None
                        for col in ['Plan Code', 'Code', '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏™‡∏≤‡∏Ç‡∏≤']:
                            if col in df_master.columns:
                                code_col = col
                                break
                        
                        if code_col is None:
                            st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤ (Plan Code, Code, ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤, ‡∏™‡∏≤‡∏Ç‡∏≤)")
                        else:
                            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON
                            master_dict = {}
                            for _, row in df_master.iterrows():
                                code = str(row[code_col]).strip().upper()
                                if code and code != '':
                                    master_dict[code] = row.to_dict()
                            
                            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON
                            json_file = 'branch_data.json'
                            with open(json_file, 'w', encoding='utf-8') as f:
                                json.dump(master_dict, f, ensure_ascii=False, indent=2)
                            
                            st.success(f"‚úÖ ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Master Data ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: **{len(master_dict):,}** ‡∏™‡∏≤‡∏Ç‡∏≤")
                            st.info("üîÑ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ Refresh ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà")
                            
                except Exception as e:
                    st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        if st.checkbox("üëÅÔ∏è ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"):
            json_file = 'branch_data.json'
            if os.path.exists(json_file):
                with open(json_file, 'r', encoding='utf-8') as f:
                    master_data = json.load(f)
                st.info(f"üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: **{len(master_data):,}** ‡∏™‡∏≤‡∏Ç‡∏≤")
                
                # ‡πÅ‡∏™‡∏î‡∏á sample 5 ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å
                sample_codes = list(master_data.keys())[:5]
                st.markdown("**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 5 ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å:**")
                for code in sample_codes:
                    st.text(f"- {code}")
            else:
                st.warning("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå branch_data.json")
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_data = load_model()
    if not model_data:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ")
        st.stop()
    
    # Show Punthai learning stats
    if PUNTHAI_PATTERNS and 'stats' in PUNTHAI_PATTERNS and PUNTHAI_PATTERNS['stats']:
        stats = PUNTHAI_PATTERNS['stats']
        with st.expander("üìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Punthai Maxmart", expanded=False):
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                st.metric("‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤/‡∏ó‡∏£‡∏¥‡∏õ", f"{stats.get('avg_branches', 0):.1f}")
            with col_b:
                st.metric("‡∏ó‡∏£‡∏¥‡∏õ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß", f"{stats.get('same_province_pct', 0):.1f}%")
            with col_c:
                total_trips = stats.get('same_province', 0) + stats.get('mixed_province', 0)
                st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏£‡∏¥‡∏õ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á", total_trips)
    
    st.markdown("---")
    
    # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model_data = load_model()
    
    if not model_data:
        st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.info("üí° ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á: `python test_model.py`")
        st.stop()
    
    # ==========================================
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Master Data ‡πÅ‡∏•‡∏∞ Sync
    # ==========================================
    st.markdown("### üìä ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master (‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤)")
    
    json_file = 'branch_data.json'
    col_m1, col_m2, col_m3 = st.columns([2, 1, 1])
    
    with col_m1:
        if os.path.exists(json_file):
            # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• JSON ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤
            try:
                file_stat = os.stat(json_file)
                last_modified = datetime.fromtimestamp(file_stat.st_mtime)
                time_diff = datetime.now() - last_modified
                
                with open(json_file, 'r', encoding='utf-8') as f:
                    master_data = json.load(f)
                    master_branch_count = len(master_data)
                    has_dc = '8nvDC011' in master_data
                
                # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
                if time_diff.total_seconds() < 300:  # < 5 ‡∏ô‡∏≤‡∏ó‡∏µ
                    status_icon = "üü¢"
                    status_text = "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"
                elif time_diff.total_seconds() < 3600:  # < 1 ‡∏ä‡∏°.
                    status_icon = "üü°"
                    status_text = "‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà"
                else:
                    status_icon = "üî¥"
                    status_text = "‡∏Ñ‡∏ß‡∏£ Sync ‡πÉ‡∏´‡∏°‡πà"
                
                st.success(f"{status_icon} **{master_branch_count:,} ‡∏™‡∏≤‡∏Ç‡∏≤** (‡∏£‡∏ß‡∏° DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢: {'‚úÖ' if has_dc else '‚ùå'})")
                st.caption(f"üìÖ {status_text}: {last_modified.strftime('%Y-%m-%d %H:%M:%S')}")
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        else:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå branch_data.json - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤ Sync ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Google Sheets")
    
    with col_m2:
        # ‡∏õ‡∏∏‡πà‡∏° Sync ‡∏à‡∏≤‡∏Å Google Sheets
        if st.button("üîÑ Sync ‡∏à‡∏≤‡∏Å Sheets", use_container_width=True, type="primary"):
            if not SHEETS_AVAILABLE or gc is None:
                st.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö credentials.json")
                st.info("üí° ‡∏ß‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå credentials.json ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå app ‡πÅ‡∏•‡πâ‡∏ß Refresh")
            else:
                with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á Sync ‡∏à‡∏≤‡∏Å Google Sheets..."):
                    try:
                        df_synced = sync_branch_data_from_sheets()
                        if df_synced is not None and not df_synced.empty:
                            st.success(f"‚úÖ Sync ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {len(df_synced)} ‡∏™‡∏≤‡∏Ç‡∏≤")
                            st.rerun()
                        else:
                            st.error("‚ùå Sync ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                    except Exception as e:
                        st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
    
    with col_m3:
        # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master
        if st.button("üëÅÔ∏è ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", use_container_width=True):
            if os.path.exists(json_file):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        master_data = json.load(f)
                    
                    st.markdown("---")
                    st.markdown("#### üìã ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master ‡∏™‡∏≤‡∏Ç‡∏≤")
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏£‡∏∏‡∏õ
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", f"{len(master_data):,}")
                    with col2:
                        dc_count = sum(1 for code in master_data.keys() if 'DC' in code.upper())
                        st.metric("DC", f"{dc_count}")
                    with col3:
                        provinces = set()
                        for branch in master_data.values():
                            prov = branch.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', branch.get('Province', ''))
                            if prov:
                                provinces.add(prov)
                        st.metric("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", len(provinces))
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 10 ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å
                    st.markdown("**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á 10 ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏£‡∏Å:**")
                    sample_codes = list(master_data.keys())[:10]
                    sample_data = []
                    for code in sample_codes:
                        branch = master_data[code]
                        sample_data.append({
                            '‡∏£‡∏´‡∏±‡∏™': code,
                            '‡∏™‡∏≤‡∏Ç‡∏≤': branch.get('‡∏™‡∏≤‡∏Ç‡∏≤', branch.get('Branch Name', '')),
                            '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î': branch.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', branch.get('Province', '')),
                            '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': branch.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', branch.get('District', ''))
                        })
                    st.dataframe(pd.DataFrame(sample_data), use_container_width=True, hide_index=True)
                    st.markdown("---")
                    
                except Exception as e:
                    st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {e}")
            else:
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå branch_data.json")
    
    st.markdown("---")
    
    # ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    st.markdown("### üìÅ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå")
    st.markdown("""
    üìù **‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≤‡∏Ç‡∏≤ (Master Data)** ‡∏ñ‡∏π‡∏Å Sync ‡∏à‡∏≤‡∏Å **Google Sheets** ‚Üí ‡πÉ‡∏ä‡πâ‡∏õ‡∏∏‡πà‡∏° üîÑ ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠ Sync  
    üîÑ Auto Sync ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ß‡πá‡∏ö - ‡∏£‡∏ß‡∏° DC ‡∏ß‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏∞/‡∏•‡∏≠‡∏á
    """)
    
    uploaded_file = st.file_uploader(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå Excel (.xlsx)", 
        type=['xlsx'],
        help="‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Booking No, ‡∏™‡∏≤‡∏Ç‡∏≤, ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å, ‡∏Ñ‡∏¥‡∏ß ‡∏Ø‡∏•‡∏Ø"
    )
    
    df = None
    
    if uploaded_file:
        # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session_state ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô export
        uploaded_file_content = uploaded_file.read()
        st.session_state['original_file_content'] = uploaded_file_content
        
        with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•..."):
            df = load_excel(uploaded_file_content)
            df = process_dataframe(df)
    
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    if df is not None and 'Code' in df.columns:
        st.success(f"‚úÖ ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: **{len(df):,}** ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", f"{df['Code'].nunique():,}")
        with col2:
            st.metric("‚öñÔ∏è ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏ß‡∏°", f"{df['Weight'].sum():,.0f} kg")
        with col3:
            st.metric("üì¶ ‡∏Ñ‡∏¥‡∏ß‡∏£‡∏ß‡∏°", f"{df['Cube'].sum():.1f} m¬≥")
        with col4:
            provinces = df['Province'].nunique() if 'Province' in df.columns else 0
            st.metric("üó∫Ô∏è ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", f"{provinces}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        with st.expander("üîç ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"):
            st.dataframe(df.head(10), use_container_width=True)
        
        # ==========================================
        # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Master (‡∏ó‡∏≥‡πÉ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ö‡πâ‡∏≤‡∏ô)
        # ==========================================
        if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á dict ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏£‡πá‡∏ß
            master_lookup = {}
            for _, row in MASTER_DATA.iterrows():
                code = str(row['Plan Code']).strip().upper()
                master_lookup[code] = {
                    'province': row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''),
                    'district': row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                    'subdistrict': row.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                    'lat': row.get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0),
                    'lon': row.get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
                }
            
            # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î
            filled_count = 0
            for idx, row in df.iterrows():
                code = str(row['Code']).strip().upper()
                if code in master_lookup:
                    master_info = master_lookup[code]
                    # ‡πÄ‡∏ï‡∏¥‡∏° Province ‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
                    if 'Province' not in df.columns or pd.isna(df.loc[idx, 'Province']) or df.loc[idx, 'Province'] == '' or df.loc[idx, 'Province'] == 'UNKNOWN':
                        if master_info['province']:
                            df.loc[idx, 'Province'] = master_info['province']
                            filled_count += 1
                    # ‡πÄ‡∏ï‡∏¥‡∏° District ‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
                    if 'District' not in df.columns:
                        df['District'] = ''
                    if pd.isna(df.loc[idx, 'District']) or df.loc[idx, 'District'] == '':
                        if master_info['district']:
                            df.loc[idx, 'District'] = master_info['district']
                    # ‡πÄ‡∏ï‡∏¥‡∏° Subdistrict ‡∏ñ‡πâ‡∏≤‡∏ß‡πà‡∏≤‡∏á
                    if 'Subdistrict' not in df.columns:
                        df['Subdistrict'] = ''
                    if pd.isna(df.loc[idx, 'Subdistrict']) or df.loc[idx, 'Subdistrict'] == '':
                        if master_info['subdistrict']:
                            df.loc[idx, 'Subdistrict'] = master_info['subdistrict']
            
            if filled_count > 0:
                st.info(f"üìç ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å Master ‡πÅ‡∏•‡πâ‡∏ß {filled_count} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà‡∏à‡∏≥‡∏ô‡∏ß‡∏ô)
        if 'Province' in df.columns:
            missing_count = len(df[(df['Province'].isna()) | (df['Province'] == '') | (df['Province'] == 'UNKNOWN')])
            if missing_count > 0:
                st.warning(f"‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡∏°‡∏µ {missing_count} ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô Master")
        
        st.markdown("---")
        
        # ‡πÅ‡∏ó‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å
        tab1, tab2 = st.tabs([
            "üì¶ ‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)", 
            "üó∫Ô∏è ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ"
        ])
            
        # ==========================================
        # ‡πÅ‡∏ó‡πá‡∏ö 1: ‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)
        # ==========================================
        with tab1:
            # ‡πÄ‡∏û‡∏¥‡πà‡∏° Region ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            if 'Region' not in df.columns and 'Province' in df.columns:
                df['Region'] = df['Province'].apply(get_region_name)
            
            # ==========================================
            # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
            # ==========================================
            st.markdown("#### ‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ")
            
            # ‡∏Å‡∏£‡∏≠‡∏Å Buffer ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó
            col_buf1, col_buf2 = st.columns(2)
            
            with col_buf1:
                punthai_buffer = st.number_input(
                    "üÖøÔ∏è Punthai Buffer %",
                    min_value=80,
                    max_value=120,
                    value=100,
                    step=5
                )
            
            with col_buf2:
                maxmart_buffer = st.number_input(
                    "üÖº Maxmart/‡∏ú‡∏™‡∏° Buffer %",
                    min_value=80,
                    max_value=150,
                    value=110,
                    step=5
                )
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô buffer value
            punthai_buffer_value = punthai_buffer / 100.0
            maxmart_buffer_value = maxmart_buffer / 100.0
            
            st.markdown("---")
            
            # ‡∏õ‡∏∏‡πà‡∏°‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ
            if st.button("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏ß (Google OR-Tools)", type="primary", use_container_width=True):
                with st.spinner("‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."):
                    # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ/‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î/‡∏≠‡∏≥‡πÄ‡∏†‡∏≠/‡∏ï‡∏≥‡∏ö‡∏•/Route (‡πÉ‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô predict_trips)
                            df_to_process = df.copy()
                            
                            # ‡πÉ‡∏ä‡πâ OR-Tools ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö optimization
                            if ORTOOLS_AVAILABLE:
                                try:
                                    st.info("ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ Google OR-Tools optimization...")
                                    result_df, summary = predict_trips_ortools(
                                        df_to_process,
                                        buffer_punthai=punthai_buffer_value,
                                        buffer_maxmart=maxmart_buffer_value,
                                        master_data=MASTER_DATA if not MASTER_DATA.empty else None,
                                        max_trips=80,
                                        time_limit=50,
                                        restrictions=VEHICLE_RESTRICTIONS if VEHICLE_LOGIC_AVAILABLE else None
                                    )
                                    if len(summary) == 0:
                                        st.warning("‚ö†Ô∏è OR-Tools ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ")
                                except Exception as e:
                                    st.error(f"‚ùå Error with OR-Tools: {e}")
                            else:
                                st.error("‚ùå OR-Tools ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô - ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢: pip install ortools")
                                st.stop()
                            
                            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ (Trip = 0)
                            unassigned_count = len(result_df[result_df['Trip'] == 0])
                            if unassigned_count > 0:
                                st.warning(f"‚ö†Ô∏è ‡∏°‡∏µ {unassigned_count} ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ (Trip = 0)")
                            
                            # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                            assigned_df = result_df[result_df['Trip'] > 0].copy()
                            
                            st.balloons()
                            st.success(f"‚úÖ **‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!** ‡∏£‡∏ß‡∏° **{len(summary)}** ‡∏ó‡∏£‡∏¥‡∏õ ({len(assigned_df)} ‡∏™‡∏≤‡∏Ç‡∏≤)")
                            
                            st.markdown("---")
                            
                            # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
                            st.markdown("### üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("üöö ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏£‡∏¥‡∏õ", len(summary))
                            with col2:
                                st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", len(assigned_df))
                            with col3:
                                avg_branches = len(assigned_df) / max(1, assigned_df['Trip'].nunique())
                                st.metric("üìä ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤/‡∏ó‡∏£‡∏¥‡∏õ", f"{avg_branches:.1f}")
                            with col4:
                                # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ summary ‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡∏´‡∏£‡∏∑‡∏≠ dict
                                if isinstance(summary, pd.DataFrame):
                                    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Cube_Use% ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                                    if 'Cube_Use%' in summary.columns and len(summary) > 0:
                                        avg_util = summary['Cube_Use%'].mean()
                                    elif 'Cube' in summary.columns and 'Vehicle' in summary.columns:
                                        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏≠‡∏á
                                        vehicle_limits = {'4W': 5.0, 'JB': 12.0, '6W': 20.0}
                                        summary['Cube_Use%'] = summary.apply(
                                            lambda row: (row['Cube'] / vehicle_limits.get(row['Vehicle'], 20.0)) * 100 
                                            if row['Vehicle'] in vehicle_limits else 0,
                                            axis=1
                                        )
                                        avg_util = summary['Cube_Use%'].mean()
                                    else:
                                        avg_util = 0
                                else:
                                    # ‡∏ñ‡πâ‡∏≤ summary ‡πÄ‡∏õ‡πá‡∏ô dict ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame
                                    summary = pd.DataFrame([summary]) if isinstance(summary, dict) else pd.DataFrame()
                                    avg_util = 0
                                st.metric("üìà ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢", f"{avg_util:.0f}%")
                            
                            st.markdown("---")
                            
                            # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ
                            st.markdown("### üöõ ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ó‡∏£‡∏¥‡∏õ")
                            
                            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ summary ‡πÄ‡∏õ‡πá‡∏ô DataFrame
                            if not isinstance(summary, pd.DataFrame):
                                if isinstance(summary, dict):
                                    summary = pd.DataFrame([summary])
                                else:
                                    summary = pd.DataFrame()
                            
                            if not summary.empty:
                                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° format dict ‡πÇ‡∏î‡∏¢‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                                format_dict = {}
                                if 'Weight' in summary.columns:
                                    format_dict['Weight'] = '{:.2f}'
                                if 'Cube' in summary.columns:
                                    format_dict['Cube'] = '{:.2f}'
                                if 'Weight_Use%' in summary.columns:
                                    format_dict['Weight_Use%'] = '{:.1f}%'
                                if 'Cube_Use%' in summary.columns:
                                    format_dict['Cube_Use%'] = '{:.1f}%'
                                if 'Total_Distance' in summary.columns:
                                    format_dict['Total_Distance'] = '{:.1f} km'
                                
                                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° subset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö gradient
                                gradient_cols = [col for col in ['Weight_Use%', 'Cube_Use%'] if col in summary.columns]
                                
                                if format_dict and gradient_cols:
                                    st.dataframe(
                                        summary.style.format(format_dict).background_gradient(
                                            subset=gradient_cols,
                                            cmap='RdYlGn',
                                            vmin=0,
                                            vmax=100
                                        ),
                                        use_container_width=True,
                                        height=400
                                    )
                                else:
                                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ format ‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏ö‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥
                                    st.dataframe(summary, use_container_width=True, height=400)
                            else:
                                st.info("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏£‡∏¥‡∏õ")
                            
                            # ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏ñ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á)
                            with st.expander("üìã ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏£‡∏≤‡∏¢‡∏™‡∏≤‡∏Ç‡∏≤ (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)"):
                                # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
                                display_cols = ['Trip', 'Code', 'Name']
                                if 'Province' in result_df.columns:
                                    display_cols.append('Province')
                                if 'Region' in result_df.columns:
                                    display_cols.append('Region')
                                
                                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
                                for col in ['Max_Distance_in_Trip', 'Weight', 'Cube', 'Truck', 'VehicleCheck']:
                                    if col in result_df.columns:
                                        display_cols.append(col)
                                
                                # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
                                display_cols = [col for col in display_cols if col in result_df.columns]
                                display_df = result_df[display_cols].copy()
                                
                                # ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
                                col_names = {'Trip': '‡∏ó‡∏£‡∏¥‡∏õ', 'Code': '‡∏£‡∏´‡∏±‡∏™', 'Name': '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', 'Province': '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 
                                           'Region': '‡∏†‡∏≤‡∏Ñ', 'Max_Distance_in_Trip': '‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á Max(km)', 
                                           'Weight': '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å(kg)', 'Cube': '‡∏Ñ‡∏¥‡∏ß(m¬≥)', 'Truck': '‡∏£‡∏ñ', 'VehicleCheck': '‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏ñ'}
                                display_df.columns = [col_names.get(c, c) for c in display_cols]
                                
                                # ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á
                                st.dataframe(
                                    display_df.style.format({
                                        '‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á(km)': '{:.1f}',
                                        '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å(kg)': '{:.2f}',
                                        '‡∏Ñ‡∏¥‡∏ß(m¬≥)': '{:.2f}'
                                    }),
                                    use_container_width=True, 
                                    height=400
                                )
                            
                            # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå VehicleCheck)
                            if 'VehicleCheck' in result_df.columns:
                                warning_branches = result_df[result_df['VehicleCheck'].str.contains('‚ö†Ô∏è', na=False)]
                                if len(warning_branches) > 0:
                                    with st.expander(f"‚ö†Ô∏è ‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏Å‡∏ï‡∏¥ ({len(warning_branches)} ‡∏™‡∏≤‡∏Ç‡∏≤)"):
                                        st.warning("‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏õ‡∏Å‡∏ï‡∏¥‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏≠‡∏∑‡πà‡∏ô ‡πÅ‡∏ï‡πà‡∏ñ‡∏π‡∏Å‡∏à‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ")
                                        display_cols_warn = ['Trip', 'Code', 'Name', 'Truck', 'VehicleCheck']
                                        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
                                        display_cols_warn = [col for col in display_cols_warn if col in warning_branches.columns]
                                        display_warn_df = warning_branches[display_cols_warn].copy()
                                        col_names_warn = {'Trip': '‡∏ó‡∏£‡∏¥‡∏õ', 'Code': '‡∏£‡∏´‡∏±‡∏™', 'Name': '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', 'Truck': '‡∏£‡∏ñ‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î', 'VehicleCheck': '‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏£‡∏ñ'}
                                        display_warn_df.columns = [col_names_warn.get(c, c) for c in display_cols_warn]
                                        st.dataframe(display_warn_df, use_container_width=True)
                            
                            st.markdown("---")
                            
                            # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î - ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö‡∏ä‡∏µ‡∏ï 2.Punthai ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏•‡∏±‡∏ö‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡πÇ‡∏ó‡∏ô‡∏™‡πâ‡∏°-‡∏Ç‡∏≤‡∏ß
                            from openpyxl import load_workbook
                            from openpyxl.styles import PatternFill, Font, Border, Side
                            
                            output = io.BytesIO()
                            
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á location_map ‡∏à‡∏≤‡∏Å MASTER_DATA
                            location_map = {}
                            if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
                                for _, row in MASTER_DATA.iterrows():
                                    code = str(row.get('Plan Code', '')).strip().upper()
                                    if code:
                                        location_map[code] = {
                                            '‡∏ï‡∏≥‡∏ö‡∏•': row.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                                            '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                                            '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î': row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''),
                                            'Route': row.get('Reference', '')
                                        }
                            
                            # ‡∏™‡∏£‡πâ‡∏≤‡∏á Trip_No map
                            trip_no_map = {}
                            vehicle_counts = {'4W': 0, '4WJ': 0, '6W': 0}
                            
                            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á trip ‡∏ï‡∏≤‡∏° Zone Order + Province Max Dist + District Max Dist (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡∏≠‡∏ô‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ)
                            ZONE_ORDER_EXPORT = {'NORTH': 1, 'NE': 2, 'SOUTH': 3, 'EAST': 4, 'WEST': 5, 'CENTRAL': 6}
                            trip_sort_keys = {}
                            
                            for trip_num in result_df['Trip'].unique():
                                if trip_num == 0:
                                    continue
                                trip_data = result_df[result_df['Trip'] == trip_num]
                                
                                # ‡∏´‡∏≤ Region Order
                                region = trip_data['Region'].iloc[0] if 'Region' in trip_data.columns else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                                region_order = ZONE_ORDER_EXPORT.get(region, 99)
                                
                                # ‡∏´‡∏≤ Province Max Distance ‡πÅ‡∏•‡∏∞ District Max Distance
                                prov_max_dist = 0
                                dist_max_dist = 0
                                
                                for code in trip_data['Code'].unique():
                                    loc = location_map.get(str(code).upper(), {})
                                    # ‡∏î‡∏∂‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏≤‡∏Å MASTER_DATA
                                    if not MASTER_DATA.empty:
                                        master_row = MASTER_DATA[MASTER_DATA['Plan Code'].astype(str).str.upper() == str(code).upper()]
                                        if len(master_row) > 0:
                                            dist_km = master_row.iloc[0].get('Distance from DC (km)', 0)
                                            if pd.notna(dist_km):
                                                prov_max_dist = max(prov_max_dist, float(dist_km))
                                                dist_max_dist = max(dist_max_dist, float(dist_km))
                                
                                # Sort key: Region Order (Asc), Prov Max Dist (Desc), Dist Max Dist (Desc)
                                # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏•‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ sort Desc
                                trip_sort_keys[trip_num] = (region_order, -prov_max_dist, -dist_max_dist)
                            
                            # Sort: Zone Order ‚Üí Province Max Dist (‡πÑ‡∏Å‡∏•‡∏Å‡πà‡∏≠‡∏ô) ‚Üí District Max Dist (‡πÑ‡∏Å‡∏•‡∏Å‡πà‡∏≠‡∏ô)
                            sorted_trips = sorted(
                                [t for t in result_df['Trip'].unique() if t != 0],
                                key=lambda t: trip_sort_keys.get(t, (99, 0, 0))
                            )
                            
                            for trip_num in sorted_trips:
                                trip_summary = summary[summary['Trip'] == trip_num]
                                if len(trip_summary) > 0:
                                    truck_info = trip_summary.iloc[0]['Truck']
                                    vehicle_type = truck_info.split()[0] if truck_info else '6W'
                                    # JB ‡πÉ‡∏ä‡πâ prefix 4WJ
                                    if vehicle_type == 'JB':
                                        vehicle_type = '4WJ'
                                    vehicle_counts[vehicle_type] = vehicle_counts.get(vehicle_type, 0) + 1
                                    trip_no = f"{vehicle_type}{vehicle_counts[vehicle_type]:03d}"
                                    trip_no_map[trip_num] = trip_no
                            
                            try:
                                # ‡πÇ‡∏´‡∏•‡∏î workbook ‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö
                                wb = load_workbook(io.BytesIO(st.session_state.get('original_file_content', b'')))
                                
                                # ‡∏´‡∏≤‡∏ä‡∏µ‡∏ï‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (2.Punthai)
                                target_sheet = None
                                for sheet_name in wb.sheetnames:
                                    if 'punthai' in sheet_name.lower() or '2.' in sheet_name.lower():
                                        target_sheet = sheet_name
                                        break
                                
                                if not target_sheet:
                                    target_sheet = '2.Punthai'
                                    if target_sheet not in wb.sheetnames:
                                        wb.create_sheet(target_sheet)
                                
                                ws = wb[target_sheet]
                                
                                # ‡∏´‡∏≤ header row
                                header_row = 1
                                for row_idx in range(1, min(5, ws.max_row + 1)):
                                    for col_idx in range(1, min(15, ws.max_column + 1)):
                                        cell_val = str(ws.cell(row=row_idx, column=col_idx).value or '')
                                        if '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤' in cell_val or 'Trip' in cell_val.upper():
                                            header_row = row_idx
                                            break
                                
                                # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤
                                if ws.max_row > header_row:
                                    ws.delete_rows(header_row + 1, ws.max_row - header_row)
                                
                                # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô header ‡πÉ‡∏´‡∏°‡πà
                                new_headers = ['Sep.', 'BU', '‡∏£‡∏´‡∏±‡∏™‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏£‡∏´‡∏±‡∏™ WMS', '‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'Route',
                                              'Total Cube', 'Total Wgt', 'Original QTY', 'Trip', 'Trip no']
                                for col_idx, header_val in enumerate(new_headers, 1):
                                    ws.cell(row=header_row, column=col_idx, value=header_val)
                                
                                # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á‡πÇ‡∏ó‡∏ô‡∏™‡πâ‡∏°-‡∏Ç‡∏≤‡∏ß (‡∏™‡∏•‡∏±‡∏ö 2 ‡∏™‡∏µ)
                                yellow_orange = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')
                                white_fill = PatternFill(start_color='FFFFFF', end_color='FFFFFF', fill_type='solid')
                                thin_border = Border(
                                    left=Side(style='thin'), right=Side(style='thin'),
                                    top=Side(style='thin'), bottom=Side(style='thin')
                                )
                                red_font = Font(color='FF0000', bold=True)
                                
                                # ‡∏´‡∏≤‡∏ó‡∏£‡∏¥‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå
                                failed_trips = set()
                                vehicle_limits = {'4W': {'max_w': 2500, 'max_c': 5.0}, 'JB': {'max_w': 3500, 'max_c': 7.0}, '6W': {'max_w': 6000, 'max_c': 20.0}}
                                for t in result_df['Trip'].unique():
                                    if t == 0:
                                        continue
                                    trip_data = result_df[result_df['Trip'] == t]
                                    trip_cube = trip_data['Cube'].sum()
                                    trip_weight = trip_data['Weight'].sum()
                                    trip_no = trip_no_map.get(t, '6W001')
                                    veh_type = 'JB' if trip_no.startswith('4WJ') else ('4W' if trip_no.startswith('4W') else '6W')
                                    limits = vehicle_limits.get(veh_type, vehicle_limits['6W'])
                                    max_util = max((trip_cube / limits['max_c']) * 100, (trip_weight / limits['max_w']) * 100)
                                    if max_util > 105 or max_util < 50:
                                        failed_trips.add(t)
                                
                                # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                                current_trip = None
                                use_yellow = True
                                row_num = header_row + 1
                                sep_num = 1
                                
                                for trip_num in sorted_trips:
                                    trip_data = result_df[result_df['Trip'] == trip_num].copy()
                                    
                                    # Sort ‡∏ï‡∏≤‡∏° ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                                    trip_data['_sort_sub'] = trip_data['Code'].apply(lambda c: location_map.get(str(c).upper(), {}).get('‡∏ï‡∏≥‡∏ö‡∏•', ''))
                                    trip_data['_sort_dist'] = trip_data['Code'].apply(lambda c: location_map.get(str(c).upper(), {}).get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''))
                                    trip_data['_sort_prov'] = trip_data['Code'].apply(lambda c: location_map.get(str(c).upper(), {}).get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''))
                                    trip_data = trip_data.sort_values(['_sort_prov', '_sort_dist', '_sort_sub', 'Code'])
                                    
                                    trip_no = trip_no_map.get(trip_num, '')
                                    
                                    # ‡∏™‡∏•‡∏±‡∏ö‡∏™‡∏µ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ó‡∏£‡∏¥‡∏õ
                                    if current_trip != trip_num:
                                        current_trip = trip_num
                                        use_yellow = not use_yellow
                                    
                                    fill = yellow_orange if use_yellow else white_fill
                                    
                                    for _, row in trip_data.iterrows():
                                        branch_code = row.get('Code', '')
                                        loc = location_map.get(str(branch_code).upper(), {})
                                        
                                        data = [
                                            sep_num,
                                            row.get('BU', 211),
                                            branch_code,
                                            branch_code,
                                            row.get('Name', ''),
                                            loc.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                                            loc.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                                            loc.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', ''),
                                            loc.get('Route', ''),
                                            round(row.get('Cube', 0), 2) if pd.notna(row.get('Cube')) else 0,
                                            round(row.get('Weight', 0), 2) if pd.notna(row.get('Weight')) else 0,
                                            row.get('OriginalQty', 0) if pd.notna(row.get('OriginalQty')) else 0,
                                            int(trip_num),
                                            trip_no,
                                        ]
                                        
                                        for col_idx, value in enumerate(data, 1):
                                            cell = ws.cell(row=row_num, column=col_idx, value=value)
                                            cell.fill = fill
                                            cell.border = thin_border
                                            if trip_num in failed_trips:
                                                cell.font = red_font
                                        
                                        row_num += 1
                                        sep_num += 1
                                
                                wb.save(output)
                                output.seek(0)
                                
                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÑ‡∏î‡πâ: {e} - ‡πÉ‡∏ä‡πâ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÅ‡∏ó‡∏ô")
                                # Fallback: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢ xlsxwriter
                                output = io.BytesIO()
                                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                                    export_df = result_df.copy()
                                    export_df['Trip_No'] = export_df['Trip'].map(lambda x: trip_no_map.get(x, ''))
                                    export_df.to_excel(writer, sheet_name='‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏£‡∏¥‡∏õ', index=False)
                                    summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏£‡∏¥‡∏õ', index=False)
                            
                            col1, col2, col3 = st.columns([1, 2, 1])
                            with col2:
                                st.download_button(
                                    label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Excel)",
                                    data=output.getvalue(),
                            file_name=f"‡∏ú‡∏•‡∏à‡∏±‡∏î‡∏ó‡∏£‡∏¥‡∏õ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
        
        # ==========================================
        # ‡πÅ‡∏ó‡πá‡∏ö 2: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ (‡πÑ‡∏°‡πà‡∏™‡∏ô‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å)
        # ==========================================
        with tab2:
            df_region = df.copy()
            
            # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
            branch_info = model_data.get('branch_info', {})
            trip_pairs = model_data.get('trip_pairs', set())
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏†‡∏≤‡∏Ñ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤ (‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)
            region_groups = {
                '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡πÉ‡∏ô': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏ä‡∏±‡πâ‡∏ô‡∏ô‡∏≠‡∏Å': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£'],
                '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏õ‡∏£‡∏¥‡∏°‡∏ì‡∏ë‡∏•': ['‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£'],
                '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤'],
                '‡∏†‡∏≤‡∏Ñ‡∏Å‡∏•‡∏≤‡∏á-‡∏Å‡∏•‡∏≤‡∏á‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏ï‡∏Å': ['‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå', '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡∏ï‡∏∞‡∏ß‡∏±‡∏ô‡∏≠‡∏≠‡∏Å': ['‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ï‡∏£‡∏≤‡∏î', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß', '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÄ‡∏´‡∏ô‡∏∑‡∏≠': ['‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°', '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨', '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£', '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£', '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π', '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏•‡∏¢'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á': ['‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå', '‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô', '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥', '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°', '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î'],
                        '‡∏†‡∏≤‡∏Ñ‡∏≠‡∏µ‡∏™‡∏≤‡∏ô-‡∏≠‡∏µ‡∏™‡∏≤‡∏ô‡πÉ‡∏ï‡πâ': ['‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤', '‡πÇ‡∏Ñ‡∏£‡∏≤‡∏ä', '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå', '‡∏¢‡πÇ‡∏™‡∏ò‡∏£', '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©', '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå', '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç', '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ'],
                        '‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠-‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏ö‡∏ô': ['‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤', '‡∏•‡∏≥‡∏õ‡∏≤‡∏á', '‡∏•‡∏≥‡∏û‡∏π‡∏ô', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÅ‡∏û‡∏£‡πà', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô'],
                        '‡∏†‡∏≤‡∏Ñ‡πÄ‡∏´‡∏ô‡∏∑‡∏≠-‡πÄ‡∏´‡∏ô‡∏∑‡∏≠‡∏ï‡∏≠‡∏ô‡∏•‡πà‡∏≤‡∏á': ['‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£', '‡∏ï‡∏≤‡∏Å', '‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå', '‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£', '‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å', '‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢', '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå', '‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏π‡∏£‡∏ì‡πå'],
                        '‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ-‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡∏±‡∏ô‡∏î‡∏≤‡∏°‡∏±‡∏ô': ['‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏ï‡∏£‡∏±‡∏á', '‡∏û‡∏±‡∏á‡∏á‡∏≤', '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏£‡∏∞‡∏ô‡∏≠‡∏á', '‡∏™‡∏ï‡∏π‡∏•'],
                        '‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ï‡πâ-‡πÉ‡∏ï‡πâ‡∏ù‡∏±‡πà‡∏á‡∏≠‡πà‡∏≤‡∏ß‡πÑ‡∏ó‡∏¢': ['‡∏ä‡∏∏‡∏°‡∏û‡∏£', '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™']
            }
  
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏†‡∏≤‡∏Ñ - ‡∏î‡∏∂‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å Master ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ
            if 'Province' not in df_region.columns or df_region['Province'].isna().any():
                # ‡∏î‡∏∂‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å Master
                if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
                    province_map = {}
                    for _, row in MASTER_DATA.iterrows():
                        code = row.get('Plan Code', '')
                        province = row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', '')
                        if code and province:
                            province_map[code] = province
                    
                    # ‡πÉ‡∏™‡πà‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÉ‡∏´‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤
                    if 'Province' not in df_region.columns:
                        df_region['Province'] = df_region['Code'].map(province_map)
                    else:
                        # ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NaN
                        df_region['Province'] = df_region.apply(
                            lambda row: province_map.get(row['Code'], row.get('Province', 'UNKNOWN')) 
                            if pd.isna(row.get('Province')) else row['Province'],
                            axis=1
                        )
                
                # Define region mapping
                REGION_PROVINCES = {
                    'NORTH': ['‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà', '‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢', '‡∏•‡∏≥‡∏õ‡∏≤‡∏á', '‡∏•‡∏≥‡∏û‡∏π‡∏ô', '‡πÅ‡∏°‡πà‡∏Æ‡πà‡∏≠‡∏á‡∏™‡∏≠‡∏ô', '‡∏ô‡πà‡∏≤‡∏ô', '‡∏û‡∏∞‡πÄ‡∏¢‡∏≤', '‡πÅ‡∏û‡∏£‡πà', '‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå'],
                    'NORTHEAST': ['‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô', '‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤', '‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£', '‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î', '‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°', '‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå', '‡πÄ‡∏•‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢', '‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π', '‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥', '‡∏¢‡πÇ‡∏™‡∏ò‡∏£', '‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£', '‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°', '‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©', '‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå', '‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå', '‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç', '‡∏ö‡∏∂‡∏á‡∏Å‡∏≤‡∏¨'],
                    'CENTRAL': ['‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û‡∏°‡∏´‡∏≤‡∏ô‡∏Ñ‡∏£', '‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£', '‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤', '‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á', '‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó', '‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ', '‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤', '‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å', '‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£', '‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°', '‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°', '‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ', '‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ', '‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ', '‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå'],
                    'EAST': ['‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ', '‡∏£‡∏∞‡∏¢‡∏≠‡∏á', '‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ', '‡∏ï‡∏£‡∏≤‡∏î', '‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß'],
                    'SOUTH': ['‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ', '‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä', '‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï', '‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà', '‡∏û‡∏±‡∏á‡∏á‡∏≤', '‡∏£‡∏∞‡∏ô‡∏≠‡∏á', '‡∏ä‡∏∏‡∏°‡∏û‡∏£', '‡∏™‡∏á‡∏Ç‡∏•‡∏≤', '‡∏ï‡∏£‡∏±‡∏á', '‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á', '‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ', '‡∏¢‡∏∞‡∏•‡∏≤', '‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™', '‡∏™‡∏ï‡∏π‡∏•']
                }
                
                # Map province to region
                def get_region_from_province(prov):
                    for region, provinces in REGION_PROVINCES.items():
                        if prov in provinces:
                            return region
                    return 'OTHER'
                
                df_region['Region'] = df_region['Province'].apply(get_region_from_province)
                
                # ‡∏´‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤ (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏≤‡∏á‡∏†‡∏π‡∏°‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå)
                def find_paired_branches(code, code_province, df_data):
                    paired = set()
                    
                    # ‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô
                    code_rows = df_data[df_data['Code'] == code]
                    if len(code_rows) == 0:
                        return paired
                    
                    # ‡∏´‡∏≤‡∏™‡∏≤‡∏Ç‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏ô‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
                    same_province = df_data[df_data['Province'] == code_province]
                    for _, other_row in same_province.iterrows():
                        other_code = other_row['Code']
                        if other_code != code:
                            paired.add(other_code)
                    
                    return paired
                    
                    all_codes_set = set(df_region['Code'].unique())
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏ö‡∏ö Union-Find (‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö: ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î)
                    # Step 1: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏≤‡∏Ç‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Master
                    initial_groups = {}
                    for code in all_codes_set:
                        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Master
                        location = {}
                        if not MASTER_DATA.empty and 'Plan Code' in MASTER_DATA.columns:
                            master_row = MASTER_DATA[MASTER_DATA['Plan Code'] == code]
                            if len(master_row) > 0:
                                master_row = master_row.iloc[0]
                                location = {
                                    'subdistrict': master_row.get('‡∏ï‡∏≥‡∏ö‡∏•', ''),
                                    'district': master_row.get('‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', ''),
                                    'province': master_row.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'UNKNOWN'),
                                    'lat': master_row.get('‡∏•‡∏∞‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0),
                                    'lon': master_row.get('‡∏•‡∏≠‡∏á‡∏ï‡∏¥‡∏à‡∏π‡∏î', 0)
                                }
                        
                        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô Master ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
                        if not location or location.get('province', 'UNKNOWN') == 'UNKNOWN':
                            c_row = df_region[df_region['Code'] == code].iloc[0] if len(df_region[df_region['Code'] == code]) > 0 else None
                            if c_row is not None:
                                location = {
                                    'subdistrict': '',
                                    'district': '',
                                    'province': c_row.get('Province', 'UNKNOWN'),
                                    'lat': 0,
                                    'lon': 0
                                }
                        
                        if location:
                            initial_groups[(code,)] = {code: location}
                    
                    # ‡πÉ‡∏ä‡πâ initial_groups ‡πÅ‡∏ó‡∏ô booking_groups
                    booking_groups = initial_groups
                    
                    # Step 2: ‡∏£‡∏ß‡∏°‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡∏ï‡∏≥‡∏ö‡∏• ‚Üí ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‚Üí ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î
                    def groups_can_merge(locs1, locs2):
                        """‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ 2 ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏ß‡∏£‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡πÑ‡∏´‡∏° (‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)"""
                        # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ï‡∏≥‡∏ö‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡∏ö‡∏•)
                        subdistricts1 = set(loc.get('subdistrict', '') for loc in locs1.values() if loc.get('subdistrict', ''))
                        subdistricts2 = set(loc.get('subdistrict', '') for loc in locs2.values() if loc.get('subdistrict', ''))
                        if subdistricts1 and subdistricts2 and (subdistricts1 & subdistricts2):
                            return True, '‡∏ï‡∏≥‡∏ö‡∏•'
                        
                        # 2. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
                        districts1 = {(loc.get('district', ''), loc.get('province', '')) for loc in locs1.values() if loc.get('district', '')}
                        districts2 = {(loc.get('district', ''), loc.get('province', '')) for loc in locs2.values() if loc.get('district', '')}
                        if districts1 and districts2:
                            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô
                            for d1, p1 in districts1:
                                for d2, p2 in districts2:
                                    if d1 == d2 and p1 == p2 and p1:
                                        return True, '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠'
                        
                        # 3. ‡πÄ‡∏ä‡πá‡∏Ñ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
                        provinces1 = set(loc.get('province', '') for loc in locs1.values() if loc.get('province', ''))
                        provinces2 = set(loc.get('province', '') for loc in locs2.values() if loc.get('province', ''))
                        if provinces1 & provinces2:
                            return True, '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î'
                        
                        return False, None
                    
                    merged_groups = []
                    used_groups = set()
                    
                    for group1, locs1 in booking_groups.items():
                        if group1 in used_groups:
                            continue
                        
                        merged_codes = set(group1)
                        merged_locs = locs1.copy()
                        used_groups.add(group1)
                        
                        # ‡∏´‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏≠‡∏∑‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á
                        changed = True
                        while changed:
                            changed = False
                            for group2, locs2 in booking_groups.items():
                                if group2 in used_groups:
                                    continue
                                can_merge, level = groups_can_merge(merged_locs, locs2)
                                if can_merge:
                                    merged_codes |= set(group2)
                                    merged_locs.update(locs2)
                                    used_groups.add(group2)
                                    changed = True
                        
                        merged_groups.append({
                            'codes': merged_codes,
                            'locations': merged_locs
                        })
                    
                    # Step 3: ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô groups format
                    groups = []
                    for mg in merged_groups:
                        rep_code = list(mg['codes'])[0]
                        rep_row = df_region[df_region['Code'] == rep_code].iloc[0]
                        # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà UNKNOWN ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô NaN
                        provinces = set(
                            str(loc.get('province', '')).strip() 
                            for loc in mg['locations'].values() 
                            if loc.get('province') and str(loc.get('province', '')).strip() not in ['UNKNOWN', 'nan', '']
                        )
                        
                        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡πÄ‡∏•‡∏¢ ‡πÉ‡∏™‡πà "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
                        province_str = ', '.join(sorted(provinces)) if provinces else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'
                        
                        groups.append({
                            'codes': mg['codes'],
                            'region': rep_row.get('Region', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'),
                            'province': province_str
                        })
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                    st.markdown("---")
                    st.markdown("### üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üìç ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤", df_region['Code'].nunique())
                    with col2:
                        st.metric("üóÇÔ∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°", len(groups))
                    with col3:
                        regions_count = df_region['Region'].nunique()
                        st.metric("üó∫Ô∏è ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏†‡∏≤‡∏Ñ", regions_count)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ
                    st.markdown("---")
                    st.markdown("### üó∫Ô∏è ‡∏™‡∏≤‡∏Ç‡∏≤‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ")
                    
                    region_summary = df_region.groupby('Region').agg({
                        'Code': 'nunique',
                        'Weight': 'sum',
                        'Cube': 'sum'
                    }).reset_index()
                    region_summary.columns = ['‡∏†‡∏≤‡∏Ñ', '‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏Ç‡∏≤', '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏£‡∏ß‡∏°', '‡∏Ñ‡∏¥‡∏ß‡∏£‡∏ß‡∏°']
                    st.dataframe(region_summary, width='stretch')
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏≤‡∏Ñ
                    for region in sorted(df_region['Region'].unique()):
                        region_data = df_region[df_region['Region'] == region]
                        with st.expander(f"üìç {region} ({region_data['Code'].nunique()} ‡∏™‡∏≤‡∏Ç‡∏≤)"):
                            display_cols = ['Code', 'Name', 'Province', 'Weight', 'Cube']
                            display_cols = [c for c in display_cols if c in region_data.columns]
                            
                            region_display = region_data[display_cols].drop_duplicates('Code')
                            col_names = {'Code': '‡∏£‡∏´‡∏±‡∏™', 'Name': '‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏Ç‡∏≤', 'Province': '‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î', 'Weight': '‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å', 'Cube': '‡∏Ñ‡∏¥‡∏ß'}
                            region_display.columns = [col_names.get(c, c) for c in display_cols]
                            st.dataframe(region_display, use_container_width=True)
                    
                    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô
                    st.markdown("---")
                    st.markdown("### üîó ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô (‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥)")
                    
                    paired_groups = [g for g in groups if len(g['codes']) > 1]
                    if paired_groups:
                        for i, group in enumerate(paired_groups, 1):
                            codes_list = list(group['codes'])
                            names = []
                            for c in codes_list:
                                name_row = df_region[df_region['Code'] == c]
                                if len(name_row) > 0 and 'Name' in name_row.columns:
                                    names.append(f"{c} ({name_row['Name'].iloc[0]})")
                                else:
                                    names.append(c)
                            
                            st.write(f"**‡∏Å‡∏•‡∏∏‡πà‡∏° {i}** - {group['region']}: {', '.join(names)}")
                    else:
                        st.info("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ô‡∏µ‡πâ")
                    
                    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
                    st.markdown("---")
                    output_region = io.BytesIO()
                    with pd.ExcelWriter(output_region, engine='xlsxwriter') as writer:
                        df_region.to_excel(writer, sheet_name='‡∏™‡∏≤‡∏Ç‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î', index=False)
                        region_summary.to_excel(writer, sheet_name='‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏†‡∏≤‡∏Ñ', index=False)
                    
                    col1, col2, col3 = st.columns([1, 2, 1])
                    with col2:
                        st.download_button(
                            label="üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° (Excel)",
                            data=output_region.getvalue(),
                            file_name=f"‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏™‡∏≤‡∏Ç‡∏≤_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )

if __name__ == "__main__":
    main()
